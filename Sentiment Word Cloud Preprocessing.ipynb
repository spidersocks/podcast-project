{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "966975aa-27e9-426e-9cee-98493a35288d",
   "metadata": {},
   "source": [
    "# Sentiment Word Cloud Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d05d3-ea4a-451a-8914-0e2f402d294b",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Add necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce89c47-2f52-4c22-9621-ca822ffedb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ee0bb-5e22-4ec6-93da-c3f88e2a0e80",
   "metadata": {},
   "source": [
    "## Loading DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb880316-4c5f-43bc-b445-c013a9d1cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/chunks_w_all_topics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8c6ab-12c1-402b-9888-3fab4efad8dd",
   "metadata": {},
   "source": [
    "## Generate Sentiment DataFrame\n",
    "Generate a DataFrame `avg_sentiment` where rows represent a combination of a source and a topic. Key outcome column is the average sentiment score of that source on that topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cea2a-65ab-45ed-be8c-a8030f7f55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute per-topic average sentiment\n",
    "avg_sentiment = (\n",
    "    exploded\n",
    "    .groupby([\"source_type\", \"source_name\", \"topic\"])[\"sentiment_score\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sentiment_score\": \"avg_sentiment_score\"})\n",
    ")\n",
    "\n",
    "# compute sentiment across all topics for each combination of sources\n",
    "all_topics_sources = (\n",
    "    exploded\n",
    "    .groupby([\"source_type\", \"source_name\"])[\"sentiment_score\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .assign(topic=\"all_topics\")\n",
    "    .rename(columns={\"sentiment_score\": \"avg_sentiment_score\"})\n",
    ")\n",
    "\n",
    "# compute an all-topics sentiment for each source type\n",
    "all_topics_types = (\n",
    "    exploded\n",
    "    .groupby([\"source_type\"])[\"sentiment_score\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .assign(topic=\"all_topics\")\n",
    "    .rename(columns={\"sentiment_score\": \"avg_sentiment_score\"})\n",
    ")\n",
    "all_topics_types[\"source_name\"] = all_topics_types[\"source_type\"]\n",
    "\n",
    "# concatenate all together\n",
    "avg_sentiment_all = pd.concat([avg_sentiment, all_topics_sources, all_topics_types], ignore_index=True)\n",
    "\n",
    "# normalize by sentiment distribution quantile\n",
    "def add_split_quantile_normalized_sentiment(avg_sentiment_df):\n",
    "    df = avg_sentiment_df.copy()\n",
    "    negatives = df[\"avg_sentiment_score\"] < 0\n",
    "    positives = df[\"avg_sentiment_score\"] > 0\n",
    "\n",
    "    df[\"quantile_sentiment_scaled\"] = 0.0\n",
    "\n",
    "    if negatives.sum() > 0:\n",
    "        df.loc[negatives, \"quantile_sentiment_scaled\"] = -df.loc[negatives, \"avg_sentiment_score\"].rank(method=\"average\", pct=True)\n",
    "    if positives.sum() > 0:\n",
    "        df.loc[positives, \"quantile_sentiment_scaled\"] = df.loc[positives, \"avg_sentiment_score\"].rank(method=\"average\", pct=True)\n",
    "    # zero stays at zero\n",
    "    return df\n",
    "\n",
    "avg_sentiment_all = add_split_quantile_normalized_sentiment(avg_sentiment_all)\n",
    "\n",
    "def get_sentiment_label(s):\n",
    "    if s < -1/3:\n",
    "        return \"negative\"\n",
    "    elif s < 1/3:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "avg_sentiment_all[\"sentiment_label\"] = avg_sentiment_all[\"quantile_sentiment_scaled\"].apply(get_sentiment_label)\n",
    "\n",
    "# display\n",
    "display(avg_sentiment_all.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe4159c-8347-4f1a-a4a6-350763262388",
   "metadata": {},
   "source": [
    "## Generate Top Unique Words DataFrame\n",
    "Generate two DataFrames `topwords_df` and `topwords_type_df`. Rows represent unique combinations of specific podcast / news sources and topics for `topwrods_df`, and source types (podcast/news) and topics for `topwords_type_df`. Key outcome variable is the top 20 unique words for each source-topic combo, found using tf-idf amongst all other sources on that given topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de6bd5-8817-46d1-b9ca-2a15318abb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_tfidf_topwords_alltopics(exploded_df, group_cols, top_n=20, extra_stopwords=None, compute_all_topics=True):\n",
    "    # define stopwords\n",
    "    stopwords = ENGLISH_STOP_WORDS\n",
    "    if extra_stopwords:\n",
    "        stopwords = list(stopwords.union(set(extra_stopwords)))\n",
    "    else:\n",
    "        stopwords = list(stopwords)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # calculation by topic\n",
    "    topics = exploded_df[\"topic\"].unique()\n",
    "    for topic in topics:\n",
    "        df_topic = exploded_df[exploded_df[\"topic\"] == topic]\n",
    "        groups = df_topic.groupby(group_cols)\n",
    "        corpus = groups[\"text\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "        if len(corpus) < 2:\n",
    "            continue\n",
    "\n",
    "        vectorizer = TfidfVectorizer(stop_words=stopwords, max_features=5000)\n",
    "        tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "        for idx, group in enumerate(corpus.index):\n",
    "            scores = tfidf_matrix[idx].toarray().flatten()\n",
    "            top_indices = scores.argsort()[::-1][:top_n]\n",
    "            # only include positive scores!\n",
    "            words_scores = [\n",
    "                (feature_names[i], float(scores[i]))\n",
    "                for i in top_indices if scores[i] > 0\n",
    "            ]\n",
    "            words = [w for w, s in words_scores]\n",
    "            words_scored = [{\"text\": w, \"value\": s} for w, s in words_scores]\n",
    "            group_dict = {col: val for col, val in zip(group_cols, group if isinstance(group, tuple) else (group,))}\n",
    "            group_dict['topic'] = topic\n",
    "            results.append({\n",
    "                **group_dict,\n",
    "                'top_words': words_scored,\n",
    "                'top_words_plain': words\n",
    "            })\n",
    "\n",
    "    # calculation now for ALL topics\n",
    "    if compute_all_topics:\n",
    "        group_cols_no_topic = [col for col in group_cols if col != \"topic\"]\n",
    "        if group_cols_no_topic:\n",
    "            groups = exploded_df.groupby(group_cols_no_topic)\n",
    "            corpus = groups[\"text\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "            if len(corpus) >= 2:\n",
    "                vectorizer = TfidfVectorizer(stop_words=stopwords, max_features=5000)\n",
    "                tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "                feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "                for idx, group in enumerate(corpus.index):\n",
    "                    scores = tfidf_matrix[idx].toarray().flatten()\n",
    "                    top_indices = scores.argsort()[::-1][:top_n]\n",
    "                    words_scores = [\n",
    "                        (feature_names[i], float(scores[i]))\n",
    "                        for i in top_indices if scores[i] > 0\n",
    "                    ]\n",
    "                    words = [w for w, s in words_scores]\n",
    "                    words_scored = [{\"text\": w, \"value\": s} for w, s in words_scores]\n",
    "                    group_dict = {col: val for col, val in zip(group_cols_no_topic, group if isinstance(group, tuple) else (group,))}\n",
    "                    group_dict[\"topic\"] = \"all_topics\"\n",
    "                    results.append({\n",
    "                        **group_dict,\n",
    "                        \"top_words\": words_scored,\n",
    "                        \"top_words_plain\": words\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c1fa2d-597d-4182-a4eb-1ae6632f25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying this now:\n",
    "topwords_df = precompute_tfidf_topwords_alltopics(\n",
    "    exploded_df=exploded,\n",
    "    group_cols=[\"source_type\", \"source_name\"],\n",
    "    top_n=20,\n",
    "    extra_stopwords=extra_stopwords)\n",
    "\n",
    "topwords_type_df = precompute_tfidf_topwords_alltopics(\n",
    "    exploded_df=exploded,\n",
    "    group_cols=[\"source_type\"],\n",
    "    top_n=20,\n",
    "    extra_stopwords=extra_stopwords)\n",
    "\n",
    "topwords_type_df = topwords_type_df.copy()\n",
    "topwords_type_df[\"source_name\"] = topwords_type_df[\"source_type\"]\n",
    "\n",
    "topwords_all_df = pd.concat([topwords_df, topwords_type_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f20c89-9c81-438c-8e48-e6a2f03b2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topwords_all_df.columns)\n",
    "print(avg_sentiment_all.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb34b081-dbc2-4bed-ba02-f520c13278a2",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3483d-67d1-4d59-98fd-8d377840ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "topwords_all_df.to_parquet(\"data/topwords_by_topic.parquet\", index=False)\n",
    "avg_sentiment_all.to_csv(\"data/avg_sentiment_by_source_topic.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
