
Race. The Rudder Race. The Sails race. The Sails Captain. An Unidentified ship is Approaching Over. Roger, wait. Is that an enterprise sales solution? Reach sales professionals, not professional sailors. With LinkedIn ads, you can target the right people by industry job title and more. We'll even give you a $100 credit on your next campaign. Get started today at LinkedIn dot com slash results. Terms and conditions apply.


Ryan Reynolds here from Mint Mobile. The message for everyone paying big wireless way too much. Please. For the love of everything, goodness world, stop with mint. You can get premium wireless for just $15 a month. Of course, If you enjoy overpaying, no judgements, but that's weird. Okay, one judgment. Anyway, give it a try at Mint Mobile dot com slash switch Upfront payment of $45 for three month plan equivalent to $15 per month for required intro rate for three months only. Then full price. Plan options available. Taxes and fees extra. See full terms at Mint Mobile dot com.


Hello, I'm Joanna Coles, chief Content Officer of the Daily Beast and the co-host of the Daily Beast Podcast Spring here. It's the perfect time to refresh my space. That's why I love Brooklyn and they make high quality sheets, comforters, and throw blankets that look and feel amazing every night feels like luxury. Shop award winners and fan faves in store or online@brooklyninn.com. That's B-R-O-O-K-L-I-N-E n.com and get 15% off your first order today.


Hey, TED Talks Daily listeners, I'm Elise Hugh. Today we have an episode of another podcast from the TED Audio Collective handpicked by us for you organizational psychologist. Adam Grant is one of Ted's most beloved speakers and In his podcast Rethinking he talks to some of the world's most renowned scientists, entrepreneurs, and creatives about how they think. In this episode, Adam has an expansive conversation with Open AI, CEO, Sam Altman, Adam, and Sam. Discuss the advances AI has made in creativity. Consider the ethical challenges that this technology poses and debate the role of human oversight in developing these tools. To hear more deep conversations with Adam, you can find rethinking wherever you get your podcasts.


Learn more about the TED Audio Collective at audio collective dot TED dot com. Now onto the episode right after a quick break.


Support for the show comes from Mint Mobile. I don't know about you, but I like keeping my money where I can see it. Unfortunately, traditional big wireless carriers seem to like keeping my money too. After years of overpaying for wireless, I finally got fed up and switched to Mint Mobile. It was a great option for us because my daughter recently got her first phone and we weren't really loving the high prices and pointless perks offered by the big wireless carriers. Thankfully, Mint Mobile rescued us offering premium wireless plans for her starting at just $15 a month. They're here to rescue you two. All plans come with high suite data and unlimited talk and tax delivered on the nation's largest 5G network. Ditch overpriced wireless and get three months of premium wireless service from Mint Mobile for 15 bucks a month like my family did. If you like your money, Mint Mobile is for you. Shop plans at Mint Mobile dot com slash talks. That's Mint Mobile dot com slash talks. Upfront. Payment of $45 for three month five gigabyte plan required equivalent to $15 a month. New customer offer for first three months only. Then full price plan options available. Taxes and fees, extras. See Mint Mobile for details.


Does it ever feel like you're a marketing professional just speaking into the void, void? Well, with LinkedIn ads, you can know you're reaching the right decision makers. You can even target buyers by job title, industry, company, seniority skills. Wait, did I say job title yet? Get started today and see how you can avoid the void and reach the right buyers with LinkedIn ads. We'll even give you a $100 credit on your next campaign. Get started at LinkedIn dot com slash results. Terms and conditions apply.


One of the surprises for me about kind of this trajectory OpenAI has launched onto since the launch of Chachi BT is how many things can go wrong by one o'clock in the afternoon? Hey everyone, it's Adam Grant. Welcome back to rethinking my podcast on the science of what makes us Tick with the TED Audio Collective. I'm an organizational psychologist and I'm taking you inside the minds of fascinating people to explore new thoughts and new ways of thinking. My guest today is Sam Altman, CEO and co-founder of OpenAI. Since Sam and his colleagues first dreamed up chat GPT, a lot has changed. You and I are living through this once in human history transition where humans go from being the smartest thing on planet earth to not the smartest thing on planet earth.


The exponential progress of AI has made me rethink many of my assumptions about what's uniquely human and raised far more questions than answers. Since the source code is a black box, I figured it was time to go to the source himself. Having crossed paths with Sam at a few events, I've appreciated his willingness to think out loud instead of just sticking to scripted talking points even when his opinions are unpopular. I suspect that in a couple of years on almost any topic, the most interesting, maybe the most empathetic conversation that you could have will be with an ai. Sam Altman does his own tech check. How did that happen?


You know, I don't know. It's Fine. There's no handler here. Sometimes I have to start where I'm sure many conversations have kicked off over the past year, which is what did it feel like to be fired from your own company? This Like surreal haze. The confusion was kind of the dominant first emotion. Then there were like I went through everything but confusion was the first one And then Then like frustration, anger, sadness, gratitude, I mean it was everything. Wow, That 48 hours was like a full range of human emotion. It was like impressive in the breath. What did you do with those emotions in that, in that 48 hours? Honestly, there was so much due just like tactically that there was not a lot of time for like dealing with any emotions.


So in those 48 hours, not much. And then it was like hard after when the dust was settling and I had to like get back to work in the midst of all of this. I remember Steve Jobs saying years later after he was forced out of Apple that it was awful tasting medicine, but I guess the patient needed it. Is that relatable in any way or is this situation just too different? Maybe it hasn't been long enough. I have not reflected deeply on it recently. I think it was so different from the Steve Jobs case in all of these ways and it was also just so short. The whole thing was like totally over in five days this like very strange fever dream and then like back to work, picking up the pieces, I guess five days versus a decade is a slightly different learning curve, right? What, what did you learn lesson and wise?


I Actually, maybe I was wrong. Maybe it was only four days, I think it was four days. I learned a bunch of stuff that I would do differently next time about how we communicated during and after that process and like the need to just sort of be direct and clear about what's happening. I think there was this like cloud of suspicion over OpenAI for a long time that we could have done a better job with. I knew I worked with great people, but seeing how good the team was in a crisis and in a stressful situation with uncertainty, one of the proudest moments for me was watching the executive team kind of operate without me for a little while and knowing that any of them would be perfectly capable of running the company and I felt a lot of pride both about picking those people, about teaching them to whatever degree I did and just that the, the company was in a very strong place.


I'm surprised to hear you say that I, I had assumed your proudest moment would've been just the sheer number of employees who stood behind you. I, I thought as an organizational psychologist that was staggering to see the outpouring of loyalty and support from inside. It did feel nice, but that's not the thing that like sticks in. I remember feeling like very proud of the team but not for that reason. Well, I guess that's also very jobsian then when he was asked what his proudest achievement was, it wasn't the Mac or the iPod or the iPad, it was the team that built those products. I don't do the research, I don't build the products. I make some decisions, but not most of them. The thing I get to build is the company. So that is certainly the thing I have pride of authorship over. So what do you actually do?


Like how do you spend your time? It's a great question. On any given day it's pretty different and fairly chaotic somehow. The early mornings are never that chaotic, but then it often like all goes off the rails by the afternoon and there's all of this, this stuff that's happening and you're kind of in reaction mode and firefighting mode. So I've learned to get the really important things done early in the day. I spend the majority of my time thinking about research and the products that we build and then less on everything else. But what that could look like at any given time is very different. So One of the things that that I've been very curious about as I've watched you turn the world upside down in the last couple years is like what, what's gonna happen to humans? I've been tracking what I think is the most interesting research that's been done so far and humans are losing a lot faster than I hoped a lot faster.


So I think we're already behind on creativity, on empathy, on judgment, on persuasion and I want to get your reactions to some data points in each of those areas. But first like just your commentary on the overall, are you surprised by how quickly AI has surpassed a lot of human capabilities? Our latest model feels smarter than me in almost every way and it doesn't really impact my life Really. I still care about the same kinds of things as before I can work a lot more effectively. I assume as society digest this new technology society will move much faster. Certainly scientific progress I hope will move much faster and we are coexisting with this amazing new artifact tool, whatever you wanna call it.


But how different does your day-to-day life feel now from a few years ago? Kind of not that different. I think that over the very long term AI really does change everything, but I guess what I would've naively thought a decade ago is the day that we had a model as powerful as our most powerful model. Now everything was gonna change and now I think that was a naive take. I I think this is the the standard like we overestimate change in the short run. Right, and underestimate it in the long run. Right, exactly. So you're living a version of that Eventually I think the whole economy transforms. We'll find new things to do. I have no worry about that. We will, we always find new jobs even though every time we stared on a new technology we assume they're all gonna go away.


It's true that some jobs go away, but we find so many new things to do and hopefully so many better things to do. I think what's gonna happen is this is just the next step in a long unfolding exponential curve of technological progress. I think in some ways the AI revolution looks to me like the opposite of the internet because back then people were running companies, they didn't believe that the internet was gonna change the world and their companies died because they, they didn't make the changes they needed to make. But the people who bought in it was really clear what the action implications were like, I need to have a functioning website. I needed to know how to sell my products through that website, right? It was not rocket science to adapt to the digital revolution. What I'm hearing right now from a lot of founders and CEOs is the reverse, which is everybody believes that AI is game changing and nobody has a clue what it means for leadership, for work, for organizations, for products and services.


Like they're all in the dark In that sense. It's more like the industrial revolution than the internet revolution. There are huge known unknowns of how this is gonna play out, but I think we can say a lot of things about how it is gonna play out too. I wanna hear those things. A couple hypotheses that that I have. One is that we're gonna stop valuing ability and start valuing agility in humans. There Will be a kind of ability we still really value, but it will not be raw, intellectual horsepower to the same degree. And What do you think the new ability is that matters? I mean the like kind of dumb version of this would be figuring out what questions to ask will be more important than figuring out the answer That's consistent with what I've seen even just in the last couple years, which is we used to put a premium on how much knowledge you had collected in your brain and If you were a fact collector that made you smart and respected and now I think it's much more valuable to be a connector of dots than a collector of facts that If you can synthesize and recognize patterns, you have an edge.


You Ever watch that TV show Battlestar Galactica? One of the things they say again and again in the show is all this happened before all this will happen again. And when people talk about the AI revolution, it does feel different to me in some super important qualitative ways. But also it reminds me of previous technological panics. When I was a kid, this thing came out, new thing launched on the internet, I thought it was cool. Other people thought it was cool. It was clearly way better than the stuff that came before. I was not quite old enough yet for this happened directly to me. But the older kids told me about it. The teachers started banning the Google because Did they call it the Google, the Google? If you could just look up every fact then what was the purpose of going to history class and memorizing facts?


We were gonna lose something so critical about how we teach our children and what it means to be a responsible member of society. If and If you could just look up any fact instantly, you didn't even have to like fire up the combustion engine, drive to the library, look in the card catalog, find a book, it was just there. It felt unjust, it felt wrong, it felt like we were gonna lose something, we were gonna do that. And with all of these, what what happens is like we get better tools, expectations go up, but so does what someone's capable of and we just learn how to do more difficult, more impactful, more interesting, whatever things. And I expect AI to be like that too. If you asked someone a few years ago, a will there be a system as powerful as oh one in 2024 and B, if an Oracle told you you were wrong and there will be, how much would the world change?


How much would your day-to-day life change? How would we face an existential risk or whatever. Almost everybody you asked would've said, definitely not on the first one, but if I'm wrong and it happens like we're pretty fucked on the second and yet this amazing thing happened and here we are. So in the realm of innovation, there's a new paper by Aiden Toner Rogers, which shows some great news for r and d scientists that when they're AI assisted, they file 39% more patents and that leads to 17% more product innovation. And a lot of that is in radical breakthroughs, novel chemical structures being discovered and the major gains are for top scientists, not bottoms. There's very little benefit If you're in the bottom third of scientists, but the productivity of the top ones almost double.


And that doubling seems to be because AI automates a lot of idea generation tasks and it allows scientists to focus their energy on idea valuation where the great scientists are really good at recognizing a promising idea and the bad ones are vulnerable to false positives. So that's all good news, right? You incredible unlocking of scientific creativity. But it comes with a cost, which is in the study, 82% of scientists are less satisfied with their work. They feel they get to do less creative work and their skills are underutilized. And it seems like humans are in that, in that case are being reduced to judges as opposed to creators or inventors. I would love to know how you think about that evidence and what, what do we do about that?


I have two conflicting thoughts here. One of the most gratifying things ever to happen at OpenAI for me personally is as we've released these new reasoning models, we give them to great legendary scientists, mathematicians, coders, whatever, and ask what they think and hearing their stories about how this is transforming their work and they can work in new ways. I have certainly gotten the greatest professional joy from having to really creatively reason through a problem and figure out an answer that no one's figured out before. And when I think about AI taking that over, if it happens that way, I do feel some sadness. What I expect to happen in reality is just there's gonna be a new way we work on the hard problems and it's being an active participant in solving the hardest problems that brings the joy.


And if we do that with new tools that augment us in a different way, I kind of think we'll adapt, but I'm uncertain. What does that look like in your job right now? Like how do you, how do you use chat GPT for example in solving problems that you face at work? Honestly, I use it in the boring ways and I use it for like, you know, help me process all of this email or help me summarize this document. Or they're just the, the very boring things. It sounds like then you're, you're hopeful that we'll adapt in ways that allow us to still participate in the creative process. I am hopeful that's so deeply the human spirit and the way I think this all continues kind of no matter what, but it will have to evolve and it will be somewhat different. Another Domain where I expected humans to have an edge much longer than, than we've stuck it out so far is empathy.


My favorite experiments that I've read so far basically show that if you're having a a text conversation and you don't know whether it's a human or a chat GPT and then afterward you're asked how seen did you feel? How heard did you feel? How much empathy and support did you get? You feel that you got more empathy and support from AI than you did from a human unless we tell you it was AI and then you don't like it anymore. Right? I look at that evidence as a psychologist and I have a couple reactions. One is I think it's not that AI is that good at empathy, it's that our default is humans is pretty bad and poor, right? We slip into conversational narcissism way too quickly where somebody tells us a problem and we start to relate it to our own problem as opposed to showing up for them. So I think maybe that's just a, an indictment of human empathy having a poor baseline.


But also I wonder how long like this, I don't want it if I know it's from an AI is gonna last as we start to humanize and anthropomorphize this tech more and more. Let Me first talk about the sort of general concept of people sometimes preferring the actual output of something if it's ai, until they're told that it's AI and then they don't like it. That you see that over and over again. I saw a recent study that even among people who claimed that they really hated AI art the most, that the scale that you choose, they still selected more output of AI than humans for the pieces of art they liked the most until they were told, which was AI and which wasn't. And then of course it was different.


We could pick many other examples, but this trend that AI has in many ways caught up to us and yet we are hardwired to care about humans and not ai I think is a very good sign. We're all in speculation here and I'll, so I'll say I have a very high uncertainty on all of this, but although you'll probably talk more to an AI than you do today, you will still really care about when you're talking to a human that this is something very deep in our biology and our evolutionary history and our social functioning, whatever you wanna call it. Why do you think we will still want human connection? It sounds like a version of the Robert Nok argument that led to the matrix of people preferring real experience over sort of simulated pleasure.


Do you think that's what we're craving? We just want the real human connection, even if it's flawed and messy, which of course AI is gonna learn to simulate too. I Think you'll find very quickly that talking to a flawless, perfectly empathetic thing all of the time you miss the drama or the tension or what I I I, there'll be something there. I think we're just so wired to care about what other people think feel how they view us. And I don't think that translates to an ai. I think you can have a conversation with an AI that is helpful and that you feel validated and it's a good kind of entertainment in a way that playing a video game is a good kind of entertainment but I don't think it fulfills the sort of social need to be part of a group and a society in a way that is gonna register with us.


Now I might be wrong about this and maybe AI can so perfectly hack our psychology that it does and I'll be really sad if that's the case. Yeah, me too. You're right. It's hard foris to substitute for belonging. It's also hard to get status from a bot, right? To feel important or cool or respected in ways that like we rely on other human eyeballs and ears for That was kind of what I was trying to get at. I can imagine a world soon where ais are just like unbelievably more capable than us and doing these amazing things and when I imagine that world and I imagine the people in it, I imagine those people still caring about the other people quite a lot still thinking about relative status and sort of these silly games relative to other people.


Quite a lot, only many people are gonna be measuring themselves against you know, what the AI is doing and capable of. So one of the things that I've been really curious about is in a world where information is increasingly contested and and facts are, are harder and harder to, to persuade people of, we see this for example in the data on conspiracy theory beliefs like people believe in conspiracies because it makes them feel special and important and like they have access to knowledge that other people don't. That's not the only reason of course, but it's one of the driving reasons and what that means is it's really hard for another human to talk them out of those beliefs because they're kind of admitting that they're wrong. And I was fascinated by a recent paper, this is Costello Penny Cook and Rand, they showed that If you have a single conversation with an AI chat bot, it can even months later basically get people to unbelief a bunch of their conspiracy theories.


It starts by essentially just targeting a false claim that you believe in. Yeah and debunking it. And I think it works in part because it's responsive to the specific reasons that you have attached to your belief and in part because like nobody cares about looking like an idiot in front of a machine like they do a human. And not only do people, I think about 20% of of people let go of their absurd conspiracy beliefs, but also they let go of some other beliefs that the AI didn't even target. And so I think that that door opening is very exciting. Obviously this can be used for evil as well as good, but I'm really curious to hear about what, what your take is on this newfound opportunity. We have to correct people's misconceptions with these tools.


Yeah, there are people in the world that can do this that can kind of expand our mind in some way or other and it's very powerful. There're just not very many of them and it's a rare privilege to get to Talks, Odoo them. If we can make an AI that is like the world's best dinner party guest, super interesting, knows about everything, incredibly interested in you and takes the time to like understand where they could push your thinking in a new direction. That seems like a good thing to me. And I've also had this experience with AI where I, I had the experience of talking to a real expert in an important area and that changing how I think about the world, which for sure there is some human that could have done that but I didn't happen to be with him or her.


Right. Then it Also obviously raises a lot of questions about the hallucination problem and accuracy. As an outsider it's really hard for me to understand why this is such a hard problem. Can you explain this to me in a way that that will make sense to somebody who's not a computer scientist? Yeah, I think a lot of people are still stuck back in the GPT-3 days ancient history back in 2021 when none of this stuff worked really, it did hallucinate a lot. If you use the current chat GBT, it still hallucinates some for sure, but I think it's like surprising that it's generally pretty robust. We train these models to make predictions based off of all the words they've seen before. There's a bunch of wrong information in the training set. There's also sometimes cases where the model fails to generalize like it should.


And teaching the model when it should confidently express that it doesn't know versus you know, like make its guess is still an area of research but it's getting a lot better. And with our new reasoning models there's a big step forward there too. I've prompted chat GPT in various iterations like is this true? Can you please make sure this is an accurate answer that should be built in as you know, as a required step in the iteration. So is that where we're heading? Then that that just becomes an automatic part of the process. I think that will become part of the process. I think there will be a lot of other things that make it better too, but that will be part of the process. There's some brand new research and there have been a bunch of these kinds of studies over the last year or two, but the one that that sort of blew my mind this past week was that when you compare AI alone to doctors alone, of course like AI wins, but AI also beats doctor AI teams.


And my read of that evidence is that like doctors aren't benefiting from AI assistance because they override the AI when they disagree. You See versions of this throughout history, like when AI started playing chess, there was a time where humans were better then there was a time when theis were better and then for some period of time, I forget how long the AI plus humans working together were better than AI alone because they could sort of bring the different perspectives. And then there came a time where the AI was again better than an AI plus a human because the human was overriding and making mistakes where they just didn't see something. If you view your role as to try to override the AI in all cases, then it turns out not to work.


On the other hand, the second thing I think we're just early in figuring out how humans and AI should work together. The AI is gonna be a better diagnostician than the human doctor and that's probably not what you wanna fight, but there will be a lot of other things that the human does much better or at least that the people, the patients want a person to be doing. And I think that'll be really important. I've been thinking about this a lot. I'm expecting a kid soon, my kid is never gonna grow up being smarter than ai. The world that you know, kids that are about to be born, the only world they will know is a world with AI in it and that'll be natural. And of course it's smarter than us, of course it can do things we can't, but also who really cares? I think it's only weird for us in this one transition Time in some ways that's a force for humility, which I think is a good thing.


On the other hand, we don't know how to work with these tools yet, right? And maybe some people are getting a little too dependent on them too quickly. You know, I can't spell complicated words anymore because I just trust that autocorrect will save me. I feel fine about that. It's easy to have moral panics about these things even if people are more dependent on their AI to like help them express thoughts. Maybe that is just the way of the future. I've seen students who don't wanna write a paper without having chat GPT handy because like they've gotten rusty on the task of rough drafting and they're used to outsourcing a lot of that and then having raw material to work with as opposed to having to generate something in front of a blank page or a blinking cursor. And I, I do think there is a little bit of that, that dependency that's building.


Do you have thoughts on, on how we prevent that or is that just the future and we ought to get used to it? I'm Not sure that is something we should prevent. For me writing is outsourced thinking and very important, but as long as people replace a better way to do their thinking with a new kind of writing that seems directionally fine. One of the sad things about getting more well known is if I don't phrase everything perfectly for very little benefit to me or to open ai, I just like open up a ton of attacks or or whatever. And that is a bummer. I I do think that is, that is a privilege. You, you lose the ability to just riff and play with ideas publicly and and be partially wrong or have incomplete thoughts. Mostly Wrong, mostly wrong with some gems in there.


I Mean that being said, like some of us are grateful that you're a little more circumspect than some of your peers who don't exercise any self-reflection or self-control. Well That's a different thing. Like there's also something about just like being a thoughtful, somewhat careful person, which yes, I think more people should do. The thing I think is really silly, a reasonably common workflow is that someone will write the bullet points of what they wanna say to somebody else, have chat GBT, write it into a nice multi-paragraph email, send it over to somebody else. That person will then put that email in chat GBT and say, tell me what the three key bullet points are. And so I think there is some vestigial formality of writing and communication or whatever that probably doesn't still have a lot of value.


And I'm fine to get to a world where the social norms evolve that everybody can just send each other the bullet points. I really want a watermark or at least some internal memory where like chat PT can say back, hey, like this was already generated by me and like you should go back and tell this person you wanted bullet points so that you all can communicate more clearly in the future. In part what's going on is, is a lot of people are, are slow to adapt to the tools. We are seeing some really interesting human ingenuity. So the the evidence that that jumps to mind for me is a a, a study by Sharon Parker and her colleagues. This is in the, the realm of robotics technology. So they go into a manufacturing company that's essentially starting to replace humans with robots and instead of getting panicked that people are no longer gonna have gonna have jobs.


A bunch of employees say, well we need to find a unique contribution, we need to have meaning at work. And they get that by outsmarting the robots, like they study the robots, they figure out what they suck at and then they're like, okay, we are gonna make that our core competence. Now this, I think the scary thing with oh one and the advances in reasoning is that like a lot of the skills that we thought would differentiate us last year are now already obsolete, right? Like the the prompting tricks that a lot of people were using in 2023 are no longer relevant and some of them are, are never gonna be necessary again. So what, what are humans gonna be for in 50 or a hundred or a thousand years? No one knows. But I think the more interesting answer is what is a human useful for today?


And I would say being useful to other people and I think that'll keep being the case. A thing that someone said to me, this was Paul Buhe many, many years ago that really stuck with me is he had been thinking and thinking and thinking this is like before open AI started, he thought that someday there was just gonna be human money and machine money and they were gonna be completely separate currencies and one wouldn't care about the other other. I don't expect that to be literally what happens, but I think it's a very deep insight. Fascinating. I've never thought about machines having their own currency. You Will be thrilled that the AI has invented all of the science for you and cured disease and you know, made fusion work and just impossible triumphs. We can't imagine. But will you care about what N AI does versus what some friend of yours does or some person running some company does?


I don't know. Probably not that much. No. Like maybe some people do. Maybe there's like some really weird cults around particular ais and I will bet we'll be surprised. The degree to which we're still very people focused


Support for this podcast comes from Odoo. Imagine relying on a dozen different software programs to run your business, none of which are connected and each one more expensive and more complicated than the last. It can be pretty stressful. Now imagine Odoo Odoo has all the programs you'll ever need and they're all connected on one platform. Doesn't Odoo sound amazing? Let Odoo harmonize your business with simple efficient software that can handle everything for a fraction of the price. Sign up today at Odoo dot com. That's Odoo dot com.


Does it ever feel like you're a marketing professional just speaking into the void, void? Well with LinkedIn ads you can know you're reaching the right decision makers. You can even target buyers by job title, industry, company, seniority skills, wait did I say job title yet? Get started today and see how you can avoid the void and reach the right buyers with LinkedIn ads. We'll even give you a $100 credit on your next campaign. Get started at LinkedIn dot com slash results Terms and conditions apply.


Okay, I think it might be time for a lightning round. This Is me in like GBT four mode instead of a one mode where I just have to like one shot it, you know, as quickly as I can. I'll put the next token first Question is, what's something you've rethought recently on AI or changed your mind about? I think a fast takeoff is more possible than I thought a couple of years ago. How fast Feels hard to reason about but something that's in like a small number of years rather than a decade. Wow. What do you think is the worst advice people are given on adapting to ai? AI is hitting a wall, which I think is the laziest fucking way to try to not think about it and just, you know, put it out of sight, out of mind. What's your favorite advice on how to adjust or what advice would you give on how to adapt and succeed in an AI world?


This is so dumb, but the obvious thing is like just use the tools. One thing that OpenAI does that I think is really cool, we put out the most powerful model that we know of that exists in the world today oh one and anybody can use it If you pay us 20 bucks a month, If you don't wanna pay us 20 bucks a month, you can still use a very good thing it's out there like the the leading edge, the most capable person in the world and you can access the exact same frontier and I think that's awesome And so go use it and figure out what you like about it, what you don't, what you think is gonna happen with it. What's your hottest hot take or unpopular opinion on AI That it's not gonna be as big of a deal as people think, at least in the short term, long term everything changes. I kind of genuinely believe that we can launch the first A GI and no one cares that much.


People in tech care and philosophers care, those are the, those are the two, two groups I've I've heard react consistently And even then they care. But like 20 minutes later they're thinking about what they're gonna have for dinner that night. What's a question you have for me as an organizational psychologist? Oh, What advice do you have for open AI about how we manage our collective psychology as we kind of go through this crazy super intelligence takeoff, like how do we keep the people here sane, for lack of a better word. We're not really in the like super intelligence part of the takeoff, but I imagine as we go through that it'll just feel like this unbelievably high stakes, immensely stressful thing. I mean even now as we're in sort of the A GI ramp, it feels a little bit like that. I think we need much more organizational resilience for what's to come.


And when you think about organizational resilience, what does that look like? Does that mean people are not as stressed as they're likely to become? Does that mean they're able to roll more quickly with change than they might naturally Good decisions in the face of incredible incredibly high stakes uncertainty and also adaptability as the facts on the ground and thus the actions that we need to consider or to take change at a very rapid rate? I think for me the place to start on that is, is to draw a two by two and ask everybody at open AI to think about how consequentially each choice they make is, how high are those stakes and then how reversible is each choice? Are they walking through a a revolving door or is it gonna lock behind them?


And I think where you really have to slow down and do all of your thinking and rethinking upfront is the highly consequential, irreversible decisions because they really matter and you can't undo them tomorrow. I think the other three quadrants is fine to act quickly, experiment, pilot, stay open to doubting what you think. But that quadrant is where it's really important to get it right and that's where I want people to put their best thinking and and probably their best prompting. Makes sense. So I wanna ask you about something you wrote. You did a a blog about how to be successful So long ago. It was a long time ago. I Don't have that loaded in memory anymore. That's okay. I have it right here. There was one section of it that I thought was particularly fascinating on self-belief, so I'll quote you to you here you wrote, self-belief is immensely powerful.


The most successful people I know believe in themselves almost to the point of delusion, cultivate this early as you get more data points that your judgment is good and you can consistently deliver results, trust yourself more. Do you still agree with that? I think so. It's hard to overstate. When we were starting OpenAI we believed this thing that was like right about the time of like maximum skepticism in OpenAI relative to what? On the outside relative to what we believed inside. And I think my most important contribution to the company in that phase was that I, I just kept reminding people like look the external world hates anything new. Hates anything that like might go in a different direction than established belief. And so people are saying all of these crazy negative things about us and yet we have this incredible progress and I know it's early and I know we have to suspend disbelief to believe it'll keep scaling but it's been scaling so let's push it ridiculously far And now it seems so obvious but at the time I truly believe that had we not done that, it might not have happened for a long time because we were the only people that had enough self-belief to go do what, what seemed ludicrous, which was to spend a billion dollars scaling up a GPT model.


So I think that was important. I think It's all true. I think it's also scary because those same people are the ones when they believe in themselves to the point of delusion or almost delusion who make terrible decisions outside of their domains of expertise. And I think, I think if I were gonna modify what you wrote, I would say as you get more data points that your judgment is good in a given domain. Yes, yes. Then you should trust yourself in that domain more. That would've been a much better way to phrase it. I don't think it's true that experience and ability doesn't generalize at all. But many people try to generalize it too much. I should have said something about like in your area of expertise, but there's nuance because I also think you should be willing to like do new things.


You know I was a investor and not a AI lab executive, you know, six or seven years ago. It also really matters whether you're in a stable or dynamic environment because you can trust your judgment that's based on intuition in a stable environment because you have subconsciously internalized patterns of the past that are still gonna hold in the future. Whereas if you're in a more volatile setting, oftentimes your, your gut feeling is essentially trained on data that don't apply right In that world I think you wanna get even more towards the like really core underlying principles that you believe in and that work for you because yeah, even more valuable. The last topic that I wanted to, to talk with you about his ethics, I know this is also something you've been thinking a lot about, talking a lot about this is the domain in which most people are most uncomfortable outsourcing any kind of judgment to ai.


Me too Good. And I think this is where we have to rely on humans at the end of the day I'm hearing a lot of nuclear deterrence kinds of metaphors of like okay what we need is we need a race ahead of bad actors and then we'll have mutually assured destruction like wait a minute, like the arms race metaphor doesn't work here because a lot of the bad actors are not state actors and they don't, they don't face the same risk or consequences. And then also like now we're gonna trust a private company as opposed to elected officials. This feels very complicated and like it doesn't map. So Talks Odoo me about that and how you're thinking about the, the ethics and safety problems. First of all, I think humans have gotta set the rules like AI can follow them and we should hold ais to following whatever we collectively decide the rules are.


But humans have gotta set those. Second, I think people seem incapable not to think in historical analogy and I understand that and I don't think it's all bad, but I think it's kind of bad because the historical examples just are not like the future examples. So what I would encourage is people to ground the discussion as much as they can in what makes AI different than anything before, based off what we know right now, not kind of wild speculation and then trying to design a system that works for that. One thing that I really believe is deploying AI is a tool that significantly increases individual ability. Individual will, whatever you wanna call it, is a very good strategy for our current situation and better than one company or adversary or person or whatever kind of using all the AI power in the world today.


But I will also cheerfully admit that I don't know what happens as the AI become more agentic in the big way. Not like we can go give them a task where they program for three hours, but where we can have them go off and do something very complicated that would normally require like a whole organization over many years. And I suspect we'll have to figure out new models again, I don't think history will serve us that well. No, it frankly hasn't in the software world. I think that like any other technology that's powerful is regulated in the US and I think, you know, it seems like the EU might be a little bit more competent when it comes to Congress. I think what the EU is doing with AI regulation is not helpful for another reason. Like for example when we finish a new model we can launch it even if it's not that powerful, we can launch it in the US well before we can launch it in the eu 'cause there's a bunch of regulatory process and what if that means that the EU is always some number of months behind the frontier.


I think they're just gonna build less fluency and economic engine and understanding and kind of whatever else you wanna put in that direction. It's really tricky to get the regulatory balance right And also we clearly in my opinion, will need some, what Worries you the most when you look ahead in the next decade or so? I think just the rate of change. I, I really believe in the sort of human spirit of solving every problem, but we got a lot to solve pretty quickly here. One of the other things that I've been grappling with when I think about ethics and future impact is we thought so many digital technologies were gonna be democratizing and we thought they were going to, you know, sort of prevent or at least chip away at inequality.


And very often it's been the opposite that the rich have gotten richer because they have had better access to these tools. Now you pointed out that oh one is is pretty cheap by American standards. There's still I think an access discrepancy. What is it gonna take to change that? What does it look like for AI to be a force for good in the developing world? We've been able To drive the price per unit of intelligence down by roughly a factor of 10 every year. You can't do that for that much longer. No, but we've been doing it for a while and I think it's amazing how cheap intelligence has gotten, I guess in some ways though that that works against the problem of, well at least right now, like the only players that can afford to make really powerful models are governments and huge companies that are accountable For now to train it.


Yes. Yeah. But to use it is very different. So As you sit back and look at the last, I mean three years, it's gotta be like you've gone through a lifetime of change. It's been weird. Why are you doing this? I guess is one way to put It. I am a techno optimist and science nerd and I think it is the coolest thing I could possibly imagine and the best possible way I could imagine spending my work time to get to be part of what I believe is the most interesting, coolest, important scientific revolution of our lifetimes. So like what a fucking privilege. Unbelievable. And then on the kind of like non-self reason, I feel a sense of duty to scientific progress as a way that society progresses and of all of the things that I have a personal capacity to contribute to or maybe just of all of the things, this is the one that I believe will drive scientific progress and thus standards of living the quality of the human experience, whatever you wanna call it, forward the most.


And I feel a sense of duty, but not in a negative sense like a, a duty with a lot of gratitude for holding it that I get to contribute in whatever way Sounds like responsibility. Sure. With a, with a child on the way as a soon to be father, what kind of world are you hoping to see for the next generation? Abundance was the first word that came to mind. Prosperity was the second. But you know, generally just a world where people can do more, like be more fulfilled, live a better life. However we define that for each of ourselves, all the all those things. Probably the same thing every other soon to be dad has ever wanted for his kid. I've certainly never been so excited for anything. And I think it's also like no one should have a kid that doesn't wanna have a kid. So I don't wanna use the word duty here, but society is dependent on some people having some kids, At least for now.


At least for now. I don't think I've, I've heard you express as strongly as you did today, how much you're also a believer in humans, not just in technology. And I think in some ways that's a risky place to operate. Like we've seen that with social media, but I think it's also like it is table stakes when it comes to building technology is you have to care about and believe in. I Skew optimistic even though I try to just be accurate. But if there's being too optimistic about technology, like whatever, if you're too optimistic about humans, that could be a danger for us. If we put these tools out and we're like, yeah, people will use it for way more good than bad and we're just somehow really wrong about human nature, that would be a flaw with our strategy. But I don't believe that. Well, fingers are crossed.


Sam, thank you for taking the time to do this. I learned a lot and thoroughly enjoyed it. Thanks for Having me. This was fun. Was it? You be the judge. My biggest takeaway from this conversation with Sam is that technological advances may be unstoppable, but so is human adaptation. Machines can replace our skills but they won't replace our value or our values. Rethinking is hosted by me. Adam Grant, the show is part of the TED Audio Collective and this episode was produced and mixed by Cosmic Standard. Our producers are Hannah Kingsley Ma and Asia Simpson. Our editor is Alejandra Salazar. Our fact checker is Paul Durbin. Original music by Hinsdale Sue and Allison Layton Brown.


Our team includes Eliza Smith, Jacob Winnick, Samaya Adams, Roxanne Highl, ban Chang, Julia Dickerson and Whitney Pennington Rogers. I get a surprising number of emails, like cold emails or something where someone will like say, I confess, I wrote this with the help of chat GBT. And I try to, if I reply, I try to always say like, no need to ever do that again. If you ever email me again, I'll take the bullet points. So that's my one little contribution to the fight. Wow. And then there's a little disclaimer at the bottom saying, this response was also written by Chachi. If you See if I do that, I do disclose, but I I don't.


I usually just write my two bullet points back.


Raise the rudder, raise the sales, raise the captain. An unidentified ship is approaching over Roger, wait. Is that an enterprise sales solution? Reach sales professionals, not professional sailors. With LinkedIn ads, you can target the right people by industry job title and more. We'll even give you a $100 credit on your next campaign. Get started today at LinkedIn dot com slash results. Terms and conditions apply.


This episode is brought to you by Progressive Insurance. Do you ever think about switching insurance companies to see If you could save some cash? Progressive makes it easy to see If you could save. When you bundle your home and auto policies, try it@progressive.com. Progressive casualty insurance company and affiliates. Potential savings will vary not available in all states.


DirecTV Stream has the most local MLB games, which means it's never been easier to root, Root root For the home team. So whether you're rooting for a or Aura Safe or even a, it's direct three Aura. It's outta here. Root for your home team with DirecTV Stream the most MLB games period claim based on total games carried on sports networks. Sports availability varies by zip code and requires choice package.