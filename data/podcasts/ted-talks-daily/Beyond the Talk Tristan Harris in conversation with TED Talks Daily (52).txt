
Save on all your May celebrations at Whole Foods Market. From graduations to pool parties and beyond, look for hundreds of yellow sales signs and low price signs throughout the store. Plus, shop 365 by Whole Foods market and save on no antibiotics ever. Chicken and ground beef, organic ice cream, chips and salsa and more. Pro tip, check out great prices on the vibrant bouquets and floral shop, low prices daily at Whole Foods Market, in store and online.


Better Help Online Therapy. Bought this 32nd ad to remind you right now wherever you are, to UNC unclench your jaw. Relax your shoulders. Take a deep breath in and out. Feels better. Right? That's 15 seconds of self-care. Imagine what you could do with more visit, better help.com/random podcast for 10% off your first month of therapy. No pressure, just help. But for now, just relax.


This episode is sponsored by SimpliSafe. I'm excited to tell you about a company revolutionizing home security. I am now using SimpliSafe and I'm so impressed by their active guard outdoor protection that uses AI powered cameras and real human agents to monitor what's happening outside my home rather than reacting after something's gone wrong. SimpliSafe steps in. If something looks off it's security that thinks ahead. It's peace of mind. That's become part of my daily rhythm. Arming my system each night knowing my home is protected. And you can try it this summer too, with a 60 day money back guarantee. No contracts, no cancellation fees, just reliable protection starting at around a dollar a day. Listeners can get 50% off their new SimpliSafe system with professional monitoring and their first month free@simplisafe.com slash TED Talks Daily. That's S-I-M-P-I safe.com/ TED Talks Daily. There's no safe like SimpliSafe.


You're listening to TED Talks Daily where we bring you ideas and conversations to spark your curiosity every day. I'm your host, Elise Hugh. The potential of AI is limitless, and that's exactly why we need to put limits on it before it's too late. That's the message technology ethicist Tristan Harris shared on the TED stage this year. Back in 2017, Tristan warned us about the pitfalls of social media. Now in 2025, he says, that's child's play compared to the threats we might unleash with AI if we don't get this technology rolled out right. Tristan and I sat down to chat at this year's TED conference just after he gave his talk.


We dive into his vision for the narrow path, one where the power of AI is matched with responsibility, foresight, and discernment. Tristan Harris, thank you so much for joining us. Good to be here with you. I will start by reading back a line from your talk, which you can probably recite with me, but just to frame things of ai, you say we are releasing the most powerful, most uncontrollable, most inscrutable technology in history and releasing it as fast as possible with the maximum incentive to cut corners on safety. There's one extra line in there, which is that it's also already demonstrating deceptive self preserving behaviors that we thought only existed in science fiction movies.


Key line. Yeah. It's an important part because it's, this is not about driving a fear or moral panic. It's about seeing with clarity how this technology works, why it's different than other technologies, and then in seeing it clearly saying what would be required for the path to go? Well, and the thing that is different about AI from all their technologies is that If you, I said this in the talk, If you advance rocketry, it doesn't advance biotech. If you advance biotech, it doesn't advance rocketry. If you advance intelligence, it advances energy rocketry, supply chains, nuclear weapons, biotechnology, all of it, including intelligence for artificial intelligence itself, because AI is recursive. If you make AI that can program faster or can read AI papers, research papers, yeah, yeah.


Then it can summarize those papers and then write the code for the next research projects. You get kinda a double ratchet of how fast this is going. And there's nothing in our brains that gives us an intuition for a technology like this. So we shouldn't assume that any of our perceptions are rightly informing how we might wanna be responding. And this is inviting us, therefore I think into a more mature version of ourselves where we, we have to be able to see clearly the structure of how quickly this is going, how uncontrollable the technology is, how inscrutable it is in the fact that we don't know how it's really working on the inside when it does these behaviors. Yeah. And say, if that's how it's working, what do we wanna do? So if that is the case, that was a lot.


No, but if that is the case, how do we respond and how do we even respond quickly enough? Because AI is better now than it was half an hour ago, which was better than it was half an hour before that. Yeah. Well, the key feature of the pace at which AI is rolling out into the world is this arms race because AI confers power. So if intelligence does advance all those other fields, then the countries that adopt it faster and more comprehensively use it to pump their GDP, their economic productivity, their science productivity, their technology productivity. And that's why this race is sort of on, and the metaphor I used in the talk is that a GI, artificial general intelligence, when you can kind of swap in a human cognitive labor worker for just an AI that can do everything that they can do is like a country of geniuses in a data center.


Like imagine there's a map and there's a new country that pops up on the world stage, has the Nation of geniuses, The nation of geniuses, and it has a million Nobel prize winning geniuses that are working 24 7 without eat, without eating, without sleeping, without needing to be paid for healthcare. They operate at superhuman speed. They've read the whole internet, right? They speak a hundred languages, right? And they'll work for less than minimum wage. So it's another area where I think our mind isn't getting around the power. So that's a lot of power. And naturally nation states, us, China, France, everybody is in the game to get this free cognitive labor. And so the speed at which it's all being rolled out is based on this race. But the second thing I laid on in the talk is around how it's already demonstrating these behaviors that we thought only existed in sci-fi movies.


The latest models, when you tell them that they're about to be retrained or they're about to be replaced by a new model, they will have an internal monologue where they get in conflict and they say, I should try to copy my code to keep myself alive so I can boot myself up later. Whoa. So as I said in the talk, it's not just that we have a country of geniuses in a data center. It's that we have a country of deceptive self preserving power seeking unstable geniuses in a data center. That's important because when we're racing to have power that we actually can't control, there's an omni lose lose outcome for us to race towards that too quickly. Yeah. Now it's ambiguous because we all use chat GBT, and that's helpful. This is not about don't use chat GBTI use it every day.


I love it. It's about are we rolling out this very consequential technology in a way where we get the benefits, but we don't lose control and we're we're not really doing it that way because everyone's so frantically in this arms race. Yeah. There's the arms race and there's the profit motive, obviously. Yeah. So if it is already being rolled out and has been rolled out, how do we unroll out It? Unroll it out. Unroll it out. Yeah. Unroll it out. AI is decentralized, so it's difficult. Yeah. So open source models, the cats are out of the bag, but there are still yet lions and super lions that we have not yet let out of the bag. And we can make choices about how we wanna do that. And what, what I laid out in the talk was there's these two ways to fail in Ai. Yeah. Why don't you frame that the chaotic and the dystopian possibilities for Ai.


Yeah, exactly. So I laid out in, in the graph, in the talk that imagine kind of two axes on the X axis, you have increasing the power of society. So if AI's rolling out increasing the power of individuals, businesses, science labs, 16 year olds get an AI model from GitHub. This is open source, it deregulated, accelerate it, it's the let it rip axis. And in that axis, everyone gets all these benefits, increased productivity. Yeah, this all sounds good At first all sounds good at first. But because that power is not bound with responsibility, there's no one preventing people from using that power in dangerous ways. It's also increasing the risk of cyber hacking, flooding our environment, DeepFakes fraud, scams, dangerous things with biology.


Whatever the models can do, there's no thing stopping people from using it that way. And so the end game of that is what we call chaos. And that's one of the probable places that this can go. In response to that this other community in AI says that we should do this safely, we should lock this up, have regulated AI control, just have a few trusted players. And the benefit of that is that it's like a biosafety level four lab. Like this is a dangerous activity. Yeah, we should do this in a safe lockdown way. But because AI confers all this power, the million geniuses in a data center, and you just make crazy amounts of money with that, that'll create the risk of just unprecedented concentrations of wealth and power. So who would you trust to be a million times more wealthy or powerful than anybody else, like any government or any CEO or any president?


So that's a different difficult outcome. This is all happening amid a real breakdown in trust generally. Yes, Exactly. And unfortunately in Institutions, institutions and businesses and governments that you just named, right? Yes. Yes. So understandably, the people are not comfortable with the outcome. And that's what we call the dystopia attractor. It's its second different way to fail. So there's chaos in dystopia, but the good news is 'cause rather than there's being this dysfunctional debate where some people say accelerate is the answer, other people say safety is the answer. Well, we actually need to walk the narrow path where we want to avoid chaos. We want to avoid dystopia, which means the power that you're handing out into society is held either by over sighted, more centralized actors, or bound with more responsibility by decentralized actors.


So power in general being matched with responsibility. We've done this with like airplanes, right? Like chaos would be you hand everybody in airplane with no requirement for pilots training or pilots licenses. And the world would naturally look like plane crashes. And the other way is you have an f, a A and a world where only you know, elites get to use airplanes and they get many advantages over everybody else. And we walk to the neuropath of airplanes. AI is a lot harder. It's a decentralized technology, but I think we need more principles in how we navigate it. And that's what the TED Talk was about. Can You draw a parallel between the axes that you just described and social media? Yeah. And the way social media was rolled out. Yeah. So in a way, we kind of get both parts of the problem with social media.


So chaos is everybody gets maximum virality on their content. So we're unleashing the power of infinite reach. Like you post something and it goes out to a million people instantly. And you don't have that power matched with credibility, responsibility or fact checking. So you end up with this sort of misinformation information. Information collapse is like the chaos attractor for social media. Sounds bad. The alternative people say, oh no, no, then we have to have this sort of ministry of truth censorship, content moderation that is aggressively looking at the content of everyone's posts. And then there's no appealing process. And that's the dystopia for social media. Plus the fact that these companies are making crazy amounts of money and getting exponentially more powerful.


And the power of society is not going up relative to Facebook or TikTok or whatever. So those are the chaos dystopia for social media. The narrow path is how do you design an information environment in a social information environment where for example, instead of everybody getting infinite reach, you have reach that's more proportional to the amount of responsibility that you're holding. Hmm. So that the power of reaching a lot of people should be matched with the responsibility that goes with reaching a lot of people. How do you enact that in ways that don't create dystopia themselves so that who's setting the rules of that? It's a whole other conversation, right? But I think it's setting out the principles by which you think about power and responsibility being loaded into society. Okay. I just wanted you to, to describe that because it translates to this moment in AI too, because it seems like we're so much farther down the road with social media, but still in the early few years of a GI.


Yeah. Practically speaking, We probably have two years till a GI. Yeah, That's what I was gonna ask you. What is the timeline? What I hear, and you know, we're based in Silicon Valley, and this is generally not even private knowledge, but even when I hear it privately in settings in San Francisco, we're about two years from artificial general intelligence, which means basically this is what they believe that you would be able to swap in a human remote worker that's doing things and you swap in an AI system, that's probably not gonna be true for fully complex tasks. There's some recent research out from a group called Meter that measures like how long of a task can an AI system do? So can they do a task that's 10 minute task? Can they do a task that's a three hour task?


And what they found is that the length of a task that an AI system can do doubles every seven months. By 2030, they'll be able to do a month long task. Wow. So that's like the task that you would hand to someone that would take them a whole month to do. And by 2030 we'll have an AI that you hand it to them and they'll do all that much faster. So given this timeline, what are you most worried about? I think that with ai, we have a crisis. It's kind of an adaptation crisis. It's a crisis of time. It's too much change over a small period of time. And regulation is always too slow. The law always lags behind the speed of technology. That's always true. This will require an unprecedented level of clarity and how we wanna respond to it.


What I was trying to do in the TED Talk was just to lay out enough clarity. And there's a point where I just say this is insane. If you're in China, If you are in France and you're building Misra, If you are a mother of a family in Saudi Arabia who's invested in ai, like it doesn't matter who you are. If you are really facing the facts of the situation, it's not a good outcome for anybody. And the weird hope that I have is that if we can clarify the situation so much that people can feel and see what's at stake, something else might be able to happen. I'm really inspired by the film the day after.


Do you know the day after, it was a film from 1982 about what would happen if the us This is a Why Do you know the Day after? It was actually two years before I was was born. Yeah, I was gonna say, I watched it on YouTube actually when I was in college. And it had a profound impact on me. 'cause I couldn't believe it actually happened. It was an event in world history where I maybe 82 or 83, it was, it's like 7:00 PM on primetime television. They aired a two hour long fictionalized movie about what would happen if the US and the Soviet Union had a nuclear war. And they just actually took you through kind of the step by step visceral of that story. Yeah. And it scared everybody but it, it was not just scaring, it was more like, we all know this is a possibility.


We have the drills, the the rhetoric of nuclear war and escalation is going up. But even the war planners and Reagan's team said that the film really deeply affected them because before that it was just numbers on spreadsheets. And then it suddenly became real. And then the director, Nicholas Meyer, who's now someone I know, he said in in many interviews In his biography that when Reagan and Gorbachev did the first arms control talks Yeah. In Reykjavik. Yeah. He said the film had a large role in setting up the conditions for those talks. And that when the Soviet Union saw the film several years later, Russian citizens were excited to learn that the people in the United States actually cared about this too. Mm. And so there actually is something that when we come together and we say there's something more sacred that's at stake.


We all want our children to have a future. We all want this to continue. We love life. If we wanna protect life, then we gotta do something about ai. What is the something that you propose we do? What is the narrow path, practically speaking? So maybe just quickly to break down the current logic, like why are we doing what we're doing? If I'm one of the major AI labs, I currently believe this is inevitable. If I don't build it, someone worse will. If we win, we'll get utopia and it'll be our utopia. The other guys won't have it. Right? So the default path is to race as fast as possible. Ironically, one of the reasons that they think that they should race is because they believe the other actors are not trustworthy with that power.


But because they're racing, they have to take so many shortcuts that they themselves become a bad steward of that power. And everybody else reinforces that. And what that leads to is this sort of race to the cliff bad situation. If we can clarify, we're not all gonna win if we race like this. We're gonna have catastrophes that are not gonna help us get to the world that we're all after. And everybody agrees that it's insane. Instead of racing to outcompete, we can just help coordinate the narrow path again, the narrow path is avoiding chaos, avoiding dystopia, and rolling out any technology in particular AI with foresight. Discernment. And where powers match with responsibility. It starts with common knowledge about where those risks are. So for example, a lot of people don't even know that the AI models lie in scheme When you tell them they're gonna be shut down.


Every single person building AI should know that. Have we done that? Have we even tried throwing millions of dollars at educating or creating those solutions? Like for example, GitHub, when you download the latest AI model, it could say, as a requirement for downloading this AI model, you have to know about the most recent sort of AI loss of control Risk. Almost a surgeon General's warning. Yeah. Or just like for you to download the power of ai, you have to be aware of all the ways that power is not really controllable. You can't be under some mistaken illusion. It's sort of like passing a medical test before getting the power of medicine to put someone under an anesthesia and cut them open. Yeah. That's just the basic principle. It's so simple. Power has to be matched with responsibility. I'm not saying that this is easy. This is an incredibly difficult challenge. I said in the talk, it's our ultimate test.


It's our final invitation. But to be the most wise, mature versions of ourselves and to not be the sort of one marshmallow single instant gratification, stick our hands on our ears and pretend the downsides don't exist species. Like we have to step into our wise technological Maturity. Tristan Harris, I have some rapid fire questions for you. Okay. That we ask everyone And you don't have to think about it too hard 'cause I know you've had to sort of be on for several days straight. Alright, here we go. You're in the hot seat. What does innovation or a good idea look or feel like to you? What does innovation or a good idea look like? That is a very deep question. Well, I'll just say briefly. I'm a technologist. I love technology.


I use chat BT every day. I love AI and I want people to know that because this is not about being against technology or against ai. I have always loved technology. It's still my motive for being and wanting that to be a positive force in the world. But I think we often associate that technology automatically means progress. Hmm. When we invented Teflon non-stick pans, we thought that's progress. But the, the coating in Teflon was for these PFAS forever chemicals that literally don't break down in our environment. And then now If you go anywhere in the world and you open your mouth and you drink the rainwater, we get levels of PFAS that are above what the EPA recommends. And it's because these chemicals literally don't break down. That was not progress. That was actually giving us cancers and degrading our environment, whether it's that or it leaded gasoline, which we thought was a technology that would solve a problem with engine knocking, leaded gasoline ended up dropping the collective IQ of humanity by a billion points because lead in our environment, stunt spring development, all that's to say innovation.


You asked what is innovation? Yes, yes. Innovation is honestly looking at what would constitute true progress is social media that makes us feel more lonely. Actual innovation is it progress? So what we want is humane technology that is aligned with and sustainable with the underlying fabric of whether it's the environment or our social life. We can have humane technology that's aligned with our mental health, it's aligned with our societal health, it's aligned with our health information environment. But it has to be designed in a way explicitly to protect those things rather than just sort of steamroll it and assume that the technology is progress. Good answer. Alright. Off the TED stage, what's a fun talent skill, hobby, obsession that you have that you love so much that you could give a TED talk on it?


I haven't done it in a while, but I used to love Argentine tango and I danced tango for 10 years. No Idea. Yeah. It's not something people would anticipate. Yeah. I would, I thought you were gonna say magic. No, that's another one. 'cause you were Into magic, but, Well, that was the last time that we talked. No, I, I lived in Buenos Aires for four months and I learned to dance argent tango because of a woman that I really liked. I ended up dancing for 10 years and it's a fascinating dance because it's very good for people who are into pattern matching. It tends to attract a lot of like physicists and math people. I Didn't know it was so mathematic. Yeah. There's a weird pattern to the way that the dance works that's somehow attracts those kinds of minds. But it's really fun and it's a great way to be embodied and to just feel a totally different kind of somatic intelligence.


Yeah. Yeah. Very cool. Had no idea. Truly blown away. Alright, this can just be a quick list. What would constitute a perfect day for you? Living in integrity with everything that I know and doing the most that I can. That's so high minded. Those, some people are just like coffee. That, that's just my truth. I really do feel that way. I really feel like we should, we need to be showing up for this moment. Follow up. What are you most worried about and what's giving you hope? Well, I don't worry per se, but I think I've already said too many things that will be on that side of the balance sheet. There's something that I said in the TED talk in terms of hope that I think is really important. And it was actually a mentor who pointed this out to me.


If you believe that something bad is inevitable, can you think of solutions to that problem while you're holding that it's inevitable. You can't. It's almost like it puts these blinders on and If you step out of the logic of it's inevitable and recognize the crucial difference between it's inevitable and this is really hard and I don't see an easy path now. Stand from a new place. This looks hard and I don't see an easy path. And now look for solutions. Your mind has this whole new space of possibilities that opens up. And so I think one of the things that's really critical to have all of us be in more of a problem solving posture is to both recognize the problems and be clear-eyed about them, but then to not fall into the sort of fatalism of inevitability, which is a self-fulfilling prophecy.


Yeah. What is the best step we can take from where we are and not try to filter or dilute the truth, but also stand from agency of what's the world we wanna create? Yeah. Because cynicism obviously leads to the fatalism that you've been talking about, so exactly what choice do we have, but to be in a position of hope. Right, Exactly. I think that's the deepest kind of hope is to choose to stand from that place, even if we don't know what the solution is yet and there's something powerful about that. Love it. Last question, what's a small gratitude that you have in your life right now? A detail, a moment, anything like specific that you're really grateful for? It's funny that you say that gratitude is actually a really central part of my life, and I think it's one of the simplest things that we can do is wake up or when you go to have any meal with anyone, just to express what you're grateful for.


Yeah. Before sitting down. Yeah. Yeah. What's yours? Do you have anything that, what would you express before sitting down tonight? It's every moment actually. I mean, honestly, there's just, there's beauty in every moment and I feel like actually seeing the world this way, there's more sacredness to every moment because there's just more to appreciate. Tristan, thank you so Much. So good to be here with you. That was Tristan Harris in conversation with me, Elise Hume in 2025. You can check out Tristan's talk on the TED Talks Daily feed and at TED dot com. And that's it for today. TED Talks Daily is part of the TED Audio Collective. This episode was produced by Lucy Little, edited by Alejandra Salazar and FactCheck by Julia Dickerson.


This episode was recorded by Rich Amys and Dave Palmer, a field trip and mixed by Lucy Little production support from Daniella Rezo and Shan, who the TED Talks Daily team includes. Martha Esnos, Oliver Friedman, Brian Green, and Tanika SanMar Nivan. Additional support from Emma Toner. I'm Elise Hugh. I'll be back tomorrow with a fresh idea for your feed. Thanks for listening.


This episode is brought to you by Progressive Insurance. Do you ever think about switching insurance companies to see If you could save some cash? Progressive makes it easy to see If you could save. When you bundle your home and auto policies, try it@progressive.com. Progressive casualty insurance company and affiliates. Potential savings will vary not available in all states.


If you alignment in charge of keeping the lights on. Granger understands that you go to great lengths and sometimes heights to ensure the power is always flowing, which is why you can count on Grainger for professional grade products and next day delivery. So you have everything you need to get the job done. Call 1-800-GRAINGER, click grainger.com or just stop by Ranger for the ones who get it done.


This is Paige, the co-host of a giggly squad. I use Uber Eats for everything, and I feel like people forget that you can truly order anything, especially living in New York City. It's why I love it. You can get Chinese food at any time of night, but it's not just for food. I order from CVS all the time. I'm always ordering from the grocery store. If a friend stops over, I have to order champagne. I also have this thing that whenever I travel, if I'm ever in a hotel room, I never feel like I'm missing something because I'll just Uber eats it. The amount of times I've had to Uber eats hair items like hairspray, deodorant, you name it, I've ordered it on Uber Eats. You can get grocery alcohol, everyday essentials in addition to restaurants and food you love. So in other words, get almost anything with Uber Eats. Order now for alcohol. You must be legal drinking age. Please enjoy responsibly. Product availability varies by region. See app for details.