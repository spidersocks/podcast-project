
TED Audio Collective You are listening to TED Talks Daily, where we bring you new ideas to spark your curiosity every day. I'm your host, Elise Hugh. Today's talk is from our brand new batch of 2024 TED Fellows films adapted for podcasts. Just for our TED Talks Daily listeners, Ted's Fellowship supports a network of global innovators and we're so excited to share their work with you today. We'd like you to meet AI scientist Ramin Hasani. We talk about AI a lot here at TED because it's a world-changing technological development that's fast improving and risky.


But it's hard for a lay person like me to really grasp how it functions. Rahman's new AI system, which he co-invented, addresses that issue head on his system, gives us a lot more control and visibility into the mechanics behind the tech, making it safer and more trustworthy. After we hear from Robbie, stick around for his conversation with TED Fellows, program director, Lily James Olds all coming up after the break.


If you love iPhone, you'll love Apple Card. It comes with the privacy and security you expect from Apple. Plus you earn up to 3% daily cash back on every purchase, which can automatically earn interest when you open a high yield savings account through Apple. Card. Apply for Apple. Card in the wallet app. Subject to credit approval. Savings is available to Apple Card owners subject to eligibility. Apple Card and savings by Goldman Sachs Bank, USA, salt Lake City, branch member FDIC terms and more at Apple Card dot com


Teams with big ideas start in Jira. The only project management tool you need to plan and track work across any team. Jira even helps our team here at TED keeping us in sync to deliver the big ideas our listeners love. And there's a lot more that teams will love about Jira. It keeps cross-functional tasks organized with a project's timeline that's always really key so that we make our deadlines and cross-functional teams like TED. Working in one tool gives leaders the important visibility they need to make better business decisions. Get started on your next big idea. Today in Jira


Support comes from Zuckerman Spader through nearly five decades of taking on high stakes legal matters. Zuckerman Spader is recognized nationally as a premier litigation and investigations firm. Their lawyers routinely represent individuals, organizations and law firms in business disputes, government and internal investigations. And at trial, when the lawyer you choose matters most online@zuckerman.com


And now our TED talk of the day, My wildest dream is to design artificial intelligence that is our friend. You know If, you have an AI system that help us understand mathematics. You can solve the economy of the world If. you have an AI system that can understand humanitarian sciences. We can actually solve all of our conflicts. I want this system to give Einstein's and Maxwell's equations, take it and solve new physics. You know, If, you understand physics, you can solve the energy problem. So you can actually design ways for humans to be the better versions of themselves. I'm Ramin Hasani.


I'm the co-founder and CEO of liquid ai. Liquid AI is an AI company built on top of a technology that I invented back at MIT. It's called Liquid Neural Networks. These are a form of flexible intelligence as opposed to today's AI systems that are fixed basically. So think about your brain. You can change your thoughts when somebody talks to you. You can completely change the way you respond. You always have a mechanism that we call feedback in your system. So basically when you receive information from someone as an input, you basically process that information and then you reply for liquid neural networks. We simply got those feedback mechanisms and we added that to the system.


So that means it has the ability of thinking that property is inspired by nature. We looked into brains of animals and in particular a very, very tiny worm called Sea Elegance. The fascinating fact about the brain of the worm is that it shares 75% of the genome that it has with humans. We have the entire genome mapped. So we understand a whole lot about the, the functionality of its nervous system as well. So, if you understand the properties of cells in the worm, maybe we can build intelligent systems that are as good as the worm and then evolve them into systems that are better than even humans.


The reason why we are studying nature is the fact that we can actually having a shortcut through exploring all the possible kind of algorithms that you can design, you can look into nature that would give you like a shortcut to really faster get into efficient A, because nature has done a lot of search, billions of years of evolution, right? So we learned so much from those principles. I just brought a tiny principle from the worm into artificial neural networks and now they're flexible and they can solve problems in an explainable way. That was not possible before. AI is becoming very capable, right? The reason why AI is hard to regulate is because we cannot understand the same even the this people who design the systems and we don't understand those systems.


They're black boxes with liquid because we are fundamentally using mathematics that are understandable, we have tools to really understand and pinpoint which part of the system is responsible for what you're designing. White box systems So. if you have systems that you can understand their behavior, that means even If, you scale them into something very, very intelligent, you can always have a lot of control over that system because you understand it. You can never let it go rogue. So all of the crises we are dealing with right now, you know, doomsday kind of scenarios is all about scaling a technology that we don't understand. We liquid our purposes to really calm people down and show people that hey, you can have very powerful systems, that you have a lot of control and visibility into their working mechanisms.


The gift of having something very superint intelligence is massive and it can enable a lot of things for us, but at the same time, we need to have control over that technology 'cause this is the first time that we are gonna have a technology that's gonna be better than all of humanity combined. That was Rami and Hasani, A 2024 TED fellow. Stick around after the break to hear Rami and go deeper into his work. And now a special conversation between TED fellow Rami and Hasani and TED Fellow's program director Lily James oos. Hi Ramin. It's so great to have you with us today. Thanks for having me.


So does this mean we can all stop panicking about ai? Well, a little bit, yes. So we are moving in that direction. We're opening the black box. We are trying to improve the control that we have as designers of AI systems in a way that you have a lot more control on the outcomes, on the outputs of an AI system and you can put boundaries around what you want them to do, you know, and that that control ability is something that we want to create for AI and build systems that are fundamentally and inherently understandable. Okay, I'm gonna come back to that 'cause I have a lot of questions on that.


But just to start, so you say that looking into nature helped you and your team invent these liquid neural networks and in particular one specific worm that surprisingly shares a lot in common with humans. Now this is totally wild to me. I had no idea that I was so closely related to a worm. Can you tell me a bit more about how this worm's brain inspired your discovery of liquid neural networks? The worm is called sea elegance. This is the first animal that we had in its entire nervous system mapped, you know, neuroscientists, anatomically connected, all the connections that exist in the brain of the worm, 302 neurons, the scientists that designed this thing, they, they won Nobel prizes and, and the reason for that is just the faceting fact that in the tree of evolution 600 million years ago, we got split from this worm and so it, it shares 75% genetic similarity to humans.


The fact that our nervous systems, our brains are actually inspired by the mapping of this kind of worm. I thought that this would be a very good place to get started. Also, you should know that the body of the worm is transparent. You can see inside how things happen. So you see that the neurons flash actually like under microscope when you look at the worm. So you can actually see how the neuron behaves while you can record the brain activities of the worm. So you have a lot of data. So it becomes a very good model organism. So I started looking into this. I thought that, okay, so neurons and synapses are the same, almost the same on in terms of functionality in this worm and in humans.


So. if you can understand on this worm how things work from the mathematical principles and how behavior emerges from a set of neural activities with mathematics that are or involved, then we can take this and evolve this into better versions of itself, which became human brain and maybe we can also evolve artificial intelligence that way. That's so crazy that that discovery came from nature so directly. So back to where you started this conversation. Right now we don't have the transparency into how current AI systems work. As you said, it's a black box and you said you know that this is the problem and why we don't have control over these systems. I guess my first question is just how did we get to this point?


You know, why weren't these AI systems built with transparency as a core tenant? The thing is like the AI systems were transparent and they are still traceable. You know, the problem that we have with these AI systems, it is the scale of these AI systems today. So you started taking these very simple mathematics, you know, simple if condition, you know, if something happens, neuron gets activated. If doesn't happen, the neuron turns off. Then we took this function and we scaled this technology, we scaled it into billions, or now we are getting into trillions of parameters, you know, so now a system, imagine you have trillion knobs that you have to turn now If, you want to go and reverse engineer what are these trillions of knobs are actually doing?


This becomes a a, a non tractable process. So you wouldn't be able to really say what each of these one out of trillions of knobs that are actually doing and what's the function of these things in the overall kind of behavioral generation of degenerative AI system. That's why we call them black boxes. You know, when we scaled the models, we saw that much, much better and then smarter behavior emerged from these AI systems. That's the excitement that we move towards, right? We always want to design systems that are more fascinating, you know, getting closer, getting smarter than humans, and then that excitement sometimes prevents us from looking into the sociotechnical challenges that these AI systems can bring, right?


And that is something that we have to control. So how are the liquid neural networks different? So why are they more trustworthy and why do we have more control over them at scale? That's a great question. So think about it like this. When you are sitting on an airplane, you know, as a passenger, then the pilot turns on autopilot. You as a passenger completely trust that autopilot. Even If, you don't understand that system. How is it that we trust that autopilot in action in such a safety critical task? The reason why you trust it is because the engineers who design that whole system, they completely understand how that mathematics works.


They go through multiples of testing so that they can get into this safety critical kind of system. That's the best type of explainability that you want to have. You know, you want the engineers who design the systems, understand fully how the technology works. Now with liquid neural networks, the core mathematics is something that is tractable. That's why us engineers and scientists are being able to actually get into the systems and we have a lot of tools to really steer and put controls on top of the system. Something that's been on my mind and many people's minds a lot is how can we make sure that AI systems are built on ethical frameworks and inclusive data?


Data representation is one aspect. The ability of a human to understand also what happens inside a model is another aspect of it, right? Then these two together, data representation plus us being able to explain models, that's the road towards achieving safe artificial intelligence. So fascinating. I have to say, this conversation does make me feel a little bit more at ease, so thank you for taking the time to Talks Odoo us today. My last question is, if someone listening is interested in diving deeper into this topic, what resources would you recommend to them in terms of a book, a podcast, or something else? I've given a lot of talks about liquid neural networks online, but more concentrated kind of material.


You can find it on our website. We started the company around liquid neural networks and taking this technology to the next level and providing it to the society for developing safe, a safe ai. And this is liquid.ai. So this is where you can find all sort of information. There are blog posts around like the research papers, talks, products, and everything around the topic. Amazing. Well, thank you so much, Ramin. Absolutely. Thank you.


This episode is brought to you by Progressive Insurance. Do you ever find yourself playing the budgeting game? Well with the name your price tool From Progressive, you can find options that fit your budget and potentially lower your bills. Try it@progressive.com. Progressive casualty insurance company and affiliates, price and coverage match, limited by state law, not available in all states.


Hi, I'm Bvo sdu, host of Ted's newest podcast, the TED AI show, where I talk with the world's leading experts, artists, journalists, to help you live and thrive in a world where AI is changing everything. I'm stoked to be working with IBM, our official sponsor for this episode in a recent report published by the IBM Institute of Business Value. Among those surveyed, one in three companies pause an AI use case after the pilot phase, and we've all been there, right? You get hyped about the possibilities of AI spin up a bunch of these pilot projects and then crickets. Those pilots are trapped in silos. Your resources are exhausted and scaling feels daunting. What if instead of hundreds of pilots, you had a holistic strategy that's built to scale? That's what IBM can help with. They have 65,000 consultants with generative AI expertise who can help you design, integrate, and optimize AI solutions. Learn more at IBM dot com slash consulting because using AI is cool, but scaling AI across your business. That's the next level.


To learn more about the TED Fellows program and watch all the TED Fellows films, go to fellows dot TED dot com and that's it for today. TED Talks Daily is part of the TED Audio Collective. This episode was produced and edited by our team, Martha Esnos, Oliver Friedman, Brian Green, autumn Thompson, and Alejandra Salazar. It was mixed by Christopher Fay Bogan. Additional support from Emma Toner and Daniella Rezo. I'm Elise Hugh. I'll be back tomorrow with a fresh idea for your feet. Thanks for listening.