
My dad works in B2B marketing. He came by my school for career day and said he was a big row as man. Then he told everyone how much he loved calculating his return on ad spend. My friends still laugh at me. To this day,


Not everyone gets B2B, but with LinkedIn you'll be able to reach people who do get a hundred dollars credit on your next ad campaign. Go to linkedin.com/results to claim your credit. That's linkedin.com/results. Terms and conditions apply LinkedIn, the place to be to be.


Does your AI model really know code? Its specific syntax, its structure, its logic. IBM's granite code models do they're purpose built for code and trained on 116 different programming languages to help you generate, translate and explain code quickly. 'cause the more your AI model knows about code, the more it can help you do. Get started now at IBM dot com slash granite. IBM Let's create.


This episode is brought to you by Progressive Insurance. Do you ever find yourself playing the budgeting game? Well with the name your price tool From Progressive, you can find options that fit your budget and potentially lower your bills. Try it@progressive.com. Progressive casualty insurance company and affiliates. Price and coverage match limited by state law, not available in all states.


Hey TED Talks Daily listeners. I'm your host, Elise Hugh. Today we have an episode of another podcast from the TED Audio Collective handpicked by us for you. It's been a big election year and it's the first one where AI has dominated the conversation. Generative AI has made it easier than ever to create voter confusion through deep fakes and misleading false news articles. This week we're sharing an episode of The TED AI Show all about this emerging technologies impact on our political landscape. Journalist Vittoria Elliott shares how people are using artificial intelligence programs right now and what governments need to do to protect future AI chaos.


If you wanna hear more fascinating discussions about ai, listen to The TED AI Show wherever you get your podcasts. Learn more about the TED Audio Collective at Audio Collective dot TED dot com now onto the episode. So I've been thinking a lot about the elections this year because this year feels different, but not for all the reasons you're thinking about. I'd say this year, national and local elections are objectively different from any other because it's gonna be our first AI election. We're less than a hundred days until election day. And you've probably seen it amidst all the other election news.


AI is entering the chat. But it wasn't until I was scrolling on X one day that I realized what the next few months might look like. X had just updated grok their AI chatbot so that it could generate images using a largely uncensored open source model called Flux. And immediately the results were far more unhinged than anything we've seen. Now we've been able to generate images in the past, but this is the first time we've had these capabilities put into a social media app that 250 million people use every day. I saw photo realistic pictures of Kamala Harris and Donald Trump in bizarre situations that range from easily click bait images of them lovingly holding hands to skin crawling images of the two of them celebrating nine 11.


Suddenly my feed was full of Wild Harrison Trump memes and I started to realize it's kind of impossible to imagine a future where AI won't have an impact on elections moving forward. It feels like uncharted territory, but actually in many ways the US is late to this specific party. Other countries around the world have been adapting their elections alongside the rise of ai and it goes beyond just memes. DeepFakes and chatbots have been deployed in surprising ways in some of the world's biggest elections, like in India and Pakistan and in Europe there's even AI candidates that have run for office.


So what can we learn from the rest of the world to prepare for our first AI election? And is it really just doom and gloom or can AI actually be good for democracy? I am Bvo sdu and this is The TED AI Show where we figure out how to live and thrive in a world where AI is changing everything. Does your AI model really know code? It's specific syntax, it's structure, it's logic. IBM's granite code models do they're purpose built for code and trained on 116 different programming languages to help you generate, translate and explain code quickly.


'cause the more your AI model knows about code, the more it can help you do. Get started now at IBM dot com slash granite. IBM let's create.


So good, so good, so good. New markdowns. Up to 70% off are at Nordstrom Rack Stores. Now from fresh kicks to perfect gifts, there's always a find Levi's Paige frame, all the best denim. Why do I rack? Because check out these boots. I always score at Rack head to your Nordstrom Rack store to find amazing deals on all things winter, great brands, great prices. That's why you rack Today.


I'm talking with Vittoria Elliott, a reporter at Wired who specializes in disinformation and social media platforms and she's in the middle of a massive endeavor to collect stories about AI and elections from around the world. For Wired's AI elections project. If you go to the website, you'll see they've got a geospatial map that's basically tracking all the ways this tech is being used. When I checked it out, I was struck by how important a tool like this can be. It's a perfect example of what I'd call open source intelligence, a compilation of public sources that can reflect relevant insights and build awareness. And who knows, maybe those insights could be the key to updating our democracy's firmware ahead of our first AI election.


I was really interested in asking Victoria to walk me through some of the most important stories she'd come across and how AI's reshaping elections around the globe. Hi Victoria, welcome to the show. Hi Bil Lava. Thank you so much for having me. So let's get right into it. Can you start by walking us through the Wired AI elections project? Yeah, so this year is the biggest election year pretty much ever. There's about 65 elections that are happening around the world. This is a massive year for democracy and it's also not only the biggest election we've probably ever seen, but it is certainly the biggest election since the advent of the internet and social media.


And I think we saw it as a moment to really take stock of how technology and democracy are interacting, particularly in this moment of generative ai. And so part of it was to see how is this actually gonna impact democracy but also, you know, are the things that people were afraid of. Are those the trends we're gonna see or is it gonna be something else? And how are those trends gonna look differently in different parts of the world? So much of technology discourse is really US-centric because a lot of big technology companies are US companies, but that doesn't mean that's what that technology or that innovation is gonna look like in other places. That doesn't mean that's how it's gonna be used in other contexts.


We have a big world map that shows every country that's having an election this year and then whether or not there's been instances of generative AI related to that election showing up. So this could look like the Joe Biden robocall that happened right before the New Hampshire primaries where a voice clone of Joe Biden called all these voters in New Hampshire discouraging them from voting in the Democratic primary. That's an instance of generative ai. But then we're also seeing things like in Pakistan, the former Prime Minister, Imran Khan, a deepfake of him that he authorized that he, his party authorized declaring victory speaking to people because he was in prison.


And so we see both these like really interesting examples of something being like sanctioned and unsanctioned. So we have these types of examples in the project and they're broken down into regional categories like North America, Africa, Europe, et cetera. And so a user can look at the map and see how far this technology is reaching in terms of where it's showing up in elections and a description of what happened when it happened, where it happened, and then a link out to like other sourcing that we used to sort of confirm that this was real. I think it's super exciting to have this all collated in one place. It's also slightly disconcerting. And on that note, you know, I think when people think about generative AI and elections, people immediately jump to deep fakes.


How are DeepFakes affecting campaigns in the US so far, both at this national level, you gave the Biden example but also the local level. The DeepFakes I think are the most visible form and sometimes the easiest to detect. So I think that's why we see so many instances of that. And I think even in the project you'll see that there is a bias towards visual media because that's just easier in many cases to confirm that something's fake. And a lot of times just because we know something's fake doesn't necessarily mean it's still not emotionally resonant. So I think a really great example of this is a couple weeks ago Elon Musk, owner of formerly Twitter currently x tweeted a parody video of vice president and Democratic presidential nominee Kamala Harris saying she was the ultimate DEI hire, which is one of the things that the W right really likes to say about her.


But it was using her voice saying that in the style of a campaign ad. And when he initially tweeted it out, it didn't have a disclaimer saying that it was parody, it didn't have labels saying that it was AI generated, which many platforms require. But I think even people who really do believe that about Kamala Harris might know that that video's not real, but it's still really emotionally resonant because it's the voice of this politician saying something that people kind of already believe to be true. It's less about necessarily that people are getting tricked than the fact that they are seeing out in the world represented something that up until this point they've sort of only personally believed to be true.


And then I think when we're looking at the local level, a really interesting example is Peter Dixon who's a congressional candidate in California, he used a AI in a campaign ad to sort of like look like he was jumping through these various points In his life in different locations to sort of illustrate his background. And then we had the example of Jason Palmer who is an investor and businessman who ran in the Democratic primaries in American Samoa. And he used very openly AI to conduct that campaign. He used AI to have a deep fake avatar of himself and it answered questions about his public policy. People could ask it things. So you know, there's this sort of broad swath of how it can be used in a really sort of legitimate way to be like, hey, this man is not gonna necessarily fly to American Samoa, but how can people in American Samoa feel connected to this candidate?


Maybe it would be good for him to have an AI avatar that can answer questions that can state his policy positions. And then, you know, on a more hyper-local level, there is someone who's actually running for mayor of Cheyenne, Wyoming as an AI candidate, as in he has created an AI bot and the bot's name is Vic Virtual integrated citizen. And Vic is ingesting thousands and thousands of city council documents to make policy decisions. And that's what we're seeing on a local level and that's not a deep fake. So I think we're seeing them used in all these really innovative ways that go beyond just trying to trick people but more around how can they be useful to campaigns and very specifically how can they make people feel connected to these issues even if people know that the thing they're dealing with is not a real human.


You know, it strikes me that there is this sort of sliding scale of like pure utility to let's say like deceptiveness on the other end. And, and it is a, a blurry line, the example that you gave of you know, a politician basically making themselves more accessible, almost like a async virtual town hall where you can go ask this politician questions and maybe learn about their views a little bit better in a more intuitive fashion. It's also interesting to just see folks like bolster their, like the media that they're gonna push out there to like illustrating the various stages of a person's journey and being able to like bring people along for the ride and you know, just make that feel a little bit more transportive and authentic I think is very exciting. And then the last piece which is, you know the meme one, you can create content that is overtly like hey this is intended to be fake but it can still have a visceral impact on you both in a good sense and maybe in a negative sense too where it kind of bypasses your firewall because it has this emotional reaction in you.


And even If you know, hey this is factually incorrect, you're still gonna be influenced by that. Right? Totally. I mean I think when we think about the use of AI and satire and parody in situations where again people know it's fake, that does, just because people know it's fake doesn't mean it's not resonant to them. On that note, the lines do get blurry at times. You know, we're getting to this point where events and photos are being called in quotes, AI of course the recent example is, you know, Donald Donald Trump claimed that, you know, Kamala's crowd size was AIed in quotes. How do you think this dynamic alters how to run a campaign when you can like call out like factual things as being fake even though I'd assume these are exceedingly photographed events?


So there's actually a term for this, it's called the Liar's Dividend and it's sort of the idea that when everything could possibly be fake, nothing is real. As someone who used to cover specifically tech in the global south, everything comes home to roost. We see it elsewhere before it comes here. We saw that with the abuse of social media for disinformation campaigns in places like India or in the Philippines before it became a problem in the US. And I think when we're talking about the Liar's dividend, same thing last year in India we had politicians who real leaked recordings of them were being shared saying bad stuff and their immediate response was That's fake, that's not real, it's ai.


And you know, I think back on, you know, the Donald Trump access Hollywood tape, I think if that happened now he would just say that was fake audio. He would just say that was AI generated. And so I think what we're really gonna see is this further blurring of a se a shared sense of reality and a shared sense of truth because if nothing is real, anything is possible. Hmm. There's something so, oh dare I say earth shattering about that. 'cause it's like at the core of wait, I can't trust my eyes anymore because you know, there's real evidence of wrongdoing now more and more people are deploying it and employing it. I have to ask you, when you see this happening and now you're tracking all of these examples, good and bad, where do you net out on your like zero to 10 scale of like excited to extremely scared spectrum?


I think I net in the middle. Hmm. Mostly because what this to me shows is the in incredible MISP prioritization of what we're innovating for on a sort of grander scale rather than like thinking about the social impacts. Silicon Valley has always been move fast break things. And I think the AI thing is always very interesting to me because it repeats so many of the mistakes of Web 2.0 the idea of deploying technologies before we know their social impact. The idea of not thinking about how something's gonna be used outside of the con exact context that you thought you were designing for.


Not necessarily being able to differentiate like what's real and good and what's not, not being able to control who uses your product. Like all of these sort of baseline things that we're still trying to figure out like we don't even understand on a policy level. And even I think on a company level, how we deal with content moderation that has been the conversation from basically 2010 onwards has been how do we deal with content moderation on Web 2.0 And instead of thinking about like how can we deal with this, it's all the same mistakes, all the same behaviors all over again in different iterations for the AI revolution. And it doesn't really feel like we've learned very much. Now it strikes me even Web 2.0 and you know, let's let's say social being a exemplification of that, it ended up being quite valuable in the, you know, election context as well.


Right. I remember reading this article where it's like when the nerds go marching into the White House, this is like Obama's reelection campaign circa 2012. And so I'm kind of curious, given the tools at our disposal, do you think that AI could be an effective policy messaging tool? If it can be factual and it seems like there are certain approaches to make it more factual than not. Yeah, I mean the biggest issue is transparency. So I think a really good example for instance is like Indonesia during their election this year, the man who was formerly the head of the military under the country's former dictator won that election and there were people who worked for his party that openly admitted to using AI and specifically to write campaign speeches.


And that's great except apparently they had built that on top of chat GPT, which OpenAI has said we don't want our product used for politics. How are they tracking that? How are they ensuring that's not happening? So I think like yeah there could be really valuable ways for this to be used for say, you know, campaign messaging or like the example that we saw in American Samoa where someone can sort of, as you sort of described like an asynchronous town hall, You know, this kind of brings me back to how you see social media factoring into all of this. I mean since the last presidential election we've seen how important it is, you know, in campaigning but also in spreading misin info and disinformation.


The FEC made a decision earlier this year that they wouldn't put new restrictions on AI and political ads, which means it'll be up on platforms. And you gave this example of somebody like illustrated the journey and stages of of their their life of in a campaign ad. What are platforms doing right now to like prepare for this like very pivotal year to curb perhaps AI generated content related to elections? Are they trying to get ahead of it or do you think it'll again be sort of more responsive and retroactive? So first off platforms, you know, everything they're doing right now is voluntary. Number two, you know, a lot of them have really leaned into labeling where they're, they're saying, you know, it has to be labeled if there's generated if AI content on our platform.


But so often it is very difficult for them to detect AI generated stuff on their platform. We don't really have a ton of transparency into how they're detecting this stuff, what systems they have in place. Companies are not necessarily sharing data back and forth about what's being generated on their platform. So something can be labeled consistently across platforms. And we saw this also with disinformation issues where like, you know, maybe something would get taken down on Twitter but it would live on Facebook or maybe it would get taken off of Facebook but they'd still be platformed on YouTube. Like you know, there's all these sort of gaps because these companies are not sharing information or coordinating with each other except on things like child sexual abuse material or like terrorism where there's actual legal implications.


Right. A lot of companies that have AI models have said, you know, we're gonna start watermarking, meaning that anything that comes off our platform, it'll have some sort of signature on it. Whether or not that's visible to a human or not, but that a machine can read to say, hey, this is AI generated. Okay, well that's great but that implies that everyone has to be a good actor. Yeah, exactly. Everyone has to agree to watermark and everyone has to be able to read everybody else's watermarks, right? If you're a bad actor, you have no incentive to use technology that's gonna watermark your content. You know, we're talking about something that's detectable by a machine, but will that be detectable by a human? Who knows? Yeah. This is gonna be so challenging.


You're totally right. It's like, yeah the good actors, you know, oh yes, you know, there happened to be some watermark in the image I uploaded from a commercial image generator. But are people as they scroll through their feed, even actually gonna care about that? And certainly bad actors are actively going to try and avoid, you know, either removing the watermark or using tech that doesn't have it. And that's on the visual side. I mean, I'm even curious sort of about like fake engagements and bots have been a thing for, for at least a half decade plus now this is a well-publicized strategy from 2016, right? Where Russia so discord on social media and their strategy was almost like, hey, let's just start stirring, you know, these sort of very polarizing issues and you know, you emulate the kind of rage bait that then drives engagement and it's a total mess.


And do you think there's a strategy for addressing sort of AI generated bot forms that can start impersonating voters and sort of add themselves to this public discourse? Yeah, I mean that is a massive problem. It's actually very interesting. Open AI released its first threat report at the end of May and what it showed actually was that foreign actors still are trying to figure out this technology. Like they still are not sure how useful it is, you know what I mean? Which I thought was very funny. I was like, oh I guess we're all confused. But we definitely do see instances of them. So really big strategy that we see in foreign influence operations is they will link to websites that are meant to look like a legitimate information source and then they will use generative AI to populate articles that reinforce certain political views.


Those articles then get shared on social platforms. So it's not necessarily the bots or the content themselves, although those sometimes are also AI generated. It's creating these websites that are populated with chat GPT style AI bullshit articles and then sharing those on social platforms. But we're definitely seeing foreign influence operations experiment with this. And again, I think, you know, it's one of those things like they're, they're, they're still testing it out too and seeing what's most effective After the break. I asked Victoria about how AI's reshaping elections around the world in ways you might not expect.


So good. So good. So good. Just in and so good thousands of winter deals are at Nordstrom Rack stores now and that means thousands of fresh reasons to rack 'cause we get the latest trends for way less. 'cause I've been looking for these Because the best deals go fast. Save big with up to 60% off Sam Edelman Rell Free people Cole ha and More Cold Weather finds great brands, great prices. That's why you rack.


Hey guys, have you heard of GoldBelly? It's this amazing site where they ship the most iconic famous foods from restaurants across the country, anywhere nationwide. I've never found a more perfect gift than food. They ship Chicago deep dish pizza, New York Bagels, Maine lobster rolls, and even Hena Garten's famous cakes. So if you're looking for a gift for the food lover in your life, head to goldbelly.com and get 20% off your first order with promo code gift.


So I, I wanna transition to global elections 'cause you know, as you mentioned the, the global angle here is very interesting 'cause oftentimes we're seeing, you know, the initial instantiations of these technologies being used both for good and bad overseas before it makes its way back here. It feels new to us in the United States and maybe even in Europe. But the rest of the world's like yo, we've been dealing with this so I've got friends in Pakistan who've been WhatsApping me. And they're like, yeah D fake politicians, you know, new voice recordings so common. There's like another one floats around on WhatsApp groups almost every week. So how has AI normalized this kind of content in Pakistan, South Asia, particularly India, Pakistan places with really high concentration of like highly educated people and tech talent.


That's where we're seeing a lot of this. And I think, you know in Pakistan there's, you know, the sort of legitimate use of this as we mentioned with Iran Khan. And then during the elections there were also deep fakes of local politicians telling people not to vote, telling people that they were dropping out of the race. And I think one of the big things, particularly from the global south is audio messages are particularly common, especially when people use WhatsApp. So there's a ton of instances of audio deep fakes and they are very difficult to detect because you're not gonna have the same signals that you would have with visual medium. Like hmm, that guy has six fingers or like, hmm that looks a little glitchy.


It's purely one medium and a lot of times it circulates on platforms like WhatsApp not publicly on social media like X or Facebook. It's circulating in these closed communities on encrypted platforms. It's incredibly difficult to detect and harder to debunk India and Pakistan. They both have a lot of really fabulous tech talent and we see a lot of companies coming up to service that market. But in general, most of the AI that tools that we're seeing and the tools to detect AI generated content are trained on and built for data from the Western market. When we're looking at markets in the global south, people are recording stuff on phones that are not as advanced as like an iPhone, meaning that the baseline quality of the content might be lower and that makes it so much harder for these detection tools for flag if something's fake.


False positives and false negatives are so much more common when stuff is coming off of these lower quality phones. Secondly, when you are working with markets that speak English in a non-Western way, so like pigeon forms of English accented English, there's more likely to have content that's flagged as a deep fake like AI notoriously bad when it comes to non-white people. And so I think when we're talking about places like Pakistan and the global south, you know, there is a lot of interest in these technologies there, but also the ways in which they are used and the ways in which they can or cannot be detected is totally different.


And these are all massive problems where like this kind of technology is entering these markets but also you know, creates all these other problems that frankly these companies, they're barely prioritizing working on issues here. You know? Totally. And I'm curious, you know, with all these instances, is it actually changing how people ended up voting or like change vote voter turnout? So I think that really depends on where you look at. A really great example came from actually a wired story that I didn't write. It was wrote written by a friend of mine, Nilesh Christopher and his reporting partner Varsha Bansal out of the Indian elections. There are a ton of AI companies that are coming up in India now servicing the Indian market and obviously India's a massively diverse place in terms of language, religion, culture, et cetera.


And they found that in the lead up to the Indian elections, a lot of local politicians were employing these AI companies to create DeepFakes of themselves similar to the Joe Biden robocall. But they were authorizing it and they were calling people's numbers, the numbers of their constituents. And you know, in the US we might consider that kind of thing really annoying and invasive. But what Lesh found was that actually people felt that sort of personalized outreach even though they knew it was an AI tool, even though they knew it was automated, they felt very seen by that and they felt very considered by that. And it actually did make them want to vote for a particular candidate to feel that they were getting this personalized attention through the use of these AI tools.


So in that way, you know, it can be extraordinarily powerful. In Indonesia for instance, during the campaign, Pao Subianto who ended up winning the election, the former general under the STO dictatorship, they used Midjourney to create a avatar of him looking very cute, friendly grandpa sort of vibes. And they shared those all over TikTok and it got 19 billion views and it definitely helped make him popular with young people who don't remember the Suharto dictatorship. They didn't live through it and so they were susceptible to this sort of softer image of him and that was totally authorized by the campaign.


You know, there are ways in which this technology can be used for campaigning and image management and all this stuff and that can really maybe affect how people perceive a particular candidate. Absolutely. I mean it's interesting the India example that you also brought up earlier. There was a company called Rephrase AI that would, Shara Khan, one of the biggest Bollywood actors, they did like a Cadbury chocolate advertising campaign where the call to action like purchase the chocolate was like the local confectionary store across all these regions. It's like, hey, if you're gonna go buy this stuff, go buy it from here. And now it's interesting to see this being applied in a political context. I think that could make a huge difference, right?


Like if it feels like personalized outreach. And then as far as distribution goes, right, there's the one-to-one stuff that we're talking about, there's the TikTok example maybe on the other end that you mentioned where it's like, yeah, if these videos go viral, of course that's gonna make a dent at least like put you top of mind for a lot of, presumably, you know, in this case young voters, the stuff in the middle, going back to WhatsApp seems more concerning 'cause it feels like harder to moderate and you know, stop the spread. Like I recall a few years ago in India around Kashmir there was a little bit of instability and sort of like the internet got shut off. But then also WhatsApp basically around that time instituted, hey, there's only a limited number of people we're gonna let you forward a message to.


And that the idea is like that's one way to sort of cap the spread because in ostensibly, if we're talking about end-to-end encrypted channels, like how the heck are you supposed to, you know, stop the spread of misinformation and by the time the analysts go and send it to like, I don't know, experts in Europe to go, you know, assess the deepfake like the damage has been done. Right? Yeah. Well and I think, you know, again, if everyone was sort of agreeing like, hey we're gonna watermark or we're gonna use a hashing tool for, so like that's how they deal with encrypted messengers. That's how they deal with like child sexual abuse materials hashing. So a image will be hashed, it'll be entered into a database, it'll have sort of the specific signature and If you try and send it before it even leaves your phone to sort of go into that space of being encrypted it, it'll be sort of like caught Yeah.


By the platform. And you will be unable to forward it Because you're looking it up against this database. Exactly. 'cause it'll, it'll be hashed again, right? Its sort of digital signature. The hash will will sort of ensure that. So maybe there would be a way to say we're gonna hash everything created by ai. Anything that you know gets forwarded that is, that can be sort of checked against this hash database auto label as ai, there might be a way to do that. Yeah. If everybody agreed and invested in that. But that's an immense amount of time technology like, and that's the thing that I think people don't really think about when we're talking about all this creation of AI generated content is now you're requiring the other side of it, which is detection. You know, now you've created a whole other industry that's also about detection and that also requires an immense amount of technology and investment and time and money to scale up to respond to this problem.


Totally. I really wanna Talks Odoo you about ai, Steve, you know, my mind was really blown and I think it's super, it's a super interesting story. So why don't you start by introducing AI Steve. Yeah, so he was a British political candidate who stood for parliament from the town of Brighton and ai, Steve was literally the candidate, he's the digital avatar of actual Steve, a real man named Steve who was running for office and, and sort of the way the campaign described it to me was actual Steve would be the physical embodiment of ai. Steve, he would be in parliament doing the negotiations, talking to people, but all of his decisions would be informed by ai, Steve and ai.


Steve was a sort of in that similar way, an AI avatar who could respond to constituents and collect their their questions. And the point of having this AI model was that constituents could say, here's what we care about, here's how we want you to vote on things, here are the issues that matter to us. And then real Steve's job was to go to Parliament and do the actions dictated by AI Steve and AI Steve did not win. But in principle I think that's a really interesting idea. And actually the campaign told me that the thing, two things that people were most interested in when they first launched it were the conflict in Gaza and trash collection. But you know, I think even then that has sort of its own limitations, right?


Because members of parliament, members of Congress get classified briefings all the time and are making decisions based on information that the general public may not have. And so there would still be a negotiation you'd need to have with that sort of campaign commitment to make all decisions in line with what the AI has been able to collect from constituents. Because the reality is the AI is not going to the classified national security briefing. The AI is not being given special documentation and numbers in the way that actual members of government are. And so there probably is a way for AI technology to be incorporated into a sense of good governance, but I think that's not what we're seeing prioritized and what's being built.


And that's certainly not necessarily, I think possible when the AI itself is the candidate. Right. Well you, you certainly answered my question of like how would this even work? And so it's almost like this is like a digital twin or proxy in the public domain for a politician. And really it's a way of sort of getting a pulse, you know, of your constituents like a pulse of the nation If you will. But this isn't the only example, right? There have been other examples of AI candidates around the world. Can you tell me the story about the Belarus elections earlier this year? Belarus is a dictatorship and one might argue a sort of proxy country of Russia.


The Russian military currently is staged out of be Belarus for its war in Ukraine and its dictatorship. The Lukashenko dictatorship is one of the last remaining ones in Europe and there has been incredible crackdowns on dissidents. One of the dissidents who is an exile created an an AI candidate called gas guar to run in the country's parliamentary elections. And obviously this candidate did not win the elections in Belarus earlier this year were widely regarded to be unfree. But because dissident is so criminalized in Belarus and because many of the people who might have actually stood for elections are in exile, this was sort of a way of using AI to represent those people.


You know, he can't be arrested, he cannot be subject to the ways in which the government has used force to crack down on dissidence in the past. So I think this was actually a very clever use of ai. Just like, you know, we saw people in the Middle East use social media to really power the Arab Spring. Like there are good generative democratic creative uses of these technologies and people will find those, but that doesn't mean that's always like what they're geared towards or the most common use of them. Totally, right? I mean this is a perfect example of AI being effective If you are a political dissident, right? Like I was blown away by that one quote in that article, which was basically like, yeah, this person can't be in prison because he's just code.


And I was like, wow, that's one way to give a voice to the voice list. So we've gone through a lot of aspects of the current state of, you know, let's just call it the state of AI elections in the US and some lessons learned from other countries. I think at this point I just have to take a step back and ask like how concerned should we really be about the ways that AI could affect the 2024 election In the us? I don't know yet. I think there are a lot of things at play and I think one of the things we didn't touch on, which is important to note, is that social platforms have rolled back their investment in trust and safety and trust and safety are the people and teams who make sure that hate speech, disinformation, all that stuff stays off the platform.


And then on top of that, we're sort of adding this extra layer. So I think we are certainly going to see a ton of AI bullshit on all the platforms. I think we're gonna see more of it. But I think the real thing is, personally I am less concerned about the elections themselves and more about what happens after we are in a moment where there is less and less and less trust than there's ever been. We have now Musk who owns X, he has already started seeding narratives around, you know, illegal immigrants voting things that could vary easily sort of form the intellectual foundation to question a democratic victory.


Those are old problems that platforms still haven't solved and I think we'll see AI play a role in those, whether that's through disinformation campaigns, whether that's through AI generated media, whether that's through, for instance, grok AI recently returned answers saying that Kamala Harris had missed the deadline to register to be on the ballot in nine states and the secretary's general of five of those states had to write to X and say your AI chatbot is spitting out bad information. I think we'll see things like that. But I think the core issues underlying this, which is a lack of investment in trust and safety, a lack of investment in thinking about the implications of these technologies and the safeguards necessary and real lack of trust and sense of reality in terms of the shared world we're living in and trust in institutions and systems.


Those underpin this question more deeply than any sort of variation in the technology could. That is a a very profound and nuanced answer to end on Victoria. Thanks for being on the show. Thank you. After talking with Victoria, I had a couple of ideas about how we can prepare for the next few months of the election season. The first thing I'm thinking about is actually something we covered in the very first episode of this podcast. When I spoke with Sam Gregory from Witness, he recommended a good exercise in media literacy that I think still applies beautifully sift as a refresher that stands for stop, investigate the source, find alternative coverage and trace down the original content that you think might not be legit.


Especially since the political landscape is changing at this unprecedented pace. It's very important to always hit those four steps and have a wide range of trusted sources at your disposal. But the second thing is a little harder to break down into specific steps because it has to do with this concept that Victoria brought up the Liar's dividend. That's the idea that in a world where anything can be falsified, nothing is real. And so it kind of doesn't matter. If you can identify disinformation out in the wild, its message can still very much influence people even when they know it's not true. It's why memes can be such powerful weapons for political messaging. They can bypass that part of our brains that question if something is real and go straight to our emotions.


When I saw those AI generated memes that I mentioned at the top of the episode, I realized that introducing this tool months before election day was opening the door for full blown mimetic warfare. Which means we're all going to have to come to terms with the fact that none of us are exempt from being influenced by content AI generated or not. It's gonna be hard, but we've got to modify our information diets. That means adjusting how we let content impact our perceptions of reality. There are some really exciting possibilities for AI technology to make politics more accessible, more representative, and maybe even more revolutionary. But ahead of our first AI election, it'll be up to us to learn from the rest of the world and chart our own path towards the future.


The TED AI Show is a part of the TED Audio Collective and is produced by TED with Cosmic Standard. Our producers are Ben Montoya and Alex Higgins. Our editors are Ban Ban Chang and Alejandra Salazar. Our showrunner is Ivana Tucker and our engineer is Asia Pilar Simpson. Our technical director is Jacob Winnick and our executive producer is Eliza Smith. Our researcher and fact checker is Christian Aparte and I'm your host. Bvo Sdu. See y'all in the next one.


So good. So good, So good. Just in and so good.


Thousands of winter deals are at Nordstrom Rack stores now, and that means thousands of fresh reasons to rack because we Get the latest trends for way less. 'cause I've been looking for these because The best deals go fast. Save big with up to 60% off. Sam Edelman Sorell Free people Cole Ha and More Cold Weather finds great brands, great prices. That's why you rack.


Oh my God, it's the coolest thing ever. Hey guys, have you heard of GoldBelly? Well check this out. It's this amazing site where they ship the most iconic, famous foods from restaurants across the country, anywhere nationwide. I've never found a more perfect gift than food. They ship Chicago deep dish pizza, New York Bagels, Maine lobster rolls, and even Ina Garden's famous cakes. Seriously. So if you're looking for a gift for the food lover in your life, head to goldbelly.com and get 20% off your first order with promo code gift,


No matter what branch you serve. Military roots run deep. At American Military University, we recognize the sacrifices of service members and their loved ones. That's why we extend our military tuition savings to your family tree, parents, spouses, legal partners, siblings and dependents all qualify for our preferred military rate of just two 50 per credit hour. American Military University savings for the whole family. Learn more@amu.aus.edu slash military.