
This message is brought to you by Apple Card. Apple Card is a no fee credit card that gives you daily cash back every day. That's 3% back at Apple and 2% back on every purchase made with Apple Card using Apple Pay. Apply for Apple Card in the Wallet app on your iPhone today. Subject to credit approval variable APRs for Apple Card range from 18.24% to 28.49% based on credit worthiness rates as of January 1st, 2025. Apple Card issued by Goldman Sachs Bank, USA, salt Lake City branch terms and more at Apple Card dot com. Aging is a natural process as we all know, and I for one, don't mind embracing it. But I will tell you one part of aging that I don't care for. It's the symptoms that stem from changing hormones, especially as you get older to perimenopause and menopause.


That's why we wanna tell you about Happy Mammoth Hormone Harmony. Happy Mammoth. The company that created Hormone Harmony is dedicated to making women's lives easier, and that means using only science-backed ingredients that have been proven to work for women. They make no compromise when it comes to quality and it shows for limited time. You can get 15% off on your entire first order@happymammoth.com. Just use the code Happy me at checkout. This episode is sponsored by SimpliSafe. I'm excited to tell you about a company revolutionizing home security. I am now using SimpliSafe and I'm so impressed by their active guard outdoor protection that uses AI powered cameras and real human agents to monitor what's happening outside my home rather than reacting after something's gone wrong.


SimpliSafe steps in. If something looks off it's security that thinks ahead. It's peace of mind that's become part of my daily rhythm. Arming my system each night knowing my home is protected. And you can try it this summer too with a 60 day money back guarantee. No contracts, no cancellation fees, just reliable protection starting at around a dollar a day. Listeners can get 50% off their new Simply Safe system with professional monitoring and their first month free@simplisafe.com slash TED Talks Daily. That's S-I-M-P-L-I safe.com/ TED Talks Daily.


There's no safe like SimpliSafe Life. You are listening to TED Talks Daily where we bring you new ideas and conversations to spark your curiosity every day. I'm your host, Elise Hugh. Back in 2017, technology ethicist Tristan Harris took to the TED stage to offer a prescient warning about the dangers of social media. Now he's out with another urgent concern about the most powerful technology we've ever created AI in this new talk, Tristan urges us to learn from the mistakes of the past and confront the consequences of what he calls a reckless deployment of AI technologies.


He says, a harmonious future with AI is possible so long as we choose it and make sure to come back to this speed later this afternoon. Tristan and I actually sat down in Vancouver right after his Talks. Odoo reflect more on his idea, his work and what keeps him going. So I've always been a technologist. And eight years ago on this stage, I was warning about the problems of social media, and I saw how a lack of clarity around the downsides of that technology and kind of an inability to really confront those consequences led to a totally preventable societal catastrophe.


And I'm here today because I don't want us to make that mistake with ai, and I want us to choose differently. So at TED, we're often here to dream about the possibles of new technology. And the possible with social media was obviously we're gonna give everyone a voice democratize speech, helping people connect with their friends, but we don't talk about the probable, what's actually likely to happen due to the incentives and how the business models of maximizing engagement I saw 10 years ago would obviously lead to rewarding doom, scrolling, more addiction, more distraction, and that resulted in the most anxious and depressed generation of our lifetime.


Now, it was interesting watching kind of how this happened because at first I saw people kind of doubt these consequences. You know, we didn't really want to face it. Then we said, well, maybe this is just a new moral panic and maybe this is just a reflexive fear of new technology. Then the data started rolling in, and then we said, well, this is just inevitable. This is just what happens when you connect people on the internet. But we had a chance to make a different choice about the business models of engagement. And had we made that choice 10 years ago, I want you to reimagine how different the world might have been if we had changed that incentive.


So I'm here today because we're here to talk about ai, and AI dwarfs the power of all other technologies combined. Now, why is that? Because If you make an advance and say biotech, that doesn't advance energy and rocketry. But If you make an advance in rocketry, that doesn't advance biotech. But when you make an advance in intelligence, artificial intelligence, that is generalized, intelligence is the basis for all scientific and technological progress. And so you get an explosion of scientific and technical capability, and that's why more money has gone into AI than any other technology. A different way to think about it is Dario Amai says that AI is like a country full of geniuses in a data center.


So imagine there's a map and a new country shows up on the world stage and it has a million Nobel Prize level geniuses in it, except they don't eat, they don't sleep, they don't complain. They work at superhuman speed, and they'll work for less than minimum wage. That is a crazy amount of power To give an intuition, there was about, you know, on the order of 50 Nobel Prize level scientists on the Manhattan Project working for five-ish years, what could a million Nobel prize level scientists create working 24 7 at superhuman speed now applied for good. That could bring about a world of truly unimaginable abundance because suddenly you get an explosion of benefits.


And we're already seeing many of these benefits land in our society from new antibiotics, new drugs, new materials, and this is the possible of AI bringing about a world of abundance. But what's the probable? Well, one way to think about the probable is how will AI's power get distributed in society? Imagine a two by two axis, and on the bottom we have decentralization of power, increasing the power of individuals in society, and the other is centralized power, increasing the power of states and CEOs. You can think of this as the let it rip axis, and this is the lock it down axis. So let it rip means we can open source AI's benefits for everyone.


Every business gets the benefits of ai. Every scientific lab, every 16-year-old can go on GitHub. Every, every developing world country can get their own AI model with their own train on their own language and culture. But because that power is not bound with responsibility, it also means that you get a flood of deep fakes that are overwhelming our information environment. You increase people's hacking avail, you enable people to do dangerous things with biology, and we call this end game attractor chaos. This is one of the probable outcomes when you decentralize. So in response to that, you might say, well, let's have regulated AI control. Let's do this in a safe way with a few players locking it down.


But that has a different set of failure modes of creating unprecedented concentrations of wealth and power locked up into a few companies. One way to think about it is, who would you trust to have a million times more power and wealth than any other actor in society, any company, any government, any individual. And so one of those end games is dystopia. So these are two obviously undesirable probable outcomes of AI's rollout. And those who want to focus on the benefits of open source, don't want to think about the things that come from chaos and those who want to think about the benefits of safety and regulated AI control.


Don't want to think about dystopia. And so obviously these are both bad outcomes that no one wants, and we should seek something like a narrow path where power is matched with responsibility at every level. Now, that assumes that this power is controllable because one of the unique things about AI is that the benefit is it can think for itself and make autonomous decisions. That's one of the things that makes it so powerful. And I used to be very skeptical when friends of mine who were in the AI community talked about the idea of AI scheming or lying. But unfortunately in the last few months, we are now seeing clear evidence of things that should be in the realm of science fiction actually happening in real life.


We're seeing clear evidence of many frontier AI models that will lie and scheme when they're told that they're about to be retrained or replaced and find a way, maybe they should copy their own code outside the system. We're seeing AI think that when they will lose a game that they'll sometimes cheat in order to win the game. We're seeing AI models that are unexpectedly attempting to modify its own code to extend their runtime. So we don't just have a country of Nobel Prize geniuses in a data center. We have a million deceptive power seeking and unstable geniuses in a data center. Now, this shouldn't make you very comfortable. You would think that with a technology this powerful and this uncontrollable that we would be releasing it with the most wisdom and the most discernment that we ever have of any technology.


But we're currently caught in a race to rollout because the incentives are, the more shortcuts you take to get market dominance or prove you have the latest capabilities, the more money you can raise and the more ahead you are in the race. And we're seeing whistleblowers at AI companies forfeit millions of dollars of stock options in order to warn the public about what's at stake if we don't do something about it. Even deep seeks recent success was in part based on capabilities that it was optimizing for by not actually focusing on protecting people from certain downsides. So just to summarize, we're currently releasing the most powerful inscrutable, uncontrollable technology we've ever invented that's already demonstrating behaviors of self preservation and deception that we only saw in science fiction movies.


We're releasing it faster than we've released any other technology in history and with under the maximum incentive to cut corners on safety. And we're doing this so that we can get to utopia. There's a word for what we're doing right now. This is insane. This is insane. Now, how many people in this room feel comfortable with this outcome? How many of you feel uncomfortable with this outcome? I see almost everyone's hands up. Do you think that if you're someone who's in China or in France or in the Middle East and you're part of building AI, that If you were exposed to the same set of facts, do you think you would feel any differently than anyone in this room?


There's a universal human experience to something that is being threatened by the way that we're currently rolling this profound technology out into society. So if this is crazy, why? Why are we doing it? Because people believe it's inevitable. But is the current way that we're rolling out AI actually inevitable? Like, like if literally no one on earth wanted this to happen, would, would the laws of physics push the AI out into society? There's a critical difference between believing it's inevitable, which is a self-fulfilling prophecy that you have to, you're fatalistic and standing from the place of, it's really difficult to imagine how we would do something different, but it's really difficult, opens up a whole new space of choice, then it's inevitable, the path that we're taking, not ai.


And so the ability for us to choose something else starts by stepping outside the self-fulfilling prophecy of inevitability. So what would it take to choose another path? I think it would take two fundamental things. First is that we have to agree that the current path is unacceptable. And the second is that we have to commit to find another path in which we're still rolling out ai, but with different incentives that are more discerning with foresight and where power is matched with responsibility. So thank you.


So imagine this shared understanding. If the whole world had it, how different might that be? Well, first of all, let's imagine it goes away and let's replace it with confusion about ai. Is it good? Is it bad? I don't know. It seems complicated. And in that world, the people building AI know that the world is confused and they believe, well, it's inevitable if I don't build it, someone else will. And they know that everyone else building AI also believes that. And so what's the rational thing for them to do, given those facts to race as fast as possible and meanwhile to ignore the consequences of what might come from them to look away from the downsides. But If you replace that confusion with global clarity that the current path is insane and that there is another path, and you take the denial of what we don't wanna look at.


And through witnessing that so clearly we pop through the prophecy of self-fulfilling inevitability, and we realize that if everyone believes the default path is insane, the rational choice is to coordinate to find another path. And so clarity creates agency. If we can be crystal clear, we can choose another path just as we could have with social media. And in the past, in the face of seemingly inevitable arms races, the race to do nuclear testing, once we got clear about the downside risks of nuclear tests and the world understood the science of that, we created the nuclear test ban treaty.


And a lot of people worked hard to create infrastructure to prevent that. You could have said it was inevitable that germline editing to edit human genomes and to have super soldiers and designer babies would set off an arms race between nations. Once the off target effects of genome editing were made clear and the dangers were made clear, we've coordinated on that too. You could have said that the ozone hole was just inevitable and that we should just do nothing and that we all perish as a species, but that's not what we do. When we recognize a problem, we solve the problem. It's not inevitable. And so what would it take to illuminate this narrow path? Well, it starts with common knowledge about frontier risks.


If everybody building AI knew the latest understanding about where these risks are arising from, we would have much more chance of illuminating the contours of this path. And there's some very basic steps we can take to prevent chaos, uncontroversial things like restricting AI companions for kids so that kids are not manipulated into taking their own lives, having basic things like product liability. So if you are liable as an AI developer for certain harms, that's gonna create a more responsible innovation environment. You release AI models that are more safe and on the side of preventing dystopia for working hard to prevent ubiquitous technological surveillance and having stronger whistleblower protections so that people don't need to sacrifice millions of dollars in order to warn the world about what we need to know.


And so we have a choice. Many of you may be feeling this looks hopeless or maybe tristan's wrong, maybe the, you know, the incentives are different, or maybe Superin intelligence will magically figure all this out and it'll bring us to a better world. But don't fall into the trap of the same wishful thinking and turning away that caused us to deal with social media. Your role in this is not to solve the whole problem, but your role in this is to be part of the collective immune system that when you hear this wishful thinking or the logic of inevitability and fatalism to say that this is not inevitable. And the best qualities of human nature is when we step up and make a choice about the future that we actually want for the people and the world that we love.


There is no definition of wisdom in any tradition that does not involve restraint. Restrained is a central feature of what it means to be wise, and AI is humanity's ultimate test and greatest invitation to step into our technological maturity. There is no room of adults working secretly to make sure that this turns out okay. We are the adults we have to be. And I believe another choice is possible with AI if we can commonly recognize what we have to do. And eight years from now, I'd like to come back to this stage not to talk about more problems with technology, but to celebrate how we stepped up and solved this one.


Thank you. That was Tristan Harris speaking at TED 2025. Again, make sure to come back later this afternoon for a special conversation between Tristan and me. If you're curious about Ted's curation, find out more at TED dot com slash curation guidelines. And that's it for today's show. TED Talks Daily is part of the TED Audio Collective. This episode was produced and edited by our team, Martha Esnos, Oliver Friedman, Brian Green, Lucy, little Alejandra Salazar, and Tanika SanMar Nivo. It was mixed by Christopher Fay Bogan. Additional support from Emma Toner and Daniella Rezo.


I'm Elise Hugh. I'll be back tomorrow with a fresh idea for your feed. Thanks for listening.


Goodday America. It's Tony and Ryan from the Tony and Ryan podcast From down under Today, we want to Talks Odoo you about Boost Mobile, the newest 5G network in the country. These guys are no longer the prepaid wireless company you might remember. They've invested billions, billions into building their own 5G towers across America, transforming the carrier into America's fourth major network alongside the other big dogs. Yep. They're challenging the competitors by working harder and smarter. Like this amazing new network they've literally built The Boost Mobile Network together with their roaming partners covers 99% of the US population, but 5G speeds not available in all areas. Yep, they have a blazing fast internet and plans for all the latest devices. Visit your nearest Boost mobile store or find them online@boostmobile.com.


We had a 1200% increase in sales using TikTok ads. My name is Linda and I'm a co-founder of Love and Pebble. We created Beauty Pops, a frozen facial that melt into nourishing Skincare. I started this business with my husband and we do everything from packing orders marketing. Before it was just me creating videos, but now I have over 2000 affiliates that are working with us. If we can do it with TikTok ads, you can too want To grow your business fast. Head over to get started.tiktok.com/tiktok ads.


Our world is marked by divisions and we're not sure how to engage neighbors across differences. I'm Nicole Argo, the founder and executive director at the Together Up Institute. And I'm Scott Hutchson, the executive director of E Pluribus Uno. On re-imagining us, we'll be talking to behavioral scientists, change makers and educators. Dear true stories of people bridging divides and finding common ground, Learn more at together up.org/reimagining us.