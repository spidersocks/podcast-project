
This message is brought to you by Apple Card. Apply for Apple Card today and start earning up to 3% daily cash back on everyday purchases. And that daily cash can even grow automatically when you open a high yield savings account through Apple Card. What are you waiting for? Visit Apple co slash card calculator today to see how much daily cash you can earn. Subject to credit approval savings, available to Apple Card owners, subject to eligibility, savings, and Apple Card by Goldman Sachs Bank, USA member, FDIC, terms and Moore at Apple Card dot com.


If you're anything like us, you love attention. And my favorite way to get all eyes on me is with next level shiny, glossy hair, which Is why we're so excited to tell y'all about the new Lameer Gloss collection from the Girlies at Tresme And Gigglers. We've got you too because Tresme partnered with us to bring you one 800 Gloss, A special bonus episode of Giggly Squad, where Hannah and I give advice on all things hair and giving gloss. Check out the episode and grab the Lamellar Gloss collection today because I'm officially declaring this spring gloss season.


This episode is sponsored by SimpliSafe. I'm excited to tell you about a company revolutionizing home security. I am now using SimpliSafe and I'm so impressed by their active guard outdoor protection that uses AI powered cameras and real human agents to monitor what's happening outside my home rather than reacting after something's gone wrong. SimpliSafe steps in. If something looks off it's security that thinks ahead. It's peace of mind that's become part of my daily rhythm. Arming my system each night knowing my home is protected. And you can try it this summer too, with a 60 day money back guarantee. No contracts, no cancellation fees, just reliable protection starting at around a dollar a day. Listeners can get 50% off their new Simply Safe system with professional monitoring and their first month free@simplysafe.com slash TED Talks Daily. That's S-I-M-P-L-I safe.com/ TED Talks Daily. There's no safe like SimpliSafe.


You are listening to TED Talks Daily where we bring you new ideas and conversations to spark your curiosity every day. I'm Kelly Corrigan. I'm a writer. I'm a podcaster. I'm a TED talker, and I am taking over for Elise Hugh this week for a special series on AI and Family Life. A guest curated a session about this topic at TED 2025, and I'm here now to share these very special talks with you along with behind the scenes recordings and personal insights that shed light on the process of bringing them to life.


So I was listening to another podcast and I heard this fabulous woman named Dr. Alison Darcy, and I admit I was swayed by her charming Irish accent, but also she has a very light touch in a very heavy world, which is creating AI therapy for people who probably wouldn't do therapy at all anywhere, anytime, but nonetheless need support. And so I wanted to have Allison share everything that her company, which is called Wobo, W-O-E-B-O-T, has learned by trying to be in this very soft, intimate place with people when they're struggling.


You know, when I was starting to learn about Wobo and Allison and the work that they've been doing, my initial reaction was negative and I was like, oh my God, this is the last thing people need. People need people. This is like, I'm on team human. I want everybody to be connecting with each other way more eyeball to eyeball, heart to heart. I wanted Allison to go first because I thought that as my initial reaction to the whole idea of AI and parenting was kind of like, sure, like they can sort through your schedule stuff. Like they can do logistics, but they're not gonna get involved in the deeper interactions that help kids come into themselves as adults.


Like that. That's just territory that will never be touched. And then all of a sudden it was like, oh no, of course that will be touched. Of course there are cases where AI will be better than some parents at some conversations. And so I turned to Allison to say, tell me everything about the 1.5 million people who have used robot, and help me understand how that might end up looking in the context specifically of family life to disavow the audience of this separation that they might have in their mind as I did that there's sort of a logistics level that AI could play at.


And then there's this very intimate emotional level that AI will never touch. I had to show them that AI was already in the intimate space in very meaningful ways. And so to start us off this week here is my conversation with Dr. Alison Darcy about the ways that AI might participate in the most intimate consequential conversations we ever have. Welcome. Hi. Thank you. So will you describe for us the average robot interaction? Sure. So, well, first of all, I suppose it's important to say that we built robot to meet an unmet need in 2017.


Depression was already the leading cause of disability worldwide. And I'm team human too, and I also really believe in what human therapists do. But you know, it doesn't matter how good a therapist is, you could be the best therapist in the world, but unless you're with your patient at 2:00 AM when they are having a panic attack, you can't help them in that moment. And you know, therapy doesn't happen in a vacuum. We all have real lives. And so, and I was a clinical research psychologist making some of the world's, you know, most sophisticated psychotherapeutic treatments and, but I was always haunted by this idea that like, it doesn't really matter how sophisticated the treatments are that we make if people can't access them.


Yeah. And so access has to be part of the design, and approachability has to be part of the design because what do you do at that 2:00 AM moment? And you can't think straight, you know, and you can't remember the thing that your therapist told you you should do in this moment. And so that for me is the why we built robot to meet people where they're at in those moments when it's actually hardest to reach out to another person. And How long do they stay with you? So it's, they're brief, very brief encounters. Six and a half minutes is the average length of time, and about 75 to 80% of all of those conversations are happening outside of clinic hours.


The longest conversations people have are between two and 5:00 AM Yeah. And is Woba good for role play? Actually, we have found that generative ai, so WO robot was built to be rules based. Everything robot says has been scripted by our writing team and under the supervision of, of clinical psychologists. And so wo robot will never, it's very safe. It's on the rails. WO robot will never make up something new. Fantastic. But we have been, you know, exploring the generative models and it turns out generative AI is really good for role plays. Yeah. And it kind of speaks to some of the advantages that AI have in that they're really good at doing the stuff that humans aren't so great at.


And I think role plays are one of those things for sure. Do people disclose more quickly with an AI than they would with a person? Yeah, so that was, that was shown in an early study in about 2015, I believe, that people would rather disclose to an AI than when they believe there's a human behind that. And that's particularly pronounced for things that are perceived as very stigmatized. And so yeah, there are, there's a sort of an advantage to being an AI in that it's never judge judging you. You don't have to think about how you appear to the ai. So yeah, When I think about it, I think there's at least four concerns come to mind.


One is price always, one is privacy. Always like who gets these transcripts? One is control. Like who defines what an AI responds and what theories and the, and these of change are they working from. But the one that scares the hell outta me is the perfection problem. And sometimes I wonder if we might inadvertently be creating the conditions for a total rejection of humanity of like dumb, boring, incomplete half asleep humans when you could have this thing that is so hyperresponsive. Do you feel like people, once they find robot, they never wanna leave it?


Definitely not. No. Well, because, but that's how it was designed, right? So, whoa, what would've been designed? It's, it all depends on what are you building the thing for. And if you're building it for, you know, human wellbeing, you know, human advancement, the, you know, objective is similar to a parent. You want the, the success looks like individuation and independence and, and growth. And that's partly, you know, challenging the idea of perfection. Just like you did. You know, a great AI should be helping you see that perfection is just an illusion, particularly when it comes to humans. That's what makes us human. And that's, you know, something to be celebrated. But of course, to your point, it really depends on who, who is the designer and what is this AI being built for that is going to be, and is such a crucial question, Which goes to business model.


Sure. So who pays for robot? Well, currently robot's distributed through part in partnership with health systems, but that's right. We build for, again, these short encounters, let people talk and be invited to use a skill that's inspired by one of these, you know, great therapeutic approaches like cognitive behavioral therapy, and then get them back to their life as soon as possible. Yeah. It's, we never bill for engagement, keeping people in the, in the conversation as long as they can, or which we just think is sort of a road to addiction, right? Yeah. And that's all about the incentive. That's Yeah. How are you being paid?


And as entrepreneurs, we all have a responsibility to ensure that the ais are in service of humans, not the other way around. Yeah. And I wonder if we create this dependence on AI therapy companions that you'll never be able to say, I did it myself. None of us will. Well, I still think the humans are doing it themselves, right. Because that's the beauty of an ai. It's not, and a great therapeutic process, If you like, while this isn't really therapy, right. Structurally it is so different. Yeah. But a great process is just asking the person the right questions.


They have to, they're the ones that have to do all of the work. They're the ones that have to shift their mindset or acknowledge their role in, you know, a conflict with somebody and or, or, you know, tune into their, their deepest, darkest negative thinking. And that stuff is hard and that is all on the person. Yeah. The AI is just gonna ask you the right questions to get there. So we would, you know, I don't think this isn't giving advice or giving a diagnosis. It, it's very much and should be about helping people develop their own resources. It's like, I use the analogy of a, you know, those mechanical machines that shoot tennis balls at people and that they can, so they can practice their swing Yeah.


To get better at the game with the human. Yeah. You know, the, these are fundamentally tools. I believe that, and I think they should be built like that. Yeah. And make sure that that is the objective function, If you like, is human betterment. Is there anything you do explicitly to push people back into IRL interactions or Oh, Right. Well, yeah, exactly. That would be part of, you know, robot's kind of value set. We, you know, we constantly would, would talk somebody through, Hey, you know, what, is this the, the point of avoidance? And if it is discomfort with other people, then robot will sort of encourage that person to, to follow through with speaking to another human.


And then we'll come back a few days later and say, Hey, you said you were gonna Talks Odoo Lucy, have you done it? And we find actually in our data that, aside from the daily sort of check-ins, which which facilitates sort of emotional self-awareness, that accountability is the thing that people find their most favored feature of this technology. Oh, that's Agree. So they want that kind of accountability. Yeah. What do you have, red lines has robots sat around and said, there's a whole set of things that people might do in this space that we are not gonna do. Yeah, absolutely. Loads. Like give advice, diagnose, give away data, sell data, especially to advertisers flirt, right?


Because that, that muddies the dynamic of what is happening here. You know, again, it has to be so clear. What is the purpose of this conversation and what are we trying to achieve? And staying within the, that boundary is really important. Is the, is the effectiveness of therapy getting better over time or is it this, is this sort of element in the mix maybe going to increase the efficacy across the board? Yeah. See, this is, this is the question. I think we haven't done a great job of innovating, I think in psychotherapy. Forgive me, I, I, you know, some of my best friends are clinical psychologists, but we're not doing a great job, you know, since founding the company.


Things are much, much worse now. And it's interesting seeing all of this incredible innovation and technological advancement and you know, where we haven't mo moved the needle at all. We are still as anxious and depressed as ever. And in fact, a, a recent World Health Organization survey or study found that 20% of high schoolers have seriously considered suicide. This is getting so much worse. So something needs to change. And I think we need to expand the aperture and bring in tools, additional tools. It's never about replacing the great human therapists that we have, but most people aren't getting in front of a, of a therapist.


And even if they are, they're not there beside you as you live your life. Yeah. Could you imagine a point where you could put an AI in the, on the kitchen table and then the family could have one of, its sort of little fights, shall we say? And then it would take the transcript and say, well Edward, you shouldn't have said this, and Kelly you interrupted and do, do, do. Like, could you imagine that kind of feedback on the dynamics that are keeping a family cycling on the same dumb patterns over and over not being personal at all here, Edward? Anyway, as you were saying that, I was imagining my own family.


I'm the youngest of six. And just thinking, I had a note that laptop flying through the window so fast. Yeah, totally. Yeah. Like, again, this, this is a tool set, I believe. And, you know, we can, we can build tools, we can use the tools in certain ways, but I, but I think you're bringing up something else that's interesting in that, you know, it's not about replicating the models of therapeutic approaches that were built for human delivery. I think it's about leaning into now what can the AI bring to the table that's, that's new and that's novel and that's specific to that technology, that tool set.


Yeah. And that's really, I think, the opportunity moving forward with these more, you know, advanced tools. I'm thinking about your comment about flirting and my best friend is pretty sure that her therapist falls asleep on her, but she has bangs and she can't tell if she's nodding off or just really thinking. And, and you know, obviously like all therapists vary, parents vary. Do you have a thought about which has more potential for damage an AI or a human? That is a big question.


I think that ais have plenty of potential for damage, as do humans. And it's very early days with the technology. The thing is that we have the opportunity to develop ais with intentionality. And of course there are unintended consequences and we need to build those structures in addition to be able to monitor and watch those and take advantage of positive directions. So, so we'll see. Fundamentally these are just tools and also humanity is, is humanity for a reason. You know, there are things that are common.


Pain is something that is common to all of us, and we will all go through difficult moments. We will all experience grief, we will all lose a loved one. And it's about understanding how we're gonna work together. But yeah, just to reiterate that point, we have to make sure that the, the tech is in service of humans, not the other way around. Thank you so much for coming to TED. We have much more after a short break. So 12 minutes is not a very long conversation. I have to say that from the start.


And so we were so constrained. I don't think I've ever done a 12 minute interview in my life, and I've interviewed probably six or 700 people over the years. So it was my job upfront to reduce the number of questions from like 18 was the number that I really wanted to ask in a perfect world down to something like four or five so that she could really open up the topic. There's just one thing that I'm missing from having sure heard This, that's Lucy Little, my producer Lucy was one of several TED staffers who gave feedback on earlier stages of the conversation. I do think the, the question of where is this AI learning that's information from like who?


Oh, Oh yeah. Oh yeah, Yeah. 'cause I think that's a huge, Oh yeah, we should say that from the outset, right? So that people realize this is not a generative ai. Yeah. So this is, yeah, we're that what every, like robot's, so old school in lots of ways, it's like the retro AI therapist, it's everything robot says has been scripted. So we're using sort of machine learning and natural language processing to understand what people are saying in key areas. But the, it's a simulation of a conversation. So it's very on the rails now. We, where we've used large language models, it has been to, you know, tap into their power to better understand what the person is saying. But fundamentally it's just not, it's not trained on the internet.


Right. So I think we wanna say, get to this really good note, two things at the top, which is it's based on CBT and it's scripted, it's not generative. Yeah. And that's quite a lot of heady thinking. If I can only touch on four or five ideas here, what are the most salient, essential ideas such that as you go through the rest of the session where you're gonna meet these other five speakers, you are positioned in the best possible way to process what people are putting in front of you.


So the first thing that Allison clarified for me that I thought was essential and doesn't get talked about enough, honestly, is who pays for the product and how will the product be evaluated in terms of its efficacy? Because if the profit motive involves keeping people on the app longer so that you can say, collect more data or place more ads, the app will be designed in one way, which could be in Feeing, it could be creating this terrible dependency where a person becomes less strong and less independent and less confident in their own instincts and more addicted to this little assistant who's gonna tell them what to say or do every time they have a strange interaction with somebody in their life, It sort of forces people into a direct to consumer construct, which then has the danger of, of forcing innovators into this place where they're now just trying to hijack attention and build for addiction and not actual wellbeing.


Right? Right. So that, so I think that the big frustration is not the limitation of the tech per se, it's, it's trying to find the construct where it can live and be ethical still and be built around an objective function of human wellbeing. But when it comes to robot, I was relieved to know that they're paid by insurers based on wellbeing metrics. The biggest shift in my feelings, thanks to talking to Allison, is this possible partnership between people and ai. Like, one thing that she said during one of the pre-calls was that for some people the way that robot is talking to them is a model for the ways they could be talking to the people in their own lives.


What we are talking about, I think is making it easier to disclose, to, to share something and have practice with sharing that thing. That's what we've noticed from robot is like, you're right, people are going to robot with things they may never have shared with another person, but it makes them more likely to then go on and share it with somebody else. Like it's a practice of externalization. It's very helpful to be in a healthy interaction and see how that flows, which is basically like asking follow-up questions, making sure that you understood what the person said and meant. All of that gets modeled in these AI conversations so regularly that it does seem reasonable that a person might start using those same techniques, follow up questions, confirming that you understand what they really meant in their live interactions with other people.


And that would be a tremendous step forward. I mean, if people Talks Odoo each other that way with more intention to understand, less determined to be understood, people might get somewhere, relationships would change. Another huge takeaway from being with Allison throughout the prep period, and then also sitting across from her in front of all those people was that we should know who's behind ai. Because when you meet somebody that lovely, charming and conscientious, you feel very differently about ai, which is so anonymous in its nature.


But the way that Allison was talking about it, it's not at all that it's something that Allison and the people that she has recruited based on their knowledge of cognitive behavioral therapy, what those techniques are and what makes it effective, what they're putting in front of us. So it's nice to put a face behind these big huge letters that seem to be like towering over everything. A I, One of the things I've been thinking about since TED, in terms of everything I learned by getting to know Allison and W Robot is could there be a really smart, effective way to use an ingestion AI to observe, If you will, a family interaction or a couple's interaction or an interaction between a parent and a child and give notes back to all involved?


Loads of people say to me, but when I'm a therapist, you know, I'm reading the, the, the nonverbal communication in the room and I say, well, you're doing that because you're human and that, you know, humans are not, as we know this, aren't as able to disclose to another human as they are to an ai. And so, you know, it's a, it is actually a very different dynamic and the AI dynamic doesn't necessarily read, need to read nonverbal communication, I would say with the massive asterisk. And the asterisk is, I don't know how an AI would fare when it's not looking at the, the the nonverbal Communication. Right, because like one eye roll Exactly. Exactly. Is big is louder than all. Yeah. So theoretically it might be, it might be useful, but I would say a behavioral family therapy as I was, you know, trained to do it, that's a bit better of a fit because the therapist role there is as expert.


What about if wo robot or another AI is treating all the members of a family? Mm. If impartial, unbiased robot was talking to me and my brothers and my parents, maybe it could help me by saying, here's what your brother's really mad about from that vacation in 1978. But it's the important thing for you to have that insight or is it for your brother to be able to share, have the insight and share that with you? The only tension I felt was like, was it to the greater good that there was an AI that could walk you through some of your cognitive distortions at two in the morning?


Or is it important in some way that we learn how to do that moment alone? I think at the end of the day, maybe the most important takeaway from talking to Allison is a process point. It's like, how are you evaluating AI options that are gonna come across your desk? Like, could we be smarter consumers and advisors to one another as options become available? I wonder if AI is going to be a great new receptacle for very scary thoughts. Like, I tried cocaine, or my boyfriend wants to try choking.


Oh Yeah, okay. That You, there's no way my children are gonna come to me with that. Yes. And they never would have. Yes. But will they come to you and then what will, what is the responsibility of a company who's in that conversation? Yeah. This is a real topical issue because while some of these ais right now used for this purpose wouldn't necessarily be covered by the same law as a confidential therapist patient relationship, we feel that people using it may feel it is. And so we actually try and hit those things regardless. We treat it as if it is a confidential relationship.


Okay. So for example, where we are working with a health setting where they have in the past and they have asked for the full transcript data, we, we've absolutely said no way. And we've walked away from deals to say there's no way those things are, they're sacred. They are sacred is, and while they're not protected by law in the same way as a patient therapist notes are, we hold it to that same bar. But of course there is no law. So we are one company among many that are doing this right now. So that's just something to note. And I think we're getting smarter through Allison's talk and the talks that are coming up about how we evaluate, what questions would we ask of the developer and the designer and the company that's offering us these certain products.


How would we know who to work with and who to let in? Because we begin the interaction, we say yes to something and it enters our home. And I think it's already been clear that we were asleep when we let social media enter our lives. And I think many people were asleep when they let something like Alexa into their lives. Like, I think you have to know exactly what is in those terms and conditions that we're all clicking. Okay. Okay. Okay. Before you open the door to your most private spaces.


Well, I, I think it is interesting. I think that a lot of people aren't comfortable. That's Chloe Sasha Brooks, the TED curator who was my guiding light through this entire process during my first exploratory call with Allison At the same time. I think that the way that you're talking about it, Allison, is extremely reasonable. Like, I think you really have a clear sense of the boundaries and the lines that we need to draw between what is human and what isn't. I think to me, the bigger question for people listening to this would be what if the boundaries that we set around this or that our intentions set up for this get violated just by nature of the thing spinning out of control.


Yeah. And so how do we prevent that? Can we prevent that? Yeah. Like I, I know, and, and that's right. And I, I think one of the challenges we have in the field of AI is that most people don't understand the tech. And so it's so easy to scare and scare monger. But you have to imagine, you know, when we say they can self-improve, you still have to tell it. How are you improving? That's the objective function. What is the objective function and what are you proving towards? We still get to say that's human empowerment. That is human wellbeing, right? But they are still just tools.


And that's it for today. Come back tomorrow for the legendary anthropologist, Sarah Blaffer Herty. TED Talks Daily is part of the TED Audio Collective. This episode was produced in mixed by Lucy, little, edited by Alejandra Salazar and fact checked by the TED research team. The TED Talks Daily team includes Martha Anos, Oliver Friedman, Brian Green, and Sica Smar Nivan. Additional support from Emma Tabner and Daniella Rezo. I'm Kelly Corrigan, guest host of TED Talks Daily here for a special week of content around the topic of AI and family life.


And please join me at my podcast, Kelly Corrigan wonders, wherever you listen to podcasts. I'll be back tomorrow. Thanks for listening. I mean, this is a total overstatement, but do you think everybody, every family should have Like a, a robot as part of their family unit? I don't, I I think everyone can use a personal ally and I think AI need to be, should be constructed to so that they're, you know, they, they actually help the human condition and that that's their prime objective. But the AI in the family unit is something I have to say. I must confess even a being trained family therapist I've never really thought about before.


Isn't that interesting? Why is that? I dunno, I've never told that. Thank God we met. Opening a whole new thing for you. Just kicked open the door.


This episode is brought to you by Progressive Insurance. Do you ever think about switching insurance companies to see If you could save some cash? Progressive makes it easy to see If you could save. When you bundle your home and auto policies, try it@progressive.com. Progressive casualty insurance company and affiliates. Potential savings will vary not available in all states.


Hi friends. Ika from Side Hustle Pro here. Whether you're running a nonprofit, a school, or a small business, Walmart business is here to support your mission. They make it easy to order what you need from tech and cleaning supplies to everyday essentials, all at low prices, and with helpful tools like spend tracking and tax exempt purchasing for eligible organizations. Because when your operations are smooth, your impact can be bigger. Visit business.walmart.com to get started.


This is Paige, the co-host of Giggly Squad. I use Uber Eats for everything. And I feel like people forget that you can truly order anything, especially living in New York City. It's why I love it. You can get Chinese food at any time of night, but it's not just for food. I order from CVS all the time. I'm always ordering from the grocery store. If a friend stops over, I have to order champagne. I also have this thing that whenever I travel, if I'm ever in a hotel room, I never feel like I'm missing something because I'll just Uber eats it. The amount of times I've had to Uber eats hair items like hairspray, I deodorant, you name it, I've ordered it on Uber Eats. You can get grocery alcohol, everyday essentials in addition to restaurants and food you love. So in other words, get almost anything with Uber Eats. Order now for alcohol. You must be legal drinking age. Please enjoy responsibly. Product availability varies by region. See app for details.