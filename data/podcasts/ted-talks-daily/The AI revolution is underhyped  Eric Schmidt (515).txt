
Hey, TED Talks Daily. Listeners, it's Elise. Thank you for making this show part of your daily routine. We really appreciate it and we wanna make it even better for you. So we put together a quick survey and we'd love to hear your thoughts. It's listener survey time. It only takes a few minutes, but it really helps us shape the show and get to know you. Our listeners, so much better head to the episode description to find the link to the listener survey. We would really appreciate you doing it. Thank you so much for taking the time to help the show


Location. The lab, Quentin only has 24 hours to sell his car. Is that even possible? He goes to carvana.com. What is this? A movie trailer? He ignores the doubters, enters his license plate. Wow, that's a great offer. The car is sold, but will Carvana pick it up in time for it? They'll Literally pick it up tomorrow morning. Done with the dramatics Car selling in record time. Save your time. Go to carvana.com and sell your car today. Pick up these may apply.


This episode is sponsored by SimpliSafe. I'm excited to tell you about a company revolutionizing home security. I am now using SimpliSafe and I'm so impressed by their active guard outdoor protection that uses AI powered cameras and real human agents to monitor what's happening outside my home rather than reacting after something's gone wrong. SimpliSafe steps in. If something looks off it's security that thinks ahead. It's peace of mind. That's become part of my daily rhythm. Arming my system each night knowing my home is protected. And you can try it this summer too with a 60 day money back guarantee. No contracts, no cancellation fees, just reliable protection starting at around a dollar a day. Listeners can get 50% off their new Simply Safe system with professional monitoring and their first month free@simplysafe.com slash TED Talks Daily. That's S-I-M-P-L-I safe.com/ TED Talks Daily. There's no safe like SimpliSafe.


This episode is sponsored by monday.com. Let's face it. Work today moves fast, but monday.com is here to help with their work management product, which enables you to reach your full potential. It's built for more than just marketing teams. It connects entire organizations to gain full visibility, make better decisions, and bridge the gap between strategy and execution. The platform gives you realtime insights into campaigns, content and projects, so you can see what's working. Shift gears when needed and make data backed decisions without the guesswork. You'll go from being reactive to strategic plus with built-in AI capabilities. Monday Work Management helps your team work smarter, not harder. Maximize your marketing impact with the first work product you and your team will love to use. Visit us@monday.com to learn more.


You're listening to TED Talks Daily where we bring you new ideas and conversations to spark your curiosity every day. I'm your host, Elise Hugh. AI and the future of humanity were huge topics at this year's TED Conference. Central to all of this was a pretty existential question in today's world, what is a human actually for? To add to this discussion, Google's former CEO and chairman Eric Schmidt joined creative technologist Bala Du for a conversation about AI and our collective future. They discuss what, if any, are the limits of ai, ethical questions about its rising use across various sectors, and why the AI revolution, as Eric puts it, is under hyped.


Eric Schmidt, thank you for joining us. Thank you. You said The arrival of non human intelligence is a very big deal. What did you see that the rest of us might have missed? In 2016, we didn't understand what was now going to happen, but we understood that these algorithms were new and powerful. There was a new move invented by AI in a game that had been around for 2,500 years that no one had ever seen. Technically, the way this occurred was that the system of AlphaGo was, was essentially organized to always maintain a greater than 50% chance of winning. And so it calculated correctly this move, which was this great mystery among all of the go players who are obviously insanely brilliant mathematical and intuitive players.


The question that Henry Craig Mundy and I started to discuss, right, is what? What does this mean? How is it that our computers could come up with something that humans had never thought about? I mean, this is a game played by billions of people, and that began the process that led to two books. And I think frankly is the, is the point at which the revolution really started. If you fast forward to today, it seems that all anyone can talk about is ai, especially here at TED. But you've taken a contrarian stance. You actually think AI is under hyped.


Why is that? And I'll tell, I'll tell you why. Most of you think of AI as, I'll just use the general term as chat. GPT. For most of you, chat was the moment where you said, oh my God, this thing writes and it makes mistakes, but it's so brilliantly verbal, right? That was certainly my reaction. Most people that I knew did that. It was visceral. Yeah, This was two years ago. Since then, the gains in what is called reinforcement learning, which is what AlphaGo helped invent and so forth, allow us to do planning. And a good example is look at open AI oh three or deep seek R one, and you can see how it goes forward and back forward and back forward and back.


It's extraordinary. In my case, I bought a rocket company because it was like interesting. And I Know as one does, as One does, and it's, it's an area that I'm not an expert in and I want to be an expert. So I'm using deep research and these systems are spending 15 minutes writing these deep papers. It's true for most of them. Do you have any idea how much computation 15 minutes of these supercomputers is? It's extraordinary. So you're seeing the arrival, the shift from language to language, then you have language to sequence, which is how biology is done. Now you're doing essentially planning and strategy. The eventual state of this is the computers running all business processes, right?


So you have an agent to do this, an agent to do this, an agent to do this, an agent to do this, and you concatenate them together and they speak language among each other. They typically speak English language. I mean, speaking of, of just the sheer compute requirements of these systems. Let's talk about scale briefly. You know, I kind of think of these AI systems as hungry, hungry hippos. They seemingly soak up all the data and compute that we throw at them. They've already digested all the tokens on the public internet, and it seems we can't build data centers fast enough. What do you think the real limits are and how do we get ahead of them before they start throttling AI progress? So there's a real limit in energy.


I'll give you an example. There's one calculation, and I testified on this this week in Congress that we need another 90 gigawatts of power in America. My answer, by the way, is think Canada, right? Nice people full of hydroelectric power, but that's apparently not the political mood right now. Sorry. So 90 gigawatts is 90 nuclear power plants in America. Not happening. We're building zero, right? How are we gonna get all that power? This is a major, major national issue. You can use the Arab world, which is busy building five to 10 gigawatts of data centers.


India is considering a 10 gigawatt data center to understand how big gigawatts are is think cities per data center. That's how much power these things need. And the people look at it and they say, well, there's lots of algorithmic improvements and you will need less power. There's an old rule, I'm old enough to remember right? Grove giveth gates taketh away. Okay, the hardware just gets faster and faster. The physicists are amazing, just incredible what they've been able to do. And us software people, we just use it and use it and use it. And when you look at planning to, at least in today's algorithms, it's back and forth and try this and that and just watch it yourself.


There are estimates, and you know this from from inducing Horowitz reports, it's been well studied that there's an increase in at least a factor of a hundred, maybe a factor of a thousand in computation required just to do the kind of planning there. The technology goes from essentially deep learning to reinforcement learning to something called test time compute, where not only are you doing planning, but you're also learning while you're doing planning. That is the, If you will, the zenith or what have you of computation needs. That's problem number one, electricity and hardware. Problem number two is we ran out of data, so we have to start generating it, but we can easily do that because that's one of the functions.


And then the third question that I don't understand is what's the limit of knowledge? I'll, I'll give you an example. Let's imagine we are collectively all of the computers in the world and we're all thinking, and we're all thinking based on knowledge that exists that was previously invented. How do we invent something completely new? So Einstein, so when you study the way scientific discovery works, biology, math, so forth and so on, what typically happens is a truly brilliant human being looks at one area and says, I see a pattern that's in a completely different area, has nothing to do with the first one. It's the same pattern.


And they take the tools from one and they apply it to another. Today, our systems cannot do that. If we can get through that, I'm working on this. It's a general technical term for this is non stationarity of objectives. The the rules are keep changing. We will see if we can solve that problem. If we can solve that, we're gonna need even more data centers. And we'll also be able to invent completely new schools of scientific and intellectual thought, which will be incredible. So as we push towards a zenith, autonomy has been a big topic of discussion. Joshua Bengio gave a compelling talk earlier this week advocating that AI labs should halt the development of ag agentic AI systems that are capable of taking autonomous action.


Yet that is precisely what the next frontier is for all these AI labs and seemingly for yourself too. What is the right decision here? So Joshua is a brilliant inventor of much of what we're talking about and a good personal friend, and we've talked about this and his concerns are very legitimate. The question is not already his concerns, right? But what are the solutions? So let's think about agents. So for purposes of argument, everyone in the audience is an agent. You have an input that's English for or whatever language, and you have an output that's English, and you have memory, which is true of all humans. Now we're all busy working and all of a sudden one of you decides it's much more efficient not to use human language, but we'll invent our own computer language, uhoh.


Now you and I are sitting here watching all of this and we're saying like, what do we do now? The correct answer is unplug you, right? Because we're not going to know we, we're just not gonna know what you're up to and you might actually be doing something really bad or really amazing. We want to be able to watch. So we need Providence, something you and I have talked about. Yeah, but we also need to be able to observe it. That's a, to me, that's a core requirement. There's a set of criteria that the industry believes are points where you want to metaphorically unplug it. One is where you get recursive self-improvement, which you can't control. Recursive self-improvement is where the computer is off learning and you don't know what it's learning.


That can obviously lead to bad outcomes. Another one would be direct access to weapons. Another one would be that the computer systems decide to exfiltrate themselves to reproduce themselves without our permission. So there's a set of such things. The problem with Joshua's speech with respect to such a brilliant person is stopping things in a globally competitive market doesn't really work. Instead of stopping ag agentic work, we need to find a way to establish the guardrails, which I know you agree with 'cause we talked about it. I think that brings us nicely to the dilemmas, and let's just say there are a lot of them when it comes to this technology.


The first one I'd love to start with, Eric, is the exceedingly dual use nature of this tech, right? It's applicable to both civilian and military applications. So how do you broadly think about the dilemmas and ethical quandaries that come with this tech and how humans deploy them? In many cases, we already have doctrines about personal responsibility. A simple example, I did a lot of military work and continue to do so. The US military has a rule called 3000.09, generally known as human in the loop or meaningful human control. You don't want systems that are not under our control. It's like it's a line we can't cross. I think that's correct.


I think that the competition between the west and particularly the United States and China is going to be defining in this area, and I'll give you some examples. First, the current government has now put in essentially reciprocating 145% tariffs. That has huge implications for the supply chain. We, we in our industry depend on packaging and components from China that are boring, If you will, but incredibly important, the little packaging and the little glue things and so forth that are part of the computers. If China were to deny access to them, that would be a big deal. We are trying to deny them access to the most advanced chips, which they're super annoyed about.


Dr. Kissinger asked Craig and I to do track two dialogues with the Chinese and we're in conversations with them. What's the number one issue? There is this issue. Indeed, If you look at deep sea, which is really impressive, they managed to find algorithms that got around the problems by making them more efficient, right? Because China is doing everything. Open source, open weights. We immediately got the benefit of their invention and have adopted into us things. So we're in a situation now, which I think is quite tenuous, where the US is largely driving for many, many good reasons, largely closed models, largely under very good control. China is likely to be the leader in open source unless something changes and open source leads to very rapid proliferation around the world.


Hmm. This proliferation is dangerous at the cyber level and the bio level, but let me give you why it's also dangerous in, in a more significant way, in a nuclear threat way. Dr. Kissinger, who we all worked with very closely, was one of the architects of mutual assured destruction, deterrence and so forth. And what's happening now is you've got a situation where I'll, I'll use an example. It's easier if I explain you're the good guy and I'm the bad guy, okay? You're six months ahead of me and we're both on the same path of our super intelligence and you're going to get there, right? And I'm sure you're gonna get there. You know, you're that close and I'm six months behind. Pretty good, right?


Sounds pretty good. It. No, these are network effect businesses. And in network effect businesses, it is the slope of your improvement that determines everything. So open. I use OpenAI or Gemini, they have a thousand programmers. They're in the process of creating a million AI software programmers. What does that do? First, you don't have to feed them except electricity. So that's good. Second, they don't quit and things like that. If you get there first, you dastardly person. You're never never gonna be able to catch me. I will not be able to catch you. And I've given you the tools to reinvent the world and in particular destroy me.


That's how my brain, Mr. Evil is gonna think. So what am I gonna do? The first thing, sabotage. The first thing I'm gonna do is try to steal all your code and you've prevented that 'cause you're good and you, you were good. So you're still good at gula. Second that, then I'm gonna infiltrate you with humans. Well, you've got good protections against that. You know, we don't have spa. So what do I do? Hmm? I'm gonna go in and I'm going to change your model. I'm gonna modify it. I'm gonna actually screw you up to get me. So I'm one day ahead of you and you're so good. I can't do that. What's my next choice? Bomb your data center. Wow. Now do you think I'm insane.


These conversations are occurring around nuclear opponents today. In our world there are legitimate people saying the only solution to this problem is preemption. Now I just told you that you, Mr. Good, are about to have the keys to control the entire world, both in terms of economic dominance, innovation, surveillance, whatever it is that you care about. I have to prevent that we don't have any language in our society. The foreign policy people have not thought about this and this is coming, when is it coming? Probably five years. We have time. We have time for this conversation.


And this is really important. Let me push on this a little bit. So if this is true, and we can end up in this sort of standoff scenario and sort of the equivalent of mutually assured destruction. You've also said that the US should embrace open source AI even after China's deep seek showed what's possible with a fraction of the compute, but doesn't open sourcing these models, just like hand capabilities to adversaries that'll accelerate their own timelines. This is one of the wickedest, or we call them wicked hard problems. Our industry, our science, everything about the world that we have built is based on academic research, open source, so forth. Much of Google's technology was based on open source. Some of Google's technology is open source, some of it is proprietary, perfectly legitimate.


What happens when there's an open source model that is really dangerous and it gets into the hands of the Osama bin Ladens of the world. And we know there are more than than one. Unfortunately we don't know. The consensus in the industry right now is the open source models are not quite at the point of national or global danger. But you can see a pattern where they might get there. So a lot will now depend upon the key decisions made in the US and China and in the companies in both places. The reason I focus on US and China is they're the only two countries where people are crazy enough to spend the billions and billions of dollars that are required to build this new vision.


Europe, which would love to do it, doesn't have the capital structure to do it. Most of the other countries, not even India has the capital structure to do it all they wish to. Arabs don't have the capital structure to do it, although they're working on it. So this fight, this battle will be the defining battle. I'm worried about this fight. Dr. Kissinger talked about the likely path to war with China was by accident and he was a student of World War I and of course world. I started with a small event and it escalated over that summer in I think 1914 and, and then it was this horrific conflagration. You can imagine a series of steps along the lines of what I'm talking about that could lead us to a horrific global outcome.


That's why we have to be paying attention. I wanna talk about one of the recurring tensions here before we move on to onto the dreams, is to sort of moderate these AI systems at scale, right? There's this weird tension in AI safety that the solution to preventing 1984 often sounds a lot like 1984. So proof of personhood is a hot topic. Moderating these systems at scale is a hot topic. How do you view that trade off, right? Like in trying to prevent dystopia, let's say preventing non-state actors from using these models in undesirable ways, we might accidentally end up building the ultimate surveillance state. It's really important that we stick to the values that we have in our society.


I am very, very committed to individual freedom. It's very easy for a well-intentioned engineer to build a system which is optimized and restricts your freedom. So it's very important that human freedom be preserved in this. A lot of these are not technical issues. They're really business decisions. It's certainly possible to build a surveillance state, but it's also possible to build one that's freeing. The conundrum that you're describing is because it's now so easy to operate based on misinformation. Everyone knows what I'm talking about, that you really do need proof of identity. But proof of identity does not have to include details. Mm. So for example, you could have a cryptographic proof that you are a human being and they could actually be true without anything else.


And also not court, not be able to link it to others using various cryptographic techniques. So zero knowledge proofs and other techniques like That. Yes. Zero knowledge proofs are the most obvious one. Alright, let's change gears, shall we to dreams. In your book Genesis, you strike a cautiously optimistic tone, which you obviously co-authored with Henry Kissinger. When you look ahead to the future, what should we all be excited about? Well, I'm, I'm of the age where some of my friends are getting really dread diseases. Can we fix that now? Can we just eliminate all of those? Why can't we just uptake these and right now eradicate the all of these diseases?


That's a pretty, that's a pretty good goal. I'm aware of one nonprofit that's trying to identify in the next two years, all human druggable targets and release it to the scientists. If you know the druggable targets, then the, then the drug industry can begin to work on things. I have another company I'm associated with, which has figured out a way, allegedly was a startup to reduce the cost of stage three trials by a order of magnitude. As you know, those are the things that ultimately drive the cost structure of drugs. That's an example. I'd like to know where dark energy is, and I'd like to find it. I'm sure that there is an enormous amount of physics in dark energy, dark matter.


Hmm. And think about the revolution in material science. Infinitely more powerful transportation, infinitely more powerful science and so forth. Give you another example. Why do we not have every, every human being on the planet have their own tutor in their own language to help them learn something new? Starting with kindergarten, it's obvious. Why have we not built it? The answer, the only possible answer is there must not be a good economic argument. The technology works. Teach them in their language, gamify the learning. Bring people to their best natural names. Another example, the vast majority of healthcare in the world is either absent or delivered by the equivalent of nurse practitioners and very, very sort of stressed local village doctors.


Why do they not have the doctor assistant that helps them in their language treat whatever with again, perfect healthcare. I can just go on. There are lots and lots of issues with this world of the digital, the digital world. It feels like that we're all in our own ships in the ocean and we're not talking to each other in our hunger for connectivity and connection. We are making these tools make us lonelier. We've gotta fix that, right? But these are fixable problems. They're, they don't require new physics. They don't require new discoveries. We just have to decide. So when I look at this future, I wanna be clear that the arrival of this intelligence, both at the AI level, the A GI, which is general intelligence, and then super intelligence is the most important thing that's gonna happen in about 500 years, maybe a thousand years in human society.


And it's happening in our lifetime. So don't screw it up. Let's say we don't. Yeah, Let's say we don't screw it up. Let's say we get into this world of radical abundance. Let's say we end up in this place and we hit that point of recursive self-improvement. AI systems take on the vast majority of economically productive tasks. In your mind, what are humans gonna do in this future? Like, are we all sipping pina coladas on the beach? Like engaging in hobbies? You, You tech liberal, you just, I have that. You must be in favor. You must be in favor of UBI. Okay, Look, humans are unchanged in the midst of this incredible discovery.


Do you really think that we're gonna get rid of lawyers? No. They're just gonna have more sophisticated lawsuits, right? Do you really think we're gonna get rid of politicians? No. They'll just have more platforms to mislead you. Sorry. Oh my god. I mean, I can just go on and on and on. The key thing to understand about this new economics is that we collectively as a society are not having enough humans, right? Look at the reproduction rate in Asia is essentially 1.0 for two parents. This is not good, right? So for the rest of our lives, the key problem is going to get the people who are productive, that is in their productive period of lives more, more productive to support old people like me, right?


Who will be bitching that we want more stuff from the younger people. That's how it's going to work. These tools will radically increase that productivity. There's a study that says that we will un under the set of assumptions around agent AI and discovery and the scale that I'm describing. There's a lot of assumptions that you'll end up with something like 30% increase in productivity per year. The econ, having now talked to a bunch of economists, they have no models for what that kind of increase in productivity looks like. We just have never seen it. It didn't occur in, in any rise of a, of a democracy or a kingdom in our history. It's unbelievable what's going to happen.


Hopefully we'll get it in the right direction. It is truly unbelievable. Let's bring this home. Eric, you've navigated decades of technological change for everyone that's navigating this AI transition. Technologists, leaders, you know, citizens that are feeling a mix of excitement and anxiety. What is that single piece of wisdom or advice you'd like to offer for navigating this insane moment that we're living through today? So one, one thing to remember is that this is a marathon, not a sprint. One. One year I decided to do a hundred mile bike race, which is a mistake. And the idea was I learned about spin rate. You just, every day you get up and you just keep going.


You know from our work together at Google that it's when you're growing at the rate that we're growing, you get so much done in a year, you forget how far you went. Humans can't understand that as this stuff happens quicker, you will forget what was true two years ago or three years ago. That's the key thing. So my advice to you all is ride the wave, but ride it every day. Don't view it as episodic and somebody you can in, but understand it and build on it. Each and every one of you has a reason to use this technology. If you're an artist, a teacher, a physician, a business person, a technical person, If you're not using this technology, you're not gonna be relevant compared to your peer groups and your competitors and the people who want to be successful.


Adopt it and adopt it fast. I have been shocked at how fast these systems, I, as an aside, my background is enterprise software and nowadays there's a model protocol called from Anthropic. You can actually connect the model directly into the databases without any of the connectors. I know this sounds nerdy. There's a whole industry there that goes away because you have all this flexibility now you can just say what you want and it just produces it. That's an example of a real change in business. There are so many of these things coming every day. Ladies and gentlemen, Eric Schmidt, Thank you very much. Thank you very much. Thank you. Thank you guys.


Thank you. That was Eric Schmidt in conversation with the Laval sdu at TED 2025. If you're curious about Ted's curation, find out more at TED dot com slash curation guidelines. And that's it for today's show. TED Talks Daily is part of the TED Audio Collective. This episode was produced and edited by our team, Martha Esnos, Oliver Friedman, Brian Green, Lucy Little Alejandra Salazar, and Tanika SanMar Nivo. It was mixed by Christopher Fay Bogan. Additional support from Emma Toner and Daniella Bezo. I'm Elise Hugh. I'll be back tomorrow with a fresh idea for your feed.


Thanks for listening.


Support for the show comes from Capital One. Banking with Capital One helps you keep more money in your wallet with no fees or minimums on checking accounts and no overdraft fees. Just ask the Capital One Bank guy. It's pretty much all he talks about. In a good way. He'd also tell you that this podcast is his favorite podcast too. Oh really? Thanks. Capital One Bank Guy. What's in your wallet terms? Apply. See Capital One dot com slash bank. Capital One, NA member FDIC.


Hi, I'm Kristen Bell. Carvana makes car buying easy. Isn't that right, hun? Dax Dax, Sorry. Did you know about this seven day money back guarantee? A week to evaluate seat coms, you say A week of terrain tests. Yeah, I can test the brake pad resistance at variable speeds. Make sure all the kids' stuff fits nicely. Make sure our stuff fits nicely. Oh, The right. Still need to buy the car getting ahead of ourselves. Here. Buy your car with Carvana today.


Support for this podcast and the following message is brought to you by E-Trade for Morgan Stanley. With E-Trade, you can dive into the market with easy to use tools, $0 commissions, and a wide range of investments. And now there's even more to love. Get access to industry leading research and insights from Morgan Stanley to help guide your decisions. Open an account and get up to a thousand dollars or more with a qualifying deposit. Get started today at E-Trade dot com terms and other fees apply. Investing involves risks. Morgan Stanley. Smith Barney, LLC Member SIP E-Trade is a business of Morgan Stanley.