
With Schwab investing themes, it's easy to invest in ideas you believe in. Like online music and videos, artificial intelligence, electric vehicles and more Schwab's research process uncovers emerging trends. Then their technology curates relevant stocks into themes. Choose from over 40 themes. Buy all the stocks in a theme as is or customize to better fit your investing goals. All in a few clicks. Schwab investing themes is not intended to be investment advice or a recommendation of any stock or investment strategy. Learn more at schwab.com/thematic investing.


From The New York Times. I'm Natalie Kiro F and This is The Daily, Outmanned and outgunned in what has become a war of attrition against Russia. Ukraine has looked for any way to overcome its vulnerabilities on the battlefield. That search has led to the emergence of killer robots today, my colleague Paul Moser, on how Ukraine has become a Silicon Valley for autonomous weapons and how artificial intelligence is reshaping warfare.


It is Tuesday, July 9th. Paul, when we've talked on the show about the applications of advanced artificial intelligence, one of the scarier ideas has been that militaries around the world could use it to make autonomous killing machines. IE killer robots. Your reporting shows that this may already be happening. Tell me about it. Yeah, so you know, when I first got started on my reporting, you know, I thought this was the stuff of sci-fi. Like you think about AI hunting and killing somebody and you think of Terminator and you know, Arnold Schwarzenegger hunting people as a robot.


Or you think of Hal in 2001, a Space Odyssey, an all-knowing robot that can kill people on a spaceship. But the thing is, the early versions of this technology that will get us there are already being developed and they're being developed in Ukraine. And in some ways Ukraine has become a nexus for the development of this type of autonomous military technology writ large. They're taking basically artificial intelligence and finding all kinds of new military applications for it. Why has Ukraine become that nexus? So perhaps most importantly, they're outgunned weapons don't necessarily come quickly or predictably from the United States or Europe. They have to reach to anything they can use to fight this war.


And so they turn to consumer technology and emerging technologies like AI to build new effective weapons. The second point is that they're outmanned. And so as you're facing the prospect of defending all these trenches and you just don't have as many people as the Russians have, you need to come up with things that solve that problem and, and what better than something like an automated machine gun or, or a drone? And then perhaps something people don't realize is that Ukraine has been a bit of a back office for the global technology industry for a long time. Many of the apps you use every day, were probably in some part coded by engineers in Ukraine. And so you have a lot of coders and a lot of skilled experts taking their abilities and saying, well now we need to turn from building a dating app to figuring out how to stop the Russians and, and that means building these new weapons.


And then finally, extremely importantly, this is a war of attrition. And so every day there's fighting going on. And that means you have the ability to test these weapons each day and you know, to use the Silicon Valley term, iterate on them, tweak them, and make them better. And so having what is effectively a sort of laboratory to experiment and find out ways to make AI ever more deadly really helps. Yeah, it sounds like you kind of have all of these conditions that line up to make Ukraine a perfect incubator to build this type of technology. I'm wondering, Paul, what this actually looks like on the ground. What kind of weapons are we talking about here? Yeah, so I went to Ukraine in May.


I met with all kinds of different tech startups and developers, troops who use this technology. And perhaps the most startling moment, like wasn't near the front lines or anything. It was actually in a park just outside of Kyiv. And a couple guys in their twenties and one in their teens who started this company that makes autonomous drones pulled up on motorcycles. They take me into a field and they unbox a tiny little drone, four rotors on it, kind of a smaller version of a typical drone you'd use to take pictures of your vacation or something like that. Maybe we can put the screen like somewhere where, yeah, it'll be not so much some, And then they flip open this briefcase with a screen on it.


And what they explained they'd done is they took a tiny little mini circuit board, a little mini hobbyist computer Here we have a raspberry pie plus a thermal camera, but it Could be and put software on it that allows that tiny drone to follow a tank, a piece of artillery or even a human, and eventually smash into it. And so the idea is if you have a shell on the bottom of it, it becomes something of a missile. I had heard of this before but I hadn't seen it. And so they said, well, you know, we're gonna show you. And so the CEO then flips on his motorcycle helmet, revs the engine a few times and rips off down this dirt road as a target.


And one of the teammates launches the drone and it's hovering above. And then what you kind of see is that he centers the crosshairs on the motorcycle and at that point the machine takes over from the humid. And so the drone starts sort of stalking the motorcycle and it's getting closer and closer and on the screen you can see it, you know, it's lining up to swoop in and his friends are crying out, go faster, go faster. You're screwed. Oh my God, you're done. It's basically not more than a couple of feet away from him.


Okay, that was really close. And they hit a button and turn off the autonomy and the drone flies back up into the air and they're laughing and it's a funny moment because they were able to run down their CEO. But the darker reality of it is that if this was an armed drone with a shell and they hadn't hit that button at the end, their CEO would be a garner. And this is the technology that is already being used on the Ukrainian front lines to hit Russian targets. It's kind of amazing what you're seeing is the computer takeover for the young startup guy in tracking down and targeting his CEO as he's swerving on his motorcycle. And that's why this technology is so powerful, right?


This is not a remote controlled drone. This is a drone powered by artificial intelligence that's making judgements on its own. Yeah, and I think what's important to realize about these guys is, you know, they're not doing something that miraculous. What they're doing is they're taking basic code that is around, combined it with some new data from the war and made it into something entirely different, which is a weapon. And what this automation system adds to it is, is one of the great protections against these tiny types of drones is radio jamming. And so if you can break the signal between pilot and drone, you can stop that drone from swooping in on your expensive weapon system.


But what this does is it doesn't matter what the pilot sees once they hit that lock with the help of this AI software, it will keep going. And so you all of a sudden are completely helpless to stop it unless you shoot it out of the sky. It's kind of insane. I mean, we're talking about basically autonomous kamikaze drones. Tell me about the other forms of AI that you saw. Yeah, so if you imagine that single kamikaze drone, the next step is to make a swarm of those kamikaze drones. And so there are a few companies who are building swarms of drones. And so what they're testing now is you have a single four rotor drone that watches over the battlefield, but then it has its own little pack of kamikaze drones and it can choose a target and identify a target.


And you know, it's constantly searching with its camera and its sees a tank and it can then dispatch one of those drones to go in for a hit. And one of the companies I spoke to called Swarmer recently tested that technology and hit a target 60 kilometers away. Wow. So you know, this is, again, not a very expensive thing. This is hardware that costs thousands of dollars and they're hitting weapon systems 60 kilometers away with incredible precision. Another thing that is emerging is a sort of autonomous machine gun turret. And so what this uses is computer vision that you know, you would have on a lot of surveillance cameras or even on your iPhone, you know, your smartphone, it will sort of circle a human and identify it.


So you take similar technology and you put it on a machine gun and that machine gun can then automatically see targets as they move. And then all it takes is a human to press the trigger. And it's already sort of being tested right now. Some of it's already, you know, achieving kills and taking out targets. Paul, did you see the automated machine gun in action? Yeah, I did. And and the story of it is actually fascinating and it kind of indicates why Ukraine is a place where these weapons systems are emerging. So we went to a range and met a commander of a battalion called Da Vinci Wolves and Da Vinci Wolves are very well known in Ukraine for their experimentation with weapons systems.


And the commander we met Lexander, YAB Chanka, you know, really looks the part of Ukrainian committee as this casac haircut and a bushy mustache. And he was very excited about the gun. He actually named his dog after the gun. And the reason he's so excited is because he helped create parts of the gun. He's helped innovate it. And you know, unlike the engineers that we were seeing in Kyiv, he's a soldier. So he's using this technology on the front and he's sort of the eyes for a lot of these companies and he gives feedback to them about how it's working and what they need and so on. And so he told me this amazing story. He was fighting in Bach, moot a city in eastern Ukraine that the Russians were trying very hard to take over and his unit was tasked with defending the only road in and out of the city.


And they kept having this problem, which was that their machine gunner were just constantly a target. A machine gun is a big heavy gun that can't easily be moved. You need to man it at all times. So he did what I think a lot of us do these days. He went online and tried to find a solution and he ended up asking on Facebook if anybody had an idea. And in just a few months he had a working prototype in his hands from a company called Robers. And what the gun does is it, it uses cameras and what is effectively a video game console sort of portable thing that looks like a Nintendo switch. And it can automatically identify targets as they come over the horizon or appear.


And then it kind of automatically aims and all the soldier has to do is press the button and shoot. It sounds honestly quite terrifying. Automated gun crowdsourced on Facebook, the whole thing sounds really outlandish if I'm honest. Yeah. But it solved his unit's problems. He said it was great, we could sit back in the trench, drink coffee, smoke cigarettes, and shoot Russians. And it solves this problem using very basic technology that's very powerful, but that lives in your smartphone and lives on your video game systems and is pretty easily able to be created with artificial intelligence.


Paul, you've said this technology has been quite effective in Ukraine, but just to express a dose of my skepticism here, I, I think many of us interact with AI through chat GPT or Gemini, and we've seen the kind of hilariously bad answers those systems can produce. Like we can't even depend on AI to solve a crossword puzzle. I'm just wondering how can Ukrainians rely on this technology for much higher stakes stuff? I mean, hitting the right targets in war, are they finding that their AI is making mistakes?


We don't really know the answer to that. We do know that the systems work pretty well and part of the point is that they're supposed to be cheap, so they don't always have to work if they work 80% of the time and they're cheap, that's okay. I will say that another reason why they want the human in the loop who can turn off the AI is that they're afraid of friendly fire and hitting the wrong target. And there's an ethical consideration, but there's also just a very practical one that this tech could go wrong and go at the wrong person or identify the wrong thing and they need to be able to turn it off. So there are still humans in the mix, but even with this bad technology, perhaps it's even scarier. It's super simple to just take the human out of the mix.


And how close are we to that? I mean, is Ukraine's military contemplating a scenario where the humans really go away and the machines and their are entirely responsible for killing? So that was a question I posed to everyone working on this stuff. And you know, the general answer is a no, that the human will stay in the loop for the foreseeable future, but people had different takes on it. And one guy who had a particularly interesting answer was an executive at the firm that made that automated machine gun veers. His name is Anton Skrinick, and I met him at his offices in Ukraine. So, You know, realistically the pace that we're seeing, when do you think we're gonna start seeing the first automated Kind of killing?


Is it just nobody? And when I asked him how or when the first automated killing on the front lines might occur, May maybe it was already done, most likely it was already done. You know, he said it probably honestly has already happened. He had no way of knowing, you know, he didn't, he wasn't sure, but people Very often just do something to survive to complete a mission without like sharing information. And this is like not bad, You know, in a fast-paced, high stress environment on the front where life and death are, are oftentimes a matter of an instant decision whether or not a soldier flipped a switch that allowed something to just sort of go fully automated in this way or autonomous is very possible.


Is there any thought Of changing that or is that something that you guys are sort of standby? And so I asked him, okay, but you guys aren't doing this. Like There is no, it's not a singular request about like having that. He said, no, for us, you have to hit this trigger every time the gun sees a target so that it shoots, How long would it take you to do it if you Wanted to. And I said, so, okay. But if you wanted to make it fully autonomous, how long would that take Tomorrow? Tomorrow? Because today it's already like, yeah, yeah, I, I've taken two hours of your time. So basically no time at all.


It's a matter of a few lines of code because these things are already effectively doing the auto targeting. It just has the human pulling the trigger. So to make the computer pull the trigger is almost so easy. It's trivial. Wow. So what Anton is saying essentially is that he already has the technology to create a robot that makes the decision to kill on its own. There's a human operator for now, but that's not a necessity. Exactly. And you know, his answer really hit home for me because I still, I think even sitting there had thought that this was the stuff of science fiction. But what I realized at that moment is that, you know, the era of the killer robot is already upon us. We're already here.


And you know, that raises just a huge number of ethical and moral questions about the future of warfare, the future of accessibility to these kinds of weapons. And you know what it requires to kill a human being in the future, We will be right back.


You want control of your financial future. That's why when it comes to managing your wealth, Schwab gives you more choices like full service, wealth management and advice when you need it most. You can also invest on your own and trade on Think or Swim the powerful award-winning trading platform. Plus, you'll get low costs transparent pricing. And 24 7 live help because Schwab understands it's your financial journey and they believe you should have choices in how you invest. Visit schwab.com to learn more.


This is Sue Craig, investigative reporter for The New York Times. People keep secrets. We all do. But it gets tricky when it's a person with significant power. And the secret is big, say a conflict of interest, government corruption, or covering up abuse when it comes to violations of the public trust, unethical or illegal activity. And people's lives are affected. We believe you deserve to know. But people with a lot of power also have the means to make sure their secrets stay hidden. So you need organizations like The New, York Times to say, let's investigate this. Let's put resources behind uncovering the truth. And that's what I do. It's a 24 7 commitment and it means that sometimes I can't publish until I spent months or even years following every lead and checking every fact.


All those resources, they're available to us because of New York Times subscribers. If you'd like to support this kind of work, you can subscribe at ny times.com/subscribe. Paul, you started to get into the potential moral questions raised by a world where robots need no human input at all to make decisions about killing people. Let's talk about those questions. So I guess the first big consideration is who has access to this and where it will spread? And you know, the first group that does is powerful countries, right? I mean the United States is developing swarms of drones that can accompany its fighter jets.


Other major military powers in Europe and China for instance, also are developing this kind of thing. But it's also not just those guys. You know, Ukraine for instance, has channels where it's been sharing tips on drone warfare. You know, we did a story earlier in the year out of Myanmar where we found Burmese drone pilots were training on Ukrainian software that taught them to use kamikaze drones. And so the question becomes how long until these sorts of automated targeting softwares are shared? And perhaps what's maybe scarier is that Russia also is developing very similar solutions to the Ukrainians. And so who will they share it with? Will they share it with North Korea, Iran, certain fighters in Sudan?


So the point is, it's very easy to spread software. I mean, this is' even a piece of hardware. This is just something that plugs into a piece of hardware. You can send it over an email. And the guys that we talked to in the field who were flying the drones, one of the problems they had with their technology when they showed it to the Ukrainian military is that it wasn't encrypted. So the Ukrainians were afraid that if their drone crashed behind enemy lines without blowing up, the Russians could take the little mini computer, download the code and use it to build their own system and hit the Ukrainians. Hmm. So software spreads incredibly fast and incredibly easily, and it's gonna be extremely hard once these solutions are developed to stop them from going almost anywhere.


It's not hard to imagine a dark website that allows you to sell all manner of autonomous drone attack systems. Right. There was one US official I was speaking with who has huge concerns about the terrorism implications of this. So I mean, it's not hard to imagine. I mean, take a drone for example. You know, you could fly something in from 20, 30 miles away and becomes extremely difficult to defend against. That raises a lot of questions, obviously. And I have to assume that ethicists and human rights officials are asking some of them. For example, is there any way to regulate AI weapons? Can we put limits on their use?


Yeah. So this is something that's been debated, you know, in the UN by panels of experts for years. But we never really get to anything particularly concrete in part because countries are already in an arms race to develop these things. And every time anybody proposes some kind of a rule, it's vetoed, if not by the United States, by China, by Russia, by other countries in Europe. But there are some basic principles that ethicists sort of rally behind things like keeping a human in the loop so that the human makes the ultimate decision, even if there's automated targeting going on. And that's the sort of line the Ukrainians are standing behind. But again, there's really not much out there to stop any of this from going wherever it wants to go.


And honestly, it feels like we're already heading in that direction. Paul, in listening to you this whole time, I've been wondering how we should think about this idea of software making the decision about who lives and dies. Because on the one hand, I have to say, the idea of robots hunting down humans is truly frightening. But on the other hand, it's not as if humans are known for their restraint in war. I mean, right now we're witnessing two wars in Ukraine and in Gaza where human led military campaigns have killed tens of thousands of people, many of them civilians. And so I'm wondering, in your reporting, have you come to think of this technology as in any way better or a more precise form of warfare?


Yeah, so I think what was interesting is some of the technologists building this that I spoke with did make this case. And their logic goes something like, if we have robots fighting robots, humans aren't dying. If we can put rules inside the software, no. You know, say children will be killed by this weapon. We can prevent it from doing certain things that maybe a really bad human would do. And you could maybe even create spaces like the frontline where just nobody can step foot, you know, for four kilometers on either side. 'cause the weapons are so deadly. And so how can you move forward in either way and you just create a perfect stalemate? Hmm. But I guess history shows us, in my understanding of history at least, that that's not the way this will probably go.


And that every time in the past we've seen a breakthrough in weaponry. Oftentimes it's just meant more devastating weapons get created. You know, I thought back to Alfred Nobel who famously thought dynamite would end war. And of course it simply made more powerful deadly bombs. And it feels like that is the kind of future that we are treading into. But I just think that it's very hard to sit where we are, you know, in a place that's not at war and tell people building these things that are weapons to defend their families and their friends who are going off to war against an invader to stop doing it.


'cause it could make us unsafe in the future. And even some of the ethicists I spoke with who are very opposed to dedicated their careers to fighting against autonomous weapons, they would throw up their hands and say, well, I can't really argue with the Ukrainians. One of the Ukrainians I spoke with who's making autonomous drone system said, you show me a hypothetical victim and I'll show you a real dead soldier. And you know, a family that now has to live without him. Mm. And that leaves you in a very hard place because you kind of have a what's, you know, sort of a a runaway train. You can't morally argue for people to stop building things to defend themselves.


Yet what they're building basically secures a future that will be far more dangerous than the present that we live in. And as long as this war in Ukraine goes on, we are gonna see more advanced systems get developed. And I just don't know how we avoid a future in which we have ever more powerful, ever more autonomous weapons. And that's pretty scary. Paul, thank you so much. Thank you.


On Monday, Russia launched one of the deadliest assaults on Kyiv. Since the first months of the war, striking Ukraine's largest children's hospital as part of a barrage of bombings across the country, at least 38 people were killed in the attacks. And more than a hundred were injured. We will be right back.


Millions of small businesses and entrepreneurs rely on eBay because eBay has invested billions in prioritizing small business growth. It's a place where passion, not location dictates success, which is why 43% of sellers live in small towns and rural areas by enabling people to transform a good idea into a good living. eBay is powering America's small business economy. Learn more@ebaysmallb.com.


If you find yourself bewildered by this moment where there's so much reason for despair and so much reason to hope all at the same time, lemme say I hear you. I'm Ezra Klein from New York Times opinion host of the Ezra Klein Show. And for me, the best way to beat back that bewildered feeling is to talk it out with the people who have ideas and frameworks for making sense of it. There's going to be plenty to talk about. You can find the Ezra Klein show wherever you get your podcasts.


Here's what else you should know today. The bottom line here is that we're not going anywhere. I am not going anywhere. I Wouldn't be wrong on Monday in a move to save his candidacy. President Biden told congressional Democrats in a letter and on MSNBC's morning Joe, that he would not withdraw from the race and accused those asking him to step aside of being routinely wrong about politics. Look, I don't care what those big names think they're wrong in 2020, they're wrong in 2022 about the red wave. They're wrong in 2024. And go with me, come out with me and watch. Watch people react. You make a judgment.


Biden faces what could be the most crucial week of his candidacy as he contends with growing concern among democratic lawmakers about his age and ability to win reelection. He also spoke directly to some of his biggest fundraisers and donors in a private call telling them Democrats needed to shift the focus away from him and back to Trump. And as tropical Storm Barrel battered Houston in its suburbs on Monday, at least two people were killed by fallen trees. And nearly 3 million homes and businesses lost power in Texas. The storm is expected to move across the eastern half of the United States over the next several days.


Today's episode was produced by Will Reed, Claire Tennis Getter and Stella Tan. It was edited by Lisa Chow, contains original music by Dan Powell Etu and Sophia Landman, and was engineered by Alyssa Moxley. Our theme music is by Jim Broberg and Ben Landsberg of Wonder. That's it for The. Daily, I'm Natalie Kieth. See you tomorrow.


You want control of your financial future. That's why when it comes to managing your wealth, Schwab gives you more choices like full service, wealth management and advice when you need it most. You can also invest on your own and trade on Think or Swim, the powerful award-winning trading platform. Plus, you'll get low costs transparent pricing. And 24 7 live help. Because Schwab understands it's your financial journey and they believe you should have choices in how you invest. Visit schwab.com to learn more.