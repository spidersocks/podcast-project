
Support for this podcast comes from Instagram. My name is Gilda Charles and I'm a product manager at Meta. I'm also a mom of two. We know that parents want their teens to have safe, meaningful experiences online. So the idea of the new Instagram teen accounts is to create an experience with safety features and content protections all built in. This new experience is really designed to better support parents and give them peace of mind that their teens have the right protections in place. By default. Are you the parent of a teen? Get more information@instagram.com slash teen accounts.


Hi, my name's Devin Gordon and I'm a contributor to The New York Times Magazine. So maybe you remember last year there was a major strike by the Writer's Guild of America and the Screen Actor's Guild that completely stopped Hollywood for several months. And one of the issues at the core of the contract negotiations with the movie studios was the subject of AI Guild members were concerned that AI could replace humans at every stage in the creative process that studios would soon use AI to write screenplays, direct and edit films, design the special effects, and even read and decide which scripts were green lit actors meanwhile were concerned about copyright ownership over their images.


They wanted to protect their likenesses from exploitation and reproduction and profit without their benefit. But I also heard another perspective from AI optimists in Hollywood. They told me that the technology was still widely misunderstood, so I decided to find out what AI was actually being used for, did the anxiety matched the reality? At first, it was difficult to find people in the industry who would go on the record in praise of AI because that can be seen as siding with the machines or undermining union solidarity.


But eventually I was able to speak with artists who have already incorporated AI into their work in films you might have already seen. One use of AI is to make actors look younger or older than they actually are. For example, in a new movie called Here, AI transformed Tom Hanks' face to make him look anywhere from 18 to 80 years old. This method of facial replacement technology is also being used in stunt work. You can take the face of say, Dwayne Johnson and digitally pasted it onto the face of a stunt person leaping off a cliff. Filmmakers have also used AI to bring back dead actors to reprise roles as was done with Ian Holm for his Android character in this summer's alien Romulus.


This is the kind of work that would typically take teams of hundreds of artists drawing every pixel frame by frame several months to do, and it can cost tens of millions of dollars for this week's Sunday read that you'll be hearing. Next. I wanted to get as many honest takes from people in Hollywood about where AI might ultimately lead, And I really wanted to know, and I think many of us as moviegoers do as well, but might be hesitant to ask, could AI actually make movies better? So here's my article read by Eric Jason Martin.


Our producer is Jack Dro, and our music was written and performed by Aaron Esposito, The Los Angeles headquarters of Metaphysic, a Hollywood visual effects startup that uses artificial intelligence to create digital renderings of the human face were much cooler in my imagination if I'm being honest. I came here to get my mind blown by ai and this dim three room Warren overlooking Sunset Boulevard felt more like the slouchy offices of a middling law firm. Ed Ulbrich metaphysics chief content officer steered me into a room that looked set to host a deposition, then sat me down in a leather desk chair with a camera pointed at it.


I stared at myself on a large flat screen TV waiting to be sworn in, But then Ulrich clicky clicked on his laptop for a moment and my face on the screen was Transmogrified smile. He said to me, do you recognize that face? I did right away, but I can't disclose its owner because the actor's project won't come out until 2025 and the role is still top secret. Suffice it to say that the face belonged to a major star with fantastic teeth. Smile again. Alberg said, I complied. Those aren't your teeth.


Indeed, the teeth belonged to famous actor. The synthesis was seamless and immediate as if a digital mask had been pulled over my face that matched my expressions with almost no lag time. Time Ulbrich is the former chief executive of Digital Domain, James Cameron's visual effects company, and over the course of his three decade career, he has led the VFX teams on several movies that are considered milestones in the field of computer generated imagery including Titanic, the Curious case of Benjamin Button and Top Gun Maverick. But in Ulrich's line of work in the quest for photorealism, the face is the final frontier.


I've spent so much time in uncanny valley. He likes to joke that I own real estate there. In the spring of 2023, Ulrich had a series of meetings with the founders of Metaphysic. One of them, Chris Umi, was the visual effects artist behind a series of deep fake Tom Cruise videos that went viral on TikTok in early 2021. A moment many in Hollywood cite as the warning shot that AI's hostile takeover had commenced. But in parts of the VFX industry, those deep fake videos were greeted with far less misgiving. They hinted tantalizingly at what AI could soon accomplish at IMAX resolutions and at a fraction of the production cost.


That's what Metaphysic wanted to do and its founders wanted Ulrich's help. So when they met him, they showed him an early version of the demonstration I was getting. Ulrich's own career began during the previous seismic shift in the visual effects field from practical effects to CGI and it was plain to him that another disruption was underway. I saw my career flash before my eyes Ulrich recalled. I could take my entire team from my former places of employment, I could put them on for eternity using the best CGI tools money can buy and you can't deliver what we're showing you here and it's happening in milliseconds.


He knew it was time to leave CGI behind as he put it. How could I go back in good conscience and use horses and buggies and rocks and sticks to make images when this exists in the world? Back on Sunset Boulevard, Ulrich pecked some more at his laptop. Now I was Tom Hanks, specifically a young Tom Hanks, he of the bulging green eyes and the look of gathering alarm on his face in Splash when he first discovers that Darrell Hannah's character is a mermaid. I can divulge Hanks' name because his AI debut arrived in theaters nationally on November 1st in a movie called Here directed by Robert ek, written by Zuki and Eric Roth.


A reunion of the creative team behind Forrest Gump and co-starring Robin Wright here is based on a 2014 graphic novel that takes place in a single spot in the world, primarily a suburban New Jersey living room over several centuries, the story skips back and forth through time, but focuses on a baby boomer couple played by Hanks and Wright at various stages of their lives from age 18 into their eighties from post World War II to the present day. You couldn't have made this movie three years ago. Zeek told me he could have used multiple actors for each character, but the audience would get lost, keep track.


Conventional makeup could have taken a decade off Hanks who is now 68 but not half a century. The crux with CGI is time and money Persuading us that we watching Hanks and Wright in their twenties would've required hundreds of VFX artists. Tens of millions of dollars and months of postproduction work doable in theory, but major studios don't spend that kind of money on movies like here. There's no capes or explosions or aliens or superheroes or creatures. Ulrich explained, it's people talking, it's families. It's their loves and their joys and their sorrows. It's their life.


AI software though changes all the accounting by using every available frame of Hanks' movie career to capture his facial movements and the look of his skin under countless lighting conditions, physical environments, camera angles and lenses, metaphysics, artists can generate a digital Tom Hanks mask with the click of a few keystrokes and what we see on screen is just one factor in AI's ascendancy. It's the quality and it's the speed and it's the cost. Berg said no six month production lag, no fortune spent during the filming of here.


Metaphysic devised a setup that enabled Zumeka and his crew to follow the shooting of scenes on two different monitors, one showing the raw feed from the camera of the actors as they appear in reality and one filtered through its AI tools showing the actors at whatever age the scene required. Zuki has a long history of pouncing on new technologies to help him tell stories from Forrest Gump to the Polar Express and Hanks has often come along for the ride. In this case, the production breakthrough mattered as much as the image quality. It was crucial that the cast could see it because then they could adjust their performance.


EKS told me they could say, oh, I see, I've gotta make sure I'm moving like I was when I was 17 years old. No one had to imagine it. They got a chance to see it in real time and despite the technical ambition here, only cost about $50 million less than a quarter of some Marvel movie budgets. From metaphysics office in Hollywood, I drove 30 minutes south to Sony, is Studio LA in Culver City to watch a screening of here in the basement of the Irving Thalberg building. And for me at least, the AI driven scenes passed the baseline test of any ambitious movie illusion.


I didn't notice it, but reactions are bound to vary, especially when it comes to a face as familiar as that of young Tom Hanks a high bar for a big screen visual effect and when an illusion doesn't work, it can be hard to focus on anything else. Maybe it will turn out to be impossible to escape Uncanny valley after all, even with the help of ai. Then again, the whole fuss over the Tom Cruise deep fakes was propelled by how convincing they were and that was three years and three Nvidia chips ago. It seems like only a matter of time before they fool us all.


Wells Fargo seeks broad impact in their communities. They're focused on building a sustainable inclusive future for all by supporting housing affordability, small business growth, financial health, and other community needs. That's why they've donated nearly $2 billion to strengthen local communities over the last five years. Wells Fargo, the bank of Doing, see how@wellsfargo.com slash say Do Wells Fargo's philanthropic support includes contribution from Wells Fargo and company, Wells Fargo Bank, NA and the Wells Fargo Foundation.


This podcast is supported by pharma. When you check out at the pharmacy, you see the journey from idea to medicine. Thanks to America's intellectual property system or IP for short IP safeguards. Inventions like a new way to prevent seizures or lower cholesterol and IP supports competition from other brands. Then lower cost generics, which are 90% of prescriptions filled in the US innovation competition. Lower costs thanks to ip. Learn more@phrma.org slash ip works. Wonders


Support for this podcast comes from Instagram. My name's Nicole Lopez and I work at Meta. I oversee a team of subject matter experts in all things youth safety and wellbeing. There are thousands of parents at Meta, myself included, who care really deeply about creating age appropriate experiences for teens and that's why we rolled out Instagram teen accounts. These accounts come with safety features and content protections all built in. Are you the parent of a teen? Get more information@instagram.com slash teen accounts. That's instagram.com/teen accounts.


The history of Hollywood can be told as a series of technological leaps beginning with the invention of the camera itself and each time something new comes along, jobs are lost, jobs are created. The industry reorganizes itself, everyone in town of a certain age has seen this movie before. Past leaps though have tended to have narrower impacts Home. Video changed movie distribution, digital cameras changed movie production, CGI changed visual effects. The difference here is that AI has the potential to disrupt many, many places in our pipeline.


Says Lori McCreary, the chief executive of Revelations Entertainment, a production company she owns with Morgan Freeman and a board member of the Producer's Guild of America. This one feels like it could be an entire industry disruptor. AI is evolving so rapidly though and remains so poorly understood by so many people in Hollywood that it's difficult to predict how it will wind up proving most beneficial and which aspects of the filmmaking process it will disrupt. First, everyone's nervous says Susan sprung the producer's guilds chief executive and yet no one's quite sure what to be nervous about.


The use of AI in here is a critical element in its broader illusion, but it's also a small one In a movie full of old fashioned visual invention and aging and de aging actors is just one way that filmmakers are tinkering with AI driven facial replacement. It's also being used in stunt photography, foreign language dubbing, and increasingly in lieu of reshoots AI applications are often divided into two broader categories. The first is generative ai, which helps artists and studios create things. Then there is a genetic ai which helps them get things done.


A new AI tool called kya, for instance, reads scripts and generates 35 page coverage reports along with historical comparisons and suggested theatrical release patterns. The core duty of countless junior studio executives daily work life, though perhaps not for long gen AI is depending on your vantage point, either the fun kind or the dystopic kind. It's either going to empower artists or replace them or do both. But gen AI is also the category where all the creative exploration is happening and where filmmakers are learning on the fly, how it can help them tell new stories and they believe make better movies.


Shortly after here. Wrapped up principle photography in April, 2023. Hollywood shut down for several months because of overlapping strikes by the Writer's Guild of America and the Screen Actor's Guild. Among the central issues in both labor disputes was how to protect the livelihoods of union members from AI encroachment. Even a year before the strikes, AI was still just a plot device for sci-fi thrillers for most people in the movie industry, not oppressing real world threat. Then open AI unveiled its first public version of the chat GPT in November, 2022.


Suddenly AI was an asteroid hurtling toward Los Angeles. Any day studio executives would start using chat GPT to spit out screenplays, eliminating all those pesky writers and using text to video programs like runways, gen one to auto generate all the filmmaking elements that professional artists get paid to create. Now costumes set design cinematography, and even though the guilds managed to extract strict limitations on AI use in their ratified labor agreements, their victories felt pure. I spoke with more than two dozen people across the industry for this article and discovered that while there's no shortage of AI optimists in the movie industry, they're often reluctant to share that sentiment out loud for fear of seeming to side with the machines or appearing to sanguine about a technology that everyone agrees will cost some people their jobs.


There were also a couple of occasions when an eager early adopter scheduled an interview only to cancel at the last minute at the behest of skittish corporate overseers, and yet the reality of AI's adoption within Hollywood so far has been more muted and incremental and considerably less dystopic than the nightmare scenarios. What was built as an industry earthquake has been more like a slow leaching into the top. Soil AI in Hollywood right now is like AI in here. It's everywhere and it's nowhere. It's invisible and it's all over the screen.


There's too many people in Hollywood today who think that if you type movie and press enter, you get a movie says Crystal Ball Valenzuela, the co-founder and chief executive of runway whose AI video generation engines are among the most widely used. The moment you start using it, you understand, oh, it actually doesn't really work that well yet and it's full of flaws and it doesn't actually do what I want. The critical limitation with generative AI tools for now is the absence of control. CGI requires a factory line of hundreds of artists working one frame at a time, but you control every freaking pixel you control.


Every character says ODed Grau a visual effects artist at a generative AI video startup called Hour one who worked on the Oscar winning team behind Spider-Man into the Spider Verse 2018. Making images with AI Grau explains is like Russian roulette or a slot machine. The front end requires just a simple prompt. You write, I want Spider-Man hanging from a building and it generates it, but that still leaves countless decisions up to the machine and you're stuck with the output. What does the building look like? How is he hanging upside down sideways?


And that's a single still image, not a full sequence, let alone a feature length film. You can't expect James Cameron to prompt an avatar scene says Yo Plata metaphysics Chief Innovation officer and the lead architect of the AI tools used in here. It's just not going to work. Or with Bob Zeek or Steven Spielberg, if you've ever made a movie with one of these guys, you know that they will want to change every pixel if they can rather than play wait and see and have AI thrust upon them in ways they couldn't control. Anthony and Joe Russo, the directors of the previous two Avengers movies for Marvel Studios hired a machine learning scientist away from Apple to help guide how their production company AG bbo would use it.


There's a lot of ways that we are experimenting with AI right now. Anthony Russo told me we're not quite sure what's going to work and what's not going to work, but he's sure that AI will figure somehow into how he and his brother make the next two Avengers movies both currently scheduled for 2026, even if it's only to help with brainstorming ideas and working through them faster. Over several months of talking to people around Hollywood about ai, I noticed a pattern the people who knew the least about its potential uses in the filmmaking process feared it the most and the people who understood it best, who had actually worked with it harbored the most faith in the resilience of human creativity as well as the most skepticism about generative ai ever supplanting it.


There was a broad consensus about the urgency of confronting its many potential misuses tech companies skirting copyright laws and scraping proprietary content to train their machine learning models, actors, likenesses being appropriated without their permission. Studios circumventing contractual terms designed to ensure that everything we see on screen gets written by an actual human being. I must have heard the phrase proper guardrails at least a dozen times, but as the prolific Emmy winning television director, Paris Barclay, who has six episodes of multiple shows airing this fall alone, put it, that's what unions are for


Support for this podcast comes from Instagram. Are you the parent of a teen? Then? You should know that Instagram recently introduced teen accounts with new built-in limits and protections for teens. Teens between the ages of 13 and 17 are now placed in Instagram teen accounts with automatic protections that include limits on who can contact them, what content they can see, and new ways to explore their interests. Teens under 16 will need parental permission to change these settings. To learn more, visit instagram.com/teen accounts


support for this podcast comes from Avangrid. Tom Turnal runs an Ohio millwork company that was started by his father and employs his kids. I'm in favor of wind farms because I'm committed to attracting talent for our community and the school districts with wind turbines get resources that can make a huge difference in kids' lives. Since 2012, an au grid wind farm has strengthened the economy and contributes millions to the community each year. To learn more about where energy meets humanity, visit au grid.com. That's au grid.com.


Support for this podcast comes from Instagram. My name's John and I'm a dad. We all use social media at home, however, I worry about it taking too much time, especially when the kids are trying to go to sleep. Encouraging your teen to wind down at the end of the day can be tough, so parents should know that Instagram's new teen accounts automatically place teens in sleep mode on Instagram. Teen accounts sleep mode will turn on between 10:00 PM and 7:00 AM which will mute notifications and send auto replies to dms. Learn more at instagram.com/teen accounts.


The Twilight Sun over the NC behind Tom Hanks was so golden and incandescent and lit his profile with such cinematic flare that the composition was almost too perfect as though it could only be the product of advanced machine learning and not say Zeus. One week after my visit to Metaphysic, I was once again staring into a camera and Hanks was again staring back at me. Only this time it was the real Tom Hanks enjoying the last few days of a sailing trip in the Greek islands. He was tanned and relaxed in a dark open color polo, and unlike the last time I saw him, he looked like a man in his late sixties with clear frame glasses, Tufts of short gray hair barely peeking over the top of his head and a tight white beard.


The nameplate at the bottom of his zoom window, red, HANX. I asked Hanks if it gave him any pause making a movie so reliant on AI tools at a moment when so many of his colleagues in Hollywood were anxious about it. He rejected the premise and characterized the work on here as being in the grand tradition of Lon Cheney and Monster Movie Magic. This was not AI creating content out of whole cloth. He said, this is just a tool for cinema. That's all. No different than having better film stock or a more realistic rear screen projection for somebody driving a car.


For someone like Hanks AI could enable him to take on roles for which he had long assumed he was too old. If it's possible for me to play a younger person than I am, I read stuff all the time and I think, oh man, I'd kill to play this role, but I'm 68. I'd kill to play Iago, but I can't because Iagos in his twenties, I would do it in a heartbeat though. Pity the poor 20 something actors shut out from playing Iago by an ageless Tom Hanks. When AI evangelists talk about its capacity to empower artists, this is the kind of thing they mean though Hanks' experiences have compelled him to contemplate some morbid implications.


They can go off and make movies starring me for the next 122 years if they want. He acknowledged should they legally be allowed to. What happens to my estate? Far from being appalled by the notion though he sounded ready to sign all the necessary paperwork. Listen, let's figure out the language right now. Metaphysics Handiwork has already appeared in two major theatrical releases. This year, Fiosa a Mad Max Saga and Alien Romulus, and in both cases the assignment was to resurrect a fan favorite figure from an earlier film in the franchise who had been played by a since deceased actor in Fiosa Metaphysic enabled the director George Miller to bring back the bullet farmer by putting the face of Richard Carter from Matt Max Fury Road onto the body of a living actor in Alien Romulus, the Android from Ridley Scott's 1979 original alien played by Ian Hol, who died in 2020 returns in updated form for several scenes.


Even though Holmes' family blessed the use of his likeness, public response was divided, the movie was a hit, but some viewers posted ethical critiques on social media. Then in late August, the California State Senate passed long gestating SAG supported legislation requiring estate consent for AI generated replicas of dead performers. When I asked one writer director about the practice, he didn't even let me finish the question. Nope, nope, nope, nope. Said Billy Ray who wrote Captain Phillips 2013 and co-wrote the 2012 big screen adaptation of the Hunger Games and who spent his time during the strike hosting a studio Lamb Basting podcast.


It's completely insincere, dishonest filmmaking. It's a lie. The counterargument I kept hearing from artists and from technologists is that filmmaking is a grand delusion at its core, and we all consent to being tricked. We're paying to be tricked when we walk into the theater or turn our phone sideways. When your movies require visiting multiple fantasy worlds, dreaming up new superpowers and nastier villains, you need to come up with lots of ideas knowing that a vast majority of them will be bad. This is the grunt work of making popular art the failing part, and AI could prove to be a godsend for artists who need to fail fast and at minimal expense.


It's a bit like you have 5,000 phenomenally smart interns at your disposal 24 7 in all time zones says Dominic Hughes, the Oxford University educated AI whisperer who left Apple to join the Russo Brothers Hughes switched industries. He told me in part because he came to believe Silicon Valley was getting AI all wrong. Generative AI tools are unruly and imprecise sloppy, he said, but too many companies were trying to use them for tasks where they couldn't afford to be wrong, like self-driving cars or robot surgeries or whatever he says, and we've been struggling with that for years because if you don't wanna run over seven year olds in Kansas, you've gotta be 99.999999% precise.


Whereas in a creative context, if I generate a bunch of elves and they have seven fingers hallucinations in the parlance of the medium, it doesn't matter because they're part of my iterative creative process of brainstorming what elves could look like. Generative ai he has come to believe is best suited for tasks where hallucination is a feature, not a bug. The sum of Hollywood's collective fears says Bennett Miller, the Oscar nominated director of Moneyball and Fox catcher is automation robots replacing humans just as in the movies.


Miller spent five years making a documentary about the dawn of AI that he describes as a time capsule about a moment Before A real loss of innocence in Silicon Valley. The untitled film is currently in legal limbo. In the course of making it, he got to know the original leadership team at OpenAI, including Sam Altman. A few years ago. They offered him access to a beta version of their forthcoming text to image tool Dolly. It was astounding. Miller told me from the moment that I had an account set up to literally 10 minutes ago, I've just been all in.


This January at Gagosian's Paris Gallery, people open his third show of ghostly, surreal images that evoke the grainy early days of photography, but were created with Dolly. In one of them, a silhouetted man looks up from the floor of a century old theater at a massive sea creature on stage. Its body so large that it extends beyond the frame. It's like realizing that you had locked in syndrome because you really can navigate to extraordinary places. He fell in love with getting lost, the mistakes, the wrong turns, the models peculiar way of comprehending the human world a bit.


Louis Boel a bit, Dian Arbus led to all of his breakthroughs, which is how the best art often gets made by accident. It's not just a change in degree of what's been possible before. It's really like a change in kind, and yet, as much as Miller's creative practice has been transformed by ai, it's still merely a tool to him, and the tool doesn't make you an artist, he says, I just don't see it as a threat the same way others see it. I'm not saying that there aren't going to be huge problems that emerge, but here's the thing that I cannot comprehend.


Human artists being replaced. The great wild card of AI is that it learns and gets better and we can only guess at its full capabilities. Its performance so far though has also highlighted the gap still to be closed, especially with text generation. Tools like Chat, GPTA lowest common denominator regurgitation machine whose countless practical uses don't appear to include writing screenplays. Tom Graham, a metaphysic co-founder and its chief executive, says he can see AI tools summarizing news articles and doing great explainer videos for corporate work.


I can see them creating generic or derivative stories that just kind of seem like other stories, but he adds amazing storytelling is very, very difficult. Of course, Hollywood is very much in the business of generic and derivative stories, in which case, why not completely outsource the hack work to ai? The Writer's Guild of America's labor deal forbids that though count on studios to use it for anything in the script development process that can save them money and some creative guilds are bound to be hit hard by the adoption of ai, especially in digital animation with its battalions of entry level artists who spend an entire year tweaking pixels on two minutes of film.


Many of those people could be working in AI soon, and fortunately for them AI firms are hiring. We need to double our size really quickly. Just to keep up with the demand says Alejandro Lopez, the chief marketing Officer at Metaphysic, which currently has about 120 employees working remotely in more than 20 countries. We are so behind, but as anxious as the guilds are, Hollywood's history with paradigm shifting technology suggests that the folks on the studio side, the age agentic side, have just as much to fear. We went from renting movies to streaming them, and it's not filmmakers that go away.


Blockbuster goes Away, says Brim Muser, a filmmaker and a co-founder of the streaming channel, documentary Plus whose new company, hysteria is an independent movie studio bidding to be the Pixar of ai or think about the switch from film to digital. Polaroid is the one that's gotta figure it out. Kodak has to figure it out. Photographers are still there. Filmmaking is often described as the most collaborative art form, and Metaphysic was just one among many creative contributors to the trickiest scenes of Hanks and Wright as young lovebirds in here.


The actors performed in full period costume, not in green suits, covered with ping pong balls. The makeup department taped back the loose skin around Hanks' neck and pulled up his droopy ears. So Hanks' AI generated young face would match Hank's real life, old head, and of course they had award-winning actors to deliver all the lines, you still need the warmth of the human performance. Zeus told me the illusion only works because my actors are using the tool just like they use their wardrobe just like they'd use a bald skull cap. It was the future of Hollywood and it looked Unc Cannelly like its past.


Support for this podcast comes from Instagram. Are you the parent of a teen? Then? You should know that Instagram recently introduced teen accounts with new built-in limits and protections for teens. Teens between the ages of 13 and 17 are now placed in Instagram teen accounts with automatic protections that include limits on who can contact them, what content they can see, and new ways to explore their interests. Teens under 16 will need parental permission to change these settings. To learn more, visit instagram.com/teen accounts.