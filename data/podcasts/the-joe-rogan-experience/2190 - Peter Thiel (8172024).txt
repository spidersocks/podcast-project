(2s):
Joe Rogan podcast. Check Out The Joe Rogan. Experience Train by day. Joe Rogan podcast by night all day. What's Up man? Good to see You. Glad to be on the show. My My. Pleasure. Thanks for having me. My. Pleasure. What's cracking? How you doing? Doing All right. We. Were We. were just talking about how you're still trapped in la I'm still trapped in la I know it's, You're friends with a lot of people out here. Have you thought about jetting? I, I talk about it all the time and it's, but You know it's always talk as often a substitute fraction. It's always, does it, does it lead to action or does it Right. Does it end up substituting for action? And That's a good point, But I have endless conversations about leaving and I moved from San Francisco to LA back in 2018 that felt, felt about as big a move away as possible.

(50s):
And I keep, I keep the, the extreme thing I keep saying, and I have to keep in mind, talks a substitute for fraction. The extreme thing I keep saying is I can't decide whether to leave the state or the country. Oh, boy. And You know. If you went out of the country, where would you go? Man, I, I've, it's, it's, it's tough to find places because, you know, there are a lot of problems in the US and most places are doing so much worse. Yeah. So It's not a good move to leave here, But It's as fucked up as this place is. But, but I keep, I keep, I keep thinking I, I shouldn't move twice. So you shouldn either I can't decide whether you shouldn move to Florida or should move to You know Costa Rica, New Zealand, or Costa Rica or something like that.

(1m 30s):
Yeah, Yeah. Go full John McAfee And I, I, but can't decide between those two. So ended up stuck in California. Well, Australia's okay, but they're even worse when it comes to rule of law and what they decide to make you do and the way they're cracking down on people now for online speech. And it's, it's very sketchy in other countries. It's, but somehow, somehow the, the, the relative outperformance of the US and the absolute stagnation decline of the us they're, they're actually related things because the way the conversation's grouped, every time I say, tell someone, You know I'm thinking about leaving the country, they'll, they'll do what you, you say, and they'll say, well, every place is worse.

(2m 14s):
And then that somehow distracts us from all the problems in this country. And then we can't talk about what's, what's, what's gone wrong in the US because, you know, everything is, everything's so much worse. You know. Well, I think most people know what's gone wrong, but they don't know if they're on the side of the government that's currently in power. They don't know how to criticize it. Right. They don't know exactly what to say, what should be done. Right. And they're ideologically connected to this group being correct. Right. So they try to do mental gymnastics to try to support some of the things that are going on. I think that's, that's a part of the problem. I don't think it's necessarily, we don't know what the problems are. We, we know what the problems are, but we don't have clear solutions as to how to fix 'em, nor do we understand the real mechanisms of how they got there in the first place.

(3m 0s):
Yeah. I mean, so there, there are a lot that are, that are pretty obvious to, to articulate. And they're much easier describe than, than solved. Like, we have a crazy, crazy budget deficit. Yeah. And presumably you have to do one of three things. You have to raise taxes a lot, you have to cut spending a lot, or you're just gonna keep borrowing money. Isn't there like some enormous amount of our taxes that just go to the deficit? It's, it's not, it's, it's not that high, but it's gone up a lot. And wait, What is it? What is it? Did I thought it was like peak 34% or something crazy. You know, it peak, it peaked at three point, I wanna say it peaked at 3.1% of GDP, which is You know, maybe 15, 20% of the budget.

(3m 47s):
It peaked at 3.1% of GDP DP 1991. And then it went all the way down to something like one point a half percent in the mid 2010s. And now it's crept back up to 3.1, 3.2%. And, and so we are at all time highs as a percentage of GDP. And the way to understand the, the basic math is the, the debt went up a crazy amount, but the interest rates went down. And from, you know, 2008 to 2021 for 13 years, we basically had zero interest rates with You know, one brief blip under Powell, but it was basically zero rates. And then you could have borrow away more money and it wouldn't show up in servicing the debt because you just paid 0% interest on the TBI TBIs.

(4m 27s):
Hmm. And, and the thing that's, that's very dangerous seeming to me about the current fiscal situation is the interest rates have gone back to positive. Like they were in the nineties and early two thousands, mid two thousands. And, and it's just this incredibly large debt. And so we now have a, we now have a real runaway deficit problem, but You know, people have been talking about this for 40 years and crying wolf for 40 years. So it's, it's very hard for people to take it seriously. Most people don't even understand what it means. Like when you say there's a deficit, we owe money. Okay. To who, how's that work? It's well, it's to, yeah, it's people who, who bought, who bought the bonds and it's You know it's a, a lot of it's to Americans.

(5m 15s):
Some of them are held by the Federal Reserve. Decent amount are held by, by, by foreigners at this point. Because You know, it's, it's, it's, it's, in some ways it's the opposite of the, of the trade current account deficits. The US has been running these big current account deficits, and then the foreigners end up with way more dollars than they, they they wanna spend on American goods or services. And so they have to reinvest them in the US You know some way, some put it into houses or stocks, but a lot of it just goes into, into government debt. So it's in, in some ways it's a function of the, of the chronic trade imbalances. Chronic trade deficits. Well, if you had Supreme power, if Peter Thiel was the ruler of the world and you could fix this, what would you do?

(5m 55s):
Man, I always find, I always find that hypothetical. It's, it's a ridiculous hypothetical. That's ridiculous. Hypotheticals. You get ridiculous answers. I want A ridiculous answer. That's what I like. But, but what could be done, like, what could be done, first of all, what could be done to mitigate it and what could be done to solve it? You know, I, I think, I think my, I think my answers are probably all in the, in the You know, in the, in the very libertarian direction. So I It would be sort of figure out ways to have smaller governments figure out ways You know You know to increase the age on social security means test social security. So not everyone gets it.

(6m 36s):
Just figure out ways to, to gradually dial back. You know a lot of these government benefits and then that's You know, that's insanely unpopular. So it's Yeah. That it's completely unrealistic on that level that bothers People that need social security. Well, I I said means tested Means tested, so people who don't need it don't get it. Right. So social security, like even if you're very wealthy, I don't even know how it works. Do you still get it? Yeah. Basically anyone who, pretty much everyone gets it because it was originally, originally rationalized as a, as a, as sort of a pension system, not as a welfare system. And so the, the fiction was you pay social security taxes and then you're entitled to get a pension out in the form of social security.

(7m 24s):
Right. And, and because it was, we told this fiction that it was a form of There was a pension system instead of an intergenerational Ponzi scheme or something. Something like that. Mm. You know the fiction means everybody gets paid Social Security because it's a pension system. Whereas if We were more honest and said it's You know it's just a welfare system, maybe you could, you could start dialing, you could, you could, you could probably rationalize in a lot of ways. And It's, it's not related to how much you put into it, right? Like how does social security work in Terms of It's partially, I think it's partially related. So I think there is, I'm not a total expert on this stuff, but I think, I think there's some guaranteed minimum you get and then, and then, and then if you put more in, you get somewhat more and then it's, it's capped at a certain amount And even certain Certain amount.

(8m 15s):
And that's why, that's why, that's why social security taxes are capped at something like You know $150,000 a year. And then this is, you know, this is one of the, this is one of the really big tax increase proposals that's out there is to, is to uncap it, which would effectively be a 12.4% income tax hike, You know. Oh wow. All your income Adjust to social security. Sure. Because the, the argument is the argument, the, the, the sort of progressive left democrat argument is that, is that it's You know, why should you have a regressive social security tax? Why should you pay 12.4% or whatever the social security tax is, which half gets paid by by you, half gets paid by your employer.

(8m 56s):
But then it, it, it's capped at like 1 40, 1 50 k, some, some level like that. And what should be regressive where if you make 500 K or a million KA year, you pay zero tax on your marginal income. Mm. And that makes no sense. If it's a welfare program, if it's a, if it's a retirement savings program and your, your payout's capped, then You know if you, you don't need to put in more than you get out. Well that's logical. But there's not a lot of logic going on with the way people are talking about taxes today. Like California just jacked their taxes up to 14, what was it, 14 four? Something like that. Yeah, 14 three I think. Which is hilarious. Maybe more. Yeah, 49 something. Yeah. I mean, you want more money for doing a terrible job and having more people leave for the first time ever in like the history of the state.

(9m 43s):
Yeah. But it look, it, it gets away with it. I know. And, and so well people are Forced with no choice. What, are you gonna do It is, it is. I mean, I mean, there are people at the margins who leave, but, but the state government still collects more and more in revenues. So it's You know you get, I don't know, you get 10% more revenues and 5% of the people leave you still, you still increase the amount of revenues you're getting. It's, it's, it's, it's inelastic enough that you, you're actually able to increase the revenues. I mean this is sort of the, the crazy thing about California is You know there, there's always sort of a right wing or libertarian critique of California that, you know, it's, it's such a ridiculous place, but shouldn but shouldn just collapse under its own ridiculousness and it doesn't quite happen.

(10m 35s):
You know, the, the macroeconomics on it are, are pretty good. You know 40 million people. The GDP P'S around 4 trillion. It's about the same as Germany with 80 million or Japan with 125 million. Japan has three times the population of California. Same. GDP means one third the per capita GDP. So there's some level on which You know California as a whole is working, even though it doesn't work from a governance point of view, it doesn't work for a lot of the people who live there. And the the rough model I have for how to think of California is that it's kind of like Saudi Arabia and you have a crazy religion woke in California, wahhabism in Saudi Arabia, you know, not that many people believe it, but it, it distorts everything.

(11m 20s):
And then, and then you have like oil fields in Saudi Arabia and you have the big tech companies in California and the oil pays for everything. And, and then you have a completely bloated, inefficient government sector and, and you have sort of all sorts of distortions in the real estate market where people also make lots of money in sort of the government and real estate are ways you redistribute the oil wealth or the You know, the, the, the big tech, the big tech money in, in California. And, and it's like, it's, it's not the way you might wanna design a system from scratch, but it's, it's pretty stable. you know, people have been saying Saudi Arabia is ridiculous.

(12m 1s):
It's gonna collapse in a year. Now they've been saying that for 40 or 50 years, but You know if you have a giant oil field, you can pay for a lot of ridiculousness. I think that's, that's the way to, that's that's the way you have to think of California. Well the other thing is You're also, there are things about it that are ridiculous, but there's something about it that You know it, it doesn't naturally self-destruct overnight. Well, there's A lot of kick ass people there and there's a lot of people that are still generating enormous amounts of wealth there and it's too difficult to just pack up and leave. Yeah. I think it's something like four of the eight or nine companies with market capitalizations over a trillion dollars are based in California. So it's That's amazing. It's Google Apple now.

(12m 42s):
Nvidia meta, I think. Yeah, I think, I think Broadcom's close to that. And there's no ideal place to live either. It's not like California sucks. So there's a place that's got it totally dialed in with also that has an enormous, GDP also has an enormous population. There's not like one big city that's really dialed in. Well, it's, there are, there are things that, that worked. So I looked, I looked at all the zero tax states in the US and, and it's always, you don't You know. I think the way you ask the question gets at it, which is you don't live in a You know, in theory, a lot of stuff happens on a state level, but you don't live in a state, you live in a city.

(13m 28s):
And so if you're somewhat biased towards living in at least a moderately sized city, okay, I can, there are, I think there are four states where there are no cities, Alaska, Wyoming, South Dakota, New Hampshire, there's zero tax, but no cities to speak of. And then you have, then you have Washington State with Seattle where the weather's the worst in the country. You have Nevada with Las Las Vegas, which I'm not that big a fan of. And then that leaves 3, 3 0 tax states. You have Texas, which I like as a state, but I'm not that big a fan of Austin, Dallas or Houston.

(14m 13s):
and I You know, it's a sort of Houston, it's just sort of an oil town, which is good if you're in that business. But otherwise not Dallas has sort of a inferiority complex to LA and New York, You know, just not, not the healthiest attitude. And then, you know, I don't know, Austin's a government town and a college town and a want tobe hipster San Francisco town. So You know my, my book's sort of three strikes in your, you're kind of out too. And then that leaves, that leaves Nashville, Tennessee, which was, and then, or Miami, south Florida. And those, those would be my two top choices. Miami's fun, but I wouldn't wanna live there.

(14m 53s):
It's a fun place to visit. It's a little too crazy, A little too chaotic, a little too cocaine fueled, a little too party, party party. I think it's, I think it's pretty, I think it's pretty segmented from the tourist, the tourist strip from everything else. It, it probably is You know, there probably is something A little bit paradoxical about any place that gets lots of tourists, right. Where You know it's, it's, it's in some sense of a ca there's some things that are great about it because so many tourists go, but then in some sense it's, it creates a weird aesthetic because the You know the, the day-to-day vibe is that you don't, you don't work and you're just having fun or some, something like that, right?

(15m 35s):
'cause so many people are going there just to do that. And that's, that's probably A little bit off with the South Florida, the South Florida thing. But, but I think it's, and then I think and I think Nashville is is is also sort of its own real place. Nashville's great. Yeah. So those, those would be my, those are the top two. I I could live in Nashville. No problem. Yeah. I'm probably always, I'm always, I'm always too You know. I fifth grade onwards since, you know, 70, 77 I lived in California and, and, and so I'm just a sucker for the weather. and I think there is no place besides coastal California.

(16m 17s):
We have really good weather year round in the US may maybe Hawaii's pretty good Coastal. California's tough to beat. And, and You're two hours from the mountains And man, it's like You know it's mid-August here in Austin. This is just, it's just brutal. Is it? I I think so. Really? That was too hot for you. It was too hot for me. Today's mild. I, well, what is it out there? Like 80, all right. 85 9 6 96. You're proving my point. Do so much sauna that I literally don't even notice it. I'm outside for hours every day shooting arrows and I don't even notice it. Well that's, I I don't know if you're a representative of the average Austin president, I don't know, but I think you get accustomed to it. To me it's so much better than too cold.

(16m 59s):
Too cold. You can die and I know you can die from the heat, but you probably won't. Especially if you have water, you'll be okay. But you could die from the cold cold's real. So really cold places. There's five months outta the year where your life's in danger where you could do something wrong. Like if you live in Wyoming and you break down somewhere and there's no one on the road Yep. You could die out there. That's real. You could die from exposure. Sure. There's probably some very deep reason there's been a net migration of people Oh yeah. To the sun Oh. yeah. The west and the south and the US over California. You, the five decades can do no wrong. As long as the earth doesn't move, you're good. As long as there's no tsunamis, you are good. It is a perfect o environment virtually year round. It gets a little hot in the summer, but again, coastal, not at all.

(17m 42s):
if you get an 80 degree day in Malibu, it's unusual. You know, right? It's wonderful. Right. You got a beautiful breeze coming off the ocean, sun's out, everybody's pretty, But, and then, and then it's, yeah, it's, it's correlated with confiscatory taxation. Yeah. They all, it's all sort of a package deal. Well, it's a scam. You know, they know you don't wanna leave. I didn't wanna leave California. It's fucking great. I I, I appreciate you left. I always, I always have the fantasy that if enough people like you leave, it'll put pressure on them. But it's, it's never quite enough. Never quite enough. And it's not going to be, it's too difficult for most people. It was very difficult for me. and I had a bunch of people working for me that were willing to pack up and leave like young Jamie over there. But we, you know, it was tricky. You're you're taking your whole business and my business is talking to people.

(18m 24s):
That's part of my business. My other business is standup comedy. So So You left during, during Covid or I left at the very beginning. As soon as they started locking things down, I'm like, oh, these motherfuckers never let me go. April, March, April, May, 2020. In May, I started looking at houses. Cool. That's when I came to Austin first. I I, I got a place in Miami in September, 2020. And, and I spent the last You know I've spent the last four winters there. So I'm sort of always on the cusp of, of moving to Florida. Hard, hard to get out of California. But the, the thing that's gotten a lot harder about moving relative to four years ago, and you know, I I'd say I think my real estate purchase have generally not been, not been great over the years.

(19m 8s):
I mean, they've done okay, but certainly not, not the way, not the way I've been able to make money at all. But with the one exception was Miami bought it in September, 2020 and probably You know four, fast forward four years, it's up like a hundred percent. Wow. Or some, something like that. And, and, and then, but then paradoxically, this also means it's, it's gotten much harder to move there or Austin or, or any of these places. You know, if you You know if, if, if I relocated my office in LA the people who own houses You know, okay, you have to, you have to buy a place in Florida.

(19m 52s):
It costs twice as much as it did four years ago. And then the interest rates have also doubled. And so you get a 30 year mortgage, you could have locked that in for 3% in 2020. Now it's You know, maybe six point a half, 7%. Oof. So the prices have doubled, the mortgages have doubled, so it cost you four times as much to buy a house. And so, yeah. So There was a moment where people could move during Covid and it's, it's, it's gotten dramatically harder relative to what it was four years ago. Well, the Austin real estate market went crazy and then it came back down A little bit. And it's in that down A little bit spot right now where there's a lot of like high-end properties that are still for sale. They can't move.

(20m 32s):
It's different. You know, it's, there's not a lot of people moving here now. Like There was in the boom. 'cause everything's open everywhere. Well, I, I I, I, I somehow think Austin was linked to California and Miami was linked A little bit more to, to New York. Mm. And it was A, little bit You know all these differences. But Austin was kind of part, You know, a big part of the move were people from tech, from California that moved, moved to Austin. you know, there's a part of the Miami South Florida thing, which was people from finance in New York, New York City that moved, moved to, to Florida. And the finance industry is less networked on New York City.

(21m 14s):
So I think it is possible for people, if you run a You know private equity fund or if you work at a bank, it's possible for some of those functions to easily be moved to, to a different state. The tech industry is crazily networked on California. Like there's probably some way to do it. It's, it's, it's not that easy. Mm. Yeah, it makes sense. It, it makes sense too. It's just the sheer numbers. I mean, when you're talking about all those corporations that are established and based in California, there's so many, they're so big. Just the sheer numbers of human beings that live there and work there that are involved in tech. Sure.

(21m 54s):
If it wasn't, if it wasn't as networked, you know, you could, you could pro probably just move You know. And, and maybe these things are networked till they're not You know De Detroit was very networked. The car industry was super networked on Detroit for decades and decades. And Michigan got more and more mismanaged and people thought the network sort of protected them because, you know, the big three car companies were in Detroit, but then you had all the supply chains were also in Detroit. And then eventually it was just so ridiculous. People moved, started moving the factories outside of that area and it sort of unraveled. So that's You know, it can also happen with California. It'll just take a lot. That would be insane if they just abandoned all the tech companies in California.

(22m 36s):
I mean, just look at what happened at Flint, Michigan when all the auto factories pulled out. Well, it's, it's, look, I I think you can, it's always there are all these paradoxical histories. You know, the, the internet, the point of the internet in some sense was to eliminate the tyranny of place. And that was sort of the idea. And then one of the paradoxes about the inter history of the internet was that the internet companies, you know, were You know We, were all You know We, were all centered in, in California then there, yeah, there probably, there have been different, different waves of, of how networked, how, how non-network they were.

(23m 17s):
I think, I think probably 2021 sort of the, the covid moving away from California. The, the big thing in tech was crypto and, and crypto had this conceit of a You know alternate currency decentralized away from the central banks, but also the crypto companies, the crypto protocols. You could do those from anywhere. You could do them outside the us you could do them from Miami. And so crypto was something where the tech could naturally move out of California. And, and today probably the, the, I dunno, the core tech narrative is completely flipped to AI.

(24m 2s):
And, and if, and then there's something about AI that's, you know, very centralized You know. I always, I had this one-liner years ago where it was, you know, if, if we say that crypto is libertarian, can we also say that AI is communist or something like this where the You know the natural structure for an AI company looks like it's a big company. And then somehow the AI stuff is, is feels like it's gonna be dominated by the, the big tech companies in, in the San Francisco Bay area. And so if that's, that's turning for, that's the future of tech. Yeah. The, The the the scale, the natural scale of the industry tells you that it's going to be extremely hard to get out of You know outta the San Francisco Bay area.

(24m 50s):
When you look to the future and you try to just make a, just a guess as to how all this is gonna turn out with ai, what do you think we're looking at over the next five years? Man, I, I think you shouldn start by being modest in answering that question, saying that nobody has a clue, right? Which Is true. They, which pretty much all the experts say You know. I, I would say, let me, let me do sort of a, his history. I, the, the, the riff I always had on this was that I can't stand any of the buzzwords. And I felt AI You know, there's all this big data cloud computing, there are all these crazy buzzwords people had and they always were ways to sort of abstract things and get away from, from, from reality somehow.

(25m 39s):
And we're not good ways of talking about things. and I thought AI was this incredible abstraction because it can mean the next generation of computers. It can mean the last generation of computers. It can mean anything in between. And if you think about the AI discussion in the 2010s pre open AI chat, GBT and the, the revolution of the last two years. But the 2010s ai discussion, maybe it was, so I'll start with the history before I get to the future, but the history of it was, it was maybe anchored on two, two visions of what AI meant. And one was Nick Bostrom Oxford Prof who wrote this book, super Intelligence 2014.

(26m 21s):
And it was basically AI was gonna be this super duper intelligent thing way, way God-like intelligence way smarter than any, any human being. And, and then There was sort of the, the, I don't know, the CCP Chinese communist rebuttal, the Fu Lee book from 2018, AI superpowers and I think the subtitle was something like the race for AI between Silicon Valley and China or something like this. And it, it was sort of, it defined AI as it was fairly low tech. It was just surveillance, it, it know facial recognition technology.

(27m 2s):
We would just have this sort of totalitarian stalinist monitoring. It didn't require very much innovation. It just required that you apply things and basically the subtext was China's going to win because we have no ethical qualms in China about applying this, this sort of basic machine learning to, to sort of measuring or controlling the, the, the population. And those were sort of like say two extreme competing visions of, of what AI would mean in the, in the 2010s. And that sort of maybe were sort of the anchors of, of, of the AI debate. And then, and then You know what, what happened in some sense with chat GPT in late 22, early 23 was, was that the achievement, you, you got, you did not get super intelligence.

(27m 59s):
It was not just surveillance tech, but it was you, you, you actually got to the holy grail of what people would've defined AI as from 1950 to 2010 for the previous 60 years before the 2010s. People would always said ai, the definition of AI is passing the Turing test and the Turing test it, it basically means that the computer can fool you into thinking that it's a human being. And, and, and it's a somewhat fuzzy test because You know, obviously if you have an expert on the computer or non-expert, you know, it's You know. Does, does it fool you all the time or some of the time, how good is it? But to first approximation the Turing test You know we weren't even close to passing it in 2021.

(28m 45s):
And then You know chat GPT basically passes the Turing test at least for like, let's say an IQ 100 average person. It can, it can, it's passed the Turing test. And that was, that was the holy grail, that was the holy grail of AI research for the previous 60 years. And, and, and so there's, I dunno, there's probably some psychological or sociological history where you can say that this weird debate between Bostrom about super intelligence and Fu Lee about surveillance tech was like this almost like psychological suppression people had where they were not thinking they, they lost track of the Turing test of the holy grail of, because it was about to happen.

(29m 27s):
And it was such a significant, such an important thing that you didn't even want to think about. So I'm, I'm tempted to give almost a psychological repression theory of, of the 2010 debates, but be that as it may, the Turing test gets, gets passed and that's yeah, that's an extraordinary achievement. And then You know may, maybe may and then, you know, where, where does it go from here? There, there probably are ways you can fin ref refine these. It's still gonna be You know a a long time to apply it. There is a question, there's this a GI discussion, you know, will we get artificial general intelligence, which is a hopelessly vague concept, which You know general intelligence could be just a generally smart human being.

(30m 16s):
So is that just a person with an IQ of one 30 or is it super intelligence? Is it god-like intelligence? So it's sort of an ambiguous thing, but I I keep thinking that maybe the a GI question's less important than passing the Turing test. If, if, if we got a GI, if we got let's say super intelligence, if we got, that would be interesting to Mr. God, because you'd have a competi you'd have competition for being God. But, but surely the Turing test is more important for us humans because it's either a compliment or a substitute to humans. And so it's, yeah, it, it's gonna rearrange the economic, cultural, political structure of our society in extremely dramatic ways.

(31m 3s):
And, and I think maybe what's already happened is much more important than anything else that's gonna be done. And then it's just gonna be a long ways in applying it. One, one last thought. The You know, the, the, the analogy I'm always tempted to go to and it's, these things are never, historical analogies are never perfect, but it's, it's that maybe AI in 20 23, 24 is like, it's like the internet in 1999 where on one level it's clear the Internet's going to be big and get very a lot bigger and it's gonna dominate the economy, it's gonna rearrange the society in the 21st century.

(31m 47s):
And then at the same time it was a complete bubble and people had no idea how the business models worked. you know, almost everything blew up. It, it took, you know, it didn't take that long in the scheme of things. It took You know 15, 20 years for it to become super dominant. But it didn't happen sort of in 18 months as people fantasized in in 1999. And, and maybe, maybe, maybe what we have in AI is, is is something like this. It's figuring out how to actually apply it You know in sort of all these different ways is gonna take something like two decades.

(32m 28s):
But, but that doesn't distract from it being a really big deal. It Is a really big deal. and I think you're right about the during test. I do you think that the lack of acknowledgement or the public celebration, or at least the, this like mainstream discussion, like, which I think should be everywhere that we've passed the Turing test, do you think it's connected to the fact that this stuff accelerates so rapidly that even though we've essentially breached this new territory, it, we still know that GPT five is gonna be better, G PT six is gonna be insane and then they're working on these right now and the, and the change is happening so quickly, we're almost a little reluctant to acknowledge where we're at.

(33m 10s):
Yeah, You know, I, I've, I've often, I've You know probably for 15 years or so often been on the side that there isn't that much progress in science or tech or not as much as Silicon Valley likes to claim. And, and even on the AI level, I think it's a massive technical achievement. It's still an open question, you know, is it actually gonna lead to much higher living standards for everybody? You know the internet was a massive achievement. How much did it raise people's living standards? Much much trickier question. So, so I I I, but, but in, in this world where not much has happened, one of the paradoxes of a of an era of relative tech stagnation is that when something does happen, we don't even know how to process it.

(34m 2s):
So You know, I think, I think Bitcoin was a I mean, it was a big invention. We can debate whether it was good or bad, but it was a pretty big deal. And it was, it systematically underestimated for at least You know the first 10, 11 years. And You know you could, you could trade it. It went up smoothly for 10, 11 years. It didn't get repriced all at once because we're in a world where nothing big ever happens. And, and so we, we have no way of processing it when something pretty big happens. The internet was pretty big in 99. Bitcoin was moderately big. The internet was really big, Bitcoin was moderately big. And I'd say passing the Turing test is really big.

(34m 43s):
It's on the same scale as the internet. And, and because our, our lived experiences that so little has felt like it's been changing for the last few decades, we're, we're probably underestimating it. It's interesting that you say that so little. We feel like so little has changed. 'cause if you're a person, how old are you? Same age as you were. Okay. Born 1967. So In our age, we've seen all the change, right? We saw the end of the Cold War, we saw answering machines, we saw VHS tapes, then we saw the internet and then where we're at right now, which is like this bizarre moment in time where people carry the internet around with them in their pocket every day.

(35m 25s):
And these super sophisticated computers that are ubiquitous, everybody has one. There's incredible technology that's being ramped up every year. They're getting better all the time. And now there's ai, there's AI on your phone. You could access chat, GPT and a bunch of different programs on your phone. and I think that's an insane change. I I think that that's one of the most, especially with the use of social media, it's one of the most bizarre changes. I think our culture's ever the most bizarre. It it Can be a, it can be a big change culturally or, or politically. But the, yeah, the kinds of questions I I'd ask is how do you measure it economically? Does it, how much does it change GDP?

(36m 6s):
How much does it change productivity? And and certainly the, the story I I would generally tell for the last 50 years since the 1970s, early seventies is that we've been not absolute stagnation. We in an era of relative stagnation where there has been very limited progress in the world of atoms, the world of physical things, and there has been a lot of progress in the world of bits, information, computers, internet, mobile, internet, You know now, now ai, what Are you referring to when you say the, the world of physical things?

(36m 47s):
You know it's any, it's, well, if, if we had to find technology, if We were sitting here in 1967, the the year We were born and we had a discussion about technology, what technology would've meant, would it, it would've meant computers. It would've also meant rockets. It would've meant supersonic airplanes. It would've meant new medicines. It would've meant the green revolution in agriculture, maybe underwater cities. You know it. It sort of had be, and it, because technology simply gets defined as that which is changing, that which is progressing. And so there's progress on all these fronts. T today lasts 20 years.

(37m 29s):
When you talk about technology, you're normally just talking about information technology. Technology has been reduced to meaning computers. And that tells you that the structure of progress has been weird. There's been this narrow cone of very intense progress around the world of bits around the world of computers. And then all the other areas have been relatively stagnant. We're not moving any faster. You know the Concord got decommissioned in 2003 or whenever. And then with all the low tech airport security measures, it takes even longer to fly to get through all, all of them from, from from one city to the next. You know the highways have gone backwards because they're more traffic jams. We haven't figured out ways around those.

(38m 9s):
So they're sort of, we're literally moving slower than We were 40 or 50 years ago. And, and then yeah, as, as some, and that's, that's sort of the, that's sort of the, and then, you know, the, and then of course there's also a sense in which these, the screens and the devices You know, have, have this effect distracting us from this. So You know, when you're You know, riding a hundred year old subway in New York City and you're looking at your iPhone, you can, you can look at, wow, this is this cool new gadget, but you're also being distracted from the fact that your lived environment hasn't changed You know in a hundred years.

(38m 50s):
And, and, and so there's, yeah, there's a question. How important is this world of bits versus, versus the world of atoms? you know, I would say as human beings, we're physically embodied in a material world. And so I I I would always say this world of atoms is pretty important. And when that's pretty stagnant, you know, there's a lot of stuff that, that doesn't make sense. I I was an undergraduate at Stanford, late eighties. And at the time, in retrospect, every engineering area would've been a bad thing to go into You know, mechanical engineering, chemical engineering, all these engineering fields where We were tinkering and trying to do new things because these things turned out to be stuck.

(39m 31s):
They were regulated. You couldn't come up with new things to do. Nuclear engineering, AeroAstro engineering people already knew those were really bad ones to go into. They were You know outlawed. You weren't gonna make any progress in new nuclear reactor designs or stuff like that. Electrical engineering, which was the one that sort of adjacent to making semiconductors, that one was still okay. And then the only field that was actually gonna progress a lot was computer science. And, and again, You know, it's, it's been very powerful. But that was not the felt sense in the 1980s. In the 1980s. Computer science was this ridiculous inferior subject.

(40m 12s):
You know, i I always, the, the linguistic cut is always when, when people use the word science, I'm in favor of science. I'm not in favor of science in quotes. And when that, it's always a tell that it's not real science. And so when we call it climate science or political science or social science, You know, you're just sort of making it up and you have an inferiority complex to real science or something like physics or chemistry. And computer science was in the same category as social science or political science. It was, it was a fake field for people who found electrical engineering or math way too hard and, and, and sort of dropped out of, out of the real, the real science and real, real engineering fields.

(40m 55s):
You don't feel that climate science is a real science? It's, it is. I, it's, it's, well, let me, it's, I I I there's several different things. One could say it's, it's possible climate change is happening, it's possible. We don't have great accounts of why that's going on. So I'm not, I'm not questioning any of those things, but, but how scientific it is. I I don't think, I don't think it's, it's a place where we have really vigorous debates. You know may, maybe the climate is increasing 'cause of carbon dioxide emissions temperatures are going up.

(41m 39s):
Maybe it's methane. Maybe it's people are eating too much steak. It's the cows flatting or, and you have to measure, you know, how how much is methane a greenhouse gas versus, versus carbon dioxide. I don't think they're, I don't think they're rigorously doing that stuff scientifically and I think the fact that it's called climate science tells you that it's more dogmatic than, than, than anything that's truly science should be Doesn't That dogma doesn't mean it's wrong. But, But why is the fact that it's called climate science mean that it's more dogmatic? Because if you said nuclear science, you wouldn't question it, right? It's Yeah. But it's, no one calls it nuclear science. They call it nuclear engineering. Interesting. Because No, I'm, I'm just, I see what you're saying. The only, the only thing is I was just making, I'm just making narrow linguistic points. Is There anything called science that is legitimately science?

(42m 21s):
Well, At this point people say computer science has worked, but Right. In the 1980s, all I'm saying is it was in the same categories, let's say social science, political science. It was, it was, it was a tell that the people doing it kind of deep down knew they, they weren't doing real science. Well, there's certainly ideology that's connected to climate science. And then there's certainly corporations that are invested in this, this prospect of green energy and the concept of green energy. And they're profiting off of it and pushing these different things, whether it be electric car mandates or whatever it is, like California, I think they, it's 30, 20, 35. They have a mandate that all new vehicles have to be electric, which is hilarious when you're connected to a grid that can't support the electric cars it currently has.

(43m 6s):
After they said that within a month or two, Gavin Newso asked people to not charge their Teslas because it was summer and the grid was fucked. Yeah. Look, it's, it, it, it was all linked into all these ideological projects, right? In all these ways. And there's, you know, there's, there's an environmental project, which is, you know, and, and maybe, maybe it shouldn't be scientific You know there's the You know, the hardcore environmentalist argument is we only have one planet and we don't have time to do science. If, if we, if we have to do rigorous science and you can prove that we're overheating, it'll be too late. And, and so if you're a hardcore environmentalist You know you don't want to have as high a standard of science.

(43m 48s):
Yeah. My my intuition is certainly when, when you go away from that, you end up with things that are too dogmatic, too ideological may, maybe it doesn't even work, even if the planet's getting warmer. You know, maybe climate science is, is not, like, my, my question is, is carbon, like maybe methane is a worse, is is is it more dangerous greenhouse gas than carbon dioxide? We're not, we're not even capable of measuring that. Well, we're also ignoring certain things like regenerative farms that sequester carbon. That that, and then you, you have people like Bill Gates saying that planting trees to deal with carbon is ridiculous. That's a ridiculous way to do it. Like how is that ridiculous? Is they literally turn carbon dioxide into oxygen.

(44m 31s):
It is their food, their food. That's what the food of plants is. That's, that's what powers the, the whole plant life and the way we have the symbiotic relationship with them. Like, and the more carbon dioxide is the greener it is, which is why it's greener today on earth and has been in a hundred years. Sure. These are all facts that are inconvenient to people that have a very specific narrow window of how to approach this. Sure. Although You know there probably are ways to steal man, the other side too, where, where maybe, maybe You know the, the original 1970s You know, I think the manifesto that's always very interesting from the other side was this book by the Club of Rome 1972, the limits of growth.

(45m 18s):
And it's, you can't have you, we need to head towards a society in which there's 0%, there's very limited growth. Because if you have unlimited growth, you're gonna run out of resources. if you don't run out of resources, you'll hit a pollution constraint. But the, in the 1970s it was, you're gonna have overpopulation, you're gonna run out of oil. We had the oil shocks. And then, and then by the nineties it was, it sort of morphed into more of the pollution problem with, with carbon dioxide, climate change, other, other environmental things. But, but there is sort of, you, you know, it's You know. There's been some, you know, some improvement in, in oil carbon fuels with fracking, things like this in Texas, it's, it's not at the scale that's been enough to You know, give an American standard of living to the whole planet.

(46m 11s):
And we consume a hundred million barrels of oil. You know a day globally, maybe fracking can add 10%, 10 million to that. If everybody on this planet has an American standard of living, it's something like three, 300, 400 million barrels of oil. and I don't, I don't think that's there. So that's, that's kind of, i I always wonder whether that was the, that was the real environmental argument is we, we can't have an American standard of living for the whole planet. We somehow can't justify this degree of inequality. And, and therefore, you know, we have to figure out ways to dial back and You know tax the carbon restrict it.

(46m 56s):
And, and maybe You know, maybe that's, there's some sort of a malthusian calculus that's more about resources than about pollution. Hmm. How much of that could the, the, the demand for oil could be mitigated by nuclear? It, you pro you probably could mitigate it a lot. There's, there's a question why the, why the nuclear thing has gone so wrong? It's, especially if you, if you have electric vehicles, right? Right. If, if you You know, know it's combustion engine's probably hard to get nuclear to work. But if you, if you shift to electric vehicles, you can, you can charge them, you know, your Tesla cars at night and that, that would seemingly work.

(47m 43s):
And there's definitely, yeah, there's definitely a history of energy where it was always in the direction of, you know, more intense use. It went from wood to coal to oil, which is a more compact form of energy. And in a way it takes up less of the environment. And then if we move from oil to uranium, that's even, you know, it, it, it, it's even smaller. And so in a sense, the smaller, the more dense the energy is, the less of the environment it takes up. And when we go back, when we go from oil to natural gas, which takes up more space and from natural gas to solar or wind, we have to, you know, you have to pollute the whole environment by putting up windmills everywhere. Or you have to, you know, right.

(48m 24s):
you know, you have to cover the whole desert with solar panels. And that is a good way to look at it because it is a form of pollution. And so, and so There was a way, There was a way that nuclear was supposed to be the, the, the energy mode of the, the 21st century. And then, yeah, there, there are all these, there these historical questions. Why did it, why did it get stopped? Why did we not, why did we not go down that route? The You know, the, the standard explanation of why it stopped was that it was, there were all these dangers. We had three Mile Island, 1979 You know Chernobyl in in 1986, and then the Fukushima one in Japan, I think 2011.

(49m 10s):
And you had these sort of, you had these various AC accidents. My alternate theory on why, why nuclear energy really stopped is that it it, it was, it was sort of dystopian or even apocalyptic because it turned out that it was all, it, it turned out to be very dual use. if you build nuclear power plants, it's, it's only sort of one step away from building nuclear weapons. And, and it turned out to be a lot trickier to, to separate those two things out than it looked and I think the You know the signature moment was 1974 or 75 when India gets the nuclear bomb.

(49m 56s):
and I the US I believe had transferred the nuclear reactor technology to India. We thought they couldn't weaponize it. And then it turned out it was pretty easy to weaponize. Ah, and then the, and then sort of the geopolitical problem with, with nuclear power was you either You know you need a double standard where we, we have nuclear power in the US but we don't allow other countries to have nuclear power because the US gets to keep its nuclear weapons. We don't let a hundred other countries have nuclear weapons. And this, that's an extreme double standard, probably A little bit hard to justify or, or you need some kind of really effective global governance where you have a one world government that regulates all this stuff, which doesn't sound that good either.

(50m 49s):
And, and then sort of the compromise was just to, to regulate it so much that You know maybe that the nuclear plants got grandfathered in, but it became too expensive to build new ones. Jesus, Like even China, which is the country where they're building the most nuclear power plants, they built way less than people expected a decade ago. Because You know, they, they don't trust, they don't trust their own designs. And so they have to copy the over safety overprotected designs from the west and the nuclear plants, nuclear power costs too much money. It's cheaper to do coal.

(51m 29s):
Wow. So, so if I You know, I'm not getting the numbers exactly right, but if you look at what percent of Chinese electricity was nuclear, it was, it wasn't that high. It was like maybe four, 5% in 20 13, 20 14. And the percent hasn't gone up in 10 years because, you know, they've maybe doubled the amount of electricity they used and maybe they doubled the nuclear. But the relative percentage is still, is still a pretty small part of the mix because it's just more expensive. When you have these You know over safety design reactors, they're probably ways to build small reactors that that, that are, that are way cheaper. But then you still have this, you still have this dual use thing You know, do you, do you create plutonium?

(52m 9s):
Do you You know, are are there ways you can create a pathway to building more nuclear weapons? And if There was innovation, if nuclear engineering had gotten to a point where You know, let's say there wasn't three Mile Island or Chernobyl didn't happen, do you think that it would've gotten to a much more efficient and much more effective version by now? Well, my, my understanding is there are, we, we have way, we have way more efficient designs. We have small, you, you can do small reactor designs, which which are, you don't need this giant containment structure. So it costs much less per kilowatt hour of, of electricity you produce. So I, I think we have those designs.

(52m 49s):
They're, they're just not allowed. And then, but then I think the problem is that if you were able to build them in all these countries all over the world, you still have this dual use problem. Right. and I, and again, my alternate history of what really went wrong with the nuclear power, it wasn't three mile and it wasn't Chernobyl. That's the, that's the official story. The real story was India getting the bomb. Wow. That makes sense. It completely makes sense. Geez Louise. And then this is, you know, this is always, you know, this is always the question about, there's always a big picture question. People ask me, you know, you know, if, if, if I'm right about this picture of You know this slow down in tech, this, this sort of stagnation in many, many dimensions.

(53m 36s):
And then there's always a question, you know, why, why did this happen? And, and my cop out answer is always why questions are overdetermined. Because You know it, it can be there, there are multiple reasons. And so it could be why, it could be we became a more feminized risk averse society. It could be that the education system worked well less well. It could be that We were just out of ideas. The easy ideas have been found. The hard ideas that covered nature's cupboard was bare, the low hanging fruit had been picked so that it can be overdetermined. But I think, I think one dimension that's not to be underrated for the science and tech stagnation was that an awful lot of science and technology had this dystopian or apocalyptic dimension.

(54m 25s):
And, and probably what happened at You know Los Alamos in 1945 and then with, with the thermonuclear weapons in the early fifties, it took a while for to really seep in. But it had this sort of delayed effect where You know maybe, maybe a, a stagnant world in which the physicists don't get to do anything and they have to putter around with DEI and you're not You know, but you don't build weapons that blow up the world anymore. You know. Is that a, is that a feature or a bug? And so the stagnation was sort of, was sort of like this, this response. And so it sucks that we've lived in this world for 50 years where a lot of stuff has been inert.

(55m 10s):
But if we had a world that was still accelerating on all these dimensions with supersonics and hypersonic planes and hypersonic weapons and You know modular nuclear reactors, maybe we wouldn't be sitting here and the whole world would've already blown up. And so we're, we're in that, we're in the stagnant path of the multiverse because it had, it had this partially protective thing. Even though in all these other ways, I feel it's, it's, it's deeply deranged our society. That's a very interesting perspective, and it makes a lot of sense. It really does. And particularly the dual use thing with nuclear power, and especially distributing that to other countries. When you talk about the stagnation in this country, like, I don't know how much you follow this whole UAP nonsense.

(55m 54s):
I know we met, what was that guy's name at your place? The, the guy who did Charity of the gods Oh. Yeah. Fundan. Yes. Yeah, Yeah. You, you, you didn't, you, you thought he was too crazy You like You, like Hancock. But you don't like Fundan. I said, I didn't think he's too crazy. He just willfully, in my opinion, ignores evidence that would show that some of the things that he's saying have already been solved. Hmm. and I think his, his hypothesis is all related to this concept that we have been visited and that that's how all these things were built and that this technology was brought here from another world.

(56m 36s):
and I think he's very ideologically locked into these ideas. and I think a much more compelling idea is that there were very advanced cultures for some reason 10,000 years ago, whatever it was, whatever the year was, where they, they built some of the insane structures. It's 45, a hundred years ago. They roughly think the pyramids were built, like what, whatever the fuck was going on there. I think those were human beings. I think those were human beings in that place in that time. And I think they had some sort of very sophisticated technology that was lost. And things can get lost. Things can get lost in cataclysms.

(57m 16s):
Things can get lost in, they can get lost in disease and famine and all. There's all sorts of war, all sorts of reasons. The burning of the library of Alexandria, there's all sorts of ways that technology gets lost forever. And you can have today, someone living in Los Angeles, in the most sophisticated high tech society that world has ever known, while you still have people that live in the Amazon, that live in the same way that they have lived for thousands of years. So those things can happen in the same planet at the same time. and I think, while the rest of the world was essentially operating at a much lower vibration, there were people in Egypt that were doing some extraordinary things.

(57m 57s):
I don't know how they got the information. Maybe they did get it from visitors, maybe they did, but there's no real compelling evidence that they did. I think there's much more compelling evidence that a cataclysm happened. When you look at the younger dry impact theory, it's all entirely based on science. It's entirely based on core samples and iridium content and, and also massive changes in the environment over a very short period of time. Particularly the melting in the ice caps in North America and just impact craters all around the world that we know. Something happened roughly 11,000 years ago, and probably again, 10,000 years ago. I think it's a regular occurrence on this planet that things go sideways and there's massive natural disasters.

(58m 42s):
and I think that it's, there's likely That there's the, there's the Bronze Age civilization collapse somewhere in the mid 12th century BC and, and probably the You know in some ways the, the one in which we have the best history is the fall of the Roman Empire, which was obviously Sure. The culmination of the classical world. And it's somehow, it's somehow extreme, extremely unravel. So my, yeah, I think, I think my my view on it is probably somewhere between yours and the, The Funkin. No, not funkin. I'm, I'm more on the, more on the, more on the prob the other side.

(59m 24s):
But let me, let me, lemme try to define why this, maybe agree on why this is so important today. This is not just of antiquarian interest and Right. The reason it matters today is because the alternative You know if, if, if, if, if you say civilization has seen great rises and falls, it's gone through these great cycles. You know may maybe the, the Bronze Age civilizations were very advanced, but someone came up with iron weapons. So There was just one dimension where they progressed, but then everything else they could destroy. And so, or You know, the fall of the Roman Empire was, again, this You know, pretty cataclysmic thing where there were diseases and you know, and then there were political things that unraveled, but somehow You know it was, was a massive regression for You know four or five, 600 years into the, into the dark ages.

(1h 0m 18s):
And the, the, the sort of naive, the progressive use things always just got monotonically better. And there's sort of this revisionist, purely progressive history where even the Roman empire didn't decline. And even You know this 1, 1, 1 sort of stupid way to quantify this stuff is with pure demographics. And so it's the question how many people lived in the past and, and the rises and falls of civilization stories. There were more people who lived in the Roman Empire because it was more advanced, it could support a larger population.

(1h 0m 58s):
And then the population declined. You know, city of Rome maybe had a million people at its peak. And then by You know, I dunno, 650 ad it's maybe it's down to 10,000 people or less. It, you have this complete wow collapse in population. And then, and then the, the sort of alternate, purely progressive view is the population has always just been monotonically increasing because it's a measure of how in some sense things in aggregate have, have always been getting better. So I am, I am definitely on your side. That population had great rises and falls. Civilizations had great rises and falls. And so that part of it, I I I agree with you or even You know, some variant of what Hancock or Pana can say.

(1h 1m 48s):
The, the, the place where I would say I think things are different is I don't think, I don't think, and, and, and, and, and therefore it seems possible something could happen to our civilization. That's, that's always the upshot of it. If, if, if it, if it had been monotonically always progressing, then there's nothing we should worry about. Nothing can possibly go wrong. And then certainly, certainly the thing the the, the sort of alternate Hancock fondant, Joe Rogan history of the world tells us is that we shouldn't take our civilization for granted. There's a, there are things that can go really haywire.

(1h 2m 28s):
I, I agree with that. The, the, the one place where I, I differ is I think, I do think our civilization today is on some dimensions, way more advanced than any of these past civilizations were. I don't think any of them had nuclear weapons. I don't think any of them had You know spaceships or, or or anything like that. And, and so the failure mode is likely to be be somewhat different from, from these, these past ones. Yeah, that makes sense. I think technology progressed in a different direction. That's what I think.

(1h 3m 9s):
I think structural technology, building technology at somehow or another achieved levels of competence that's not available today. When you look at the construction of the great pyramid of Giza, there's 2 million, 300,000 stones in it. There, it, the whole thing points to do north, south, east and west. It's an incredible achievement. The the stones, some of them were moved from a quarry that was 500 miles away through the mountains. They have no idea how they did it. Massive stones. The ones inside the kings chamber where they're like, the biggest ones are like 80 tons. It's crazy. The whole thing's crazy. Like how did they do that? Like whatever they did, they did without machines. Supposedly they did without the, the use of the combustion engine, they didn't have electricity.

(1h 3m 52s):
And yet they were able to do something that stands the test of time, not just so you could look at it, You know, like you can go to the Acropolis and see the Parthenon. It's gorgeous. It's, it's amazing. It's incredible. But I can understand how people could have built it. The pyramids is one of those things. You just look at it and you go, what the fuck was going on here? What was going on here? And none of these people are still around you. You have this strange culture now that's entirely based around You know you have Cairo and an enormous population of visitors. Right. Which is a lot of it, people just going to stare at these ancient relics. What, what was going on? That those people were so much more advanced than anyone anywhere else in the world.

(1h 4m 34s):
Yeah, I would, I would, I, I'm not sure I would anchor on the technological part, but I think, I think the, the piece that is very hard for us to comprehend is what motivated them culturally. Well, how did they do it physically? Why, why did they do it? Why, why were you motive? Sure, why, but also how, how is a big one? Because it's really difficult to solve. There's no traditional conventional explanations for the construction, the movement of the stones, the amount of time that It would take if you moved 10 stones a day, I believe it takes 664 years to make one of those pyramids. So how many people were involved? How long did it take? How'd they get them there? How'd they figure out how to do it? How come the shittier pyramids seemed to be dated later?

(1h 5m 14s):
Like what, what was going on in that particular period of time where they figured out how to do something so extraordinary that even today, 4,500 years later, we stare at it and we go, I don't know. I don't know what the fuck they did. I, I haven't studied carefully enough. I'll, I'll, I'll trust you that it's very hard. I think the, the, I think the, I would say though, the real mystery is why were they motivated? Yeah. And it's because you can't live in a pyramid. It's just Right. It's, it's, it was just the afterlife of the Pharaoh. There's some debate about that. Christopher Dunn is an engineer who believes that it was some sort of a power plant. He's got this very bizarre theory that There was a chamber that exists. if you, you could see, well, you see the structure of the pyramid, the inside of it.

(1h 5m 55s):
There's a chamber that's subterranean. And he believes the subterranean chamber was pounding on the surface of the, of the earth and of the walls of the thing, creating this very specific vibration. They had shafts that came down into the queen's chamber, these shafts, they were pour chemicals into these shafts. And then There was limestone at the end of it. This is all his theory, not mine. The end of it, There was this limestone, which is permeable, right? So the limestone, which is porous, these gases come through and creates this hydrogen that's inside of this chamber. Then there are these shafts inside the king's chamber that are cr they're, they're getting energy from space You know gamma rays and all the shit from space.

(1h 6m 39s):
And that it's going through these chambers, which are very specifically designed to target this, these gases and put them into this chamber where they would interact with this energy. And he believes it's enough to create electricity. Man, my, It's a crazy theory, but Look, I'm, I'm always, I'm always too, too fast to debunk all these things, right? But like my, just coming back to our earlier conversation, it, it sound, it, it must have been a crazy power print to have a containment structure much bigger than a nuclear reactor. Yeah. Well, it's ridiculous. And so, but it's also a different kind of technology, right? If nuclear technology was completely not on the table, they didn't understand atoms at all. But they did understand that there's rays that come from space and that you could somehow harness the energy of these things with specific gases and through some method, convert that into some form of electricity.

(1h 7m 29s):
But It, if it takes so much power to put all these rocks on the pyramid, you have to always look at how efficient the power plant is. So, so it can't just be some, it has to be like the, the craziest reaction ever to justify such a big containment structure. 'cause even nuclear power plants don't work economically barely work. Yeah, it, well, they didn't do, a lot of them You know, they only did this one in Giza, and then There was other pyramids that he thinks had different functions that were smaller. But the whole purpose of it is, or the whole point of it is, we, we don't know what the fuck it is. We don't know why they did it. We have a group of new archeologists that are looking at it from a completely different theory.

(1h 8m 11s):
They're not looking at it like it's a tomb. The established archeologists have insisted that this is a tomb for the Pharaoh. The newer archeologists, established archeologists are looking at it and considering whether or not There was some other uses for this thing. And one of them is the concept of the peril Product. I'm, I'm always, I don't know if this is an alternate history theory, but I I'm always into the James Frazier Golden Bow, Rene Gerard violence sacred history, where You know you have always this question about the origins of monarchy and kingship and the, the, the sort of Gerard Frazier intuition is that it's something like, it is something like, if, if every king is a kind of living God, then we have to also believe the opposite.

(1h 9m 10s):
That maybe every God is a dead or murdered king. And that, that somehow societies were organized around scapegoats. The scapegoats were You know, There was sort of a crisis in the archaic community. It got blamed on a scapegoat. The scapegoat was attributed all these powers. And then at some point, the scapegoat before he gets executed, figures out a way to postpone his execution and turn the power into something real. And so there's sort of this, this very weird adjacency between monarch the, the monarch and the scapegoat. And, and then You know, I don't know, the sort of riff on the would be that the first pyramid did not need to be invented.

(1h 9m 55s):
It was just the stones that were thrown on a victim. And then it somehow, and that that's the original, the original stone, the Stones that were thrown on a victim. A community stones a victim to death, tribe runs after victim. You stone him to death, you throw stones on the victim. That's how you create the first tomb. Hmm. And then, and Then as it gets more complicated, you create a tomb that's 2 million stones. And, and you get a, you get a Pharaoh, you get a Pharaoh who figures out a way to postpone his own execution or something like this. I, I think there's, I'm gonna blank on the name of this ritual, but I believe in old, in, in the old Egyptian kingdoms, which were sort of around the time of the great pyramids, or even before there, it was something like in the 30th year of the reign of the Pharaoh, the Pharaoh gets transformed into a living God.

(1h 10m 53s):
And, and then this perhaps dates to a time where in the 30th year of the Pharaoh's reign, the Pharaoh would get richly sacrificed or, or killed. And you have You know you have all these societies where the kings lived, were allowed to rule for an allotted time. Or you You know you, you become king, and you, you draw the number of pebbles out of a vase. And that corresponds to how many years Was this Jamie? The said festival, HEB said Festival of Tales, an ancient Egyptian ceremony that celebrated the continued rule of Pharaoh. The name was taken from the name of the Egyptian wolf. God. One of Whom's name was whip whip wet. Yeah. This is what I'm Talking about or said.

(1h 11m 35s):
The less formal feast name, the feast of the tail is derived. So yeah, next paragraph's the one to start. Okay. This No, That one, that one right there. The, the, the ancient festival might perhaps have been instituted the Replacer, a ritual of murdering a Pharaoh who was unable to continue to rule effectively because of age or Condition. Interesting. Interesting. So you can't kill 'em now. And then eventually said festivals were Jubilee, several had thrown for 30 years. Mm. And then every three to four years after that. So when it becomes unthinkable to kill the pharaoh, the Pharaoh gets turned into a living God. Mm. Before that the Pharaoh gets murdered and then gets worshiped as a dead Pharaoh or distant God.

(1h 12m 15s):
That's Interesting. But it still doesn't solve the engineering puzzle, the engineering puzzle's, the biggest one. Like how do they do that? Well, The one I, the one I'm focusing on is the motivational puzzle. Why they, Even if you have all the motivation in the world, if you wanna build a structure that's insane to build today, and you're doing it 4,500 years ago, we're dealing with a massive puzzle. I, I think, I think I think the motivational part's the harder one to solve. if you, if you, if you can figure out the motivation, you'll, you'll, you'll figure out a way to organize the whole society. And if you can figure out, if you can get the whole society working on it, you can probably do it. But don't you think that his grasp on of power was in peril in the first place, which is why they decided to come up with this idea of turning them into a living God, so to, to have the amount of resources and power and then the engineering, and then the understanding of whatever methods they use to shape and move these things.

(1h 13m 10s):
Well, This is always the, this is always the anthropological debate between Voltaire, the enlightenment thinker of the 18th century and Durkheim, the 19th century anthropologist. And Voltaire believes that religion originates as a conspiracy of the priests to maintain power. And so politics comes first. The politicians invent religion. And then Durkheim says the causations the other way around, that somehow religion came first and then politics somehow came out of it. Now of course, you know, once the politics comes out of it, you know, the, the priests, the religious authorities have political power.

(1h 13m 51s):
They figure out ways to manipulate it, things like this. But, but I, I find, you know, I find the Durheim story far more plausible than the Volterra one. I think the religious categories are, are primary and the the political categories are, are, are secondary. So you think the religious, the religion came first, but what about if we emanated from tribal societies? Tribal societies have always had leaders. When you have leaders, you're gonna have dissent, you're gonna have challenges, you're gonna have politicking. You have people negotiating to try to maintain power, keep power, keep everything organized. That's the origin of politics. Correct. You know, I, I I think that's a, that's a whitewashed enlightenment, rationalist description of the origin of politics.

(1h 14m 36s):
Yeah. That's, What do you think the origin of Politics is? I think it's far more violent than that You know what you're, what you're giving me is, well, It's very vile. The control and power and maintaining power involves murder and sabotage. Well, that, okay. That's more like It. would you, what what, what what what you gave me a minute ago sounds more like a social contract theory in which people sit down, negotiate and have You know a nice legal chitchat to draw up the social contract. That is a complete fiction. Yeah. I don't think that, I think that There was probably various levels of civility that were achieved when agriculture and when establishments were constructed that were near resources where they didn't have to worry as much about food and water and things along those lines.

(1h 15m 19s):
Things probably got A, little bit more civil. But I think that the origins of it are like the origins of all human conflict. It's filled with murder. Well, I think at the beginning was madness and murder. Yeah, madness and murder And, and I don't know. I don't, I don't know if it got, I don't know if it got that much more rational. I don't know if it's that much more rational today. Well, So In some ways it's not. Right. In some ways I, This again, this again, back to the Yeah. You know the, the progressive conception. Are we, you know, are we really, have we really progressed? How much have we really progressed from from that? But, but yeah, I, my my, my version would be that it was, you know, it was much more, it was organized around You know acts of mass violence.

(1h 16m 8s):
Like maybe, maybe you externalize it onto, you know, a mastodon or hunting some big animal or something like this. But, but the real problem of violence, it, you know, it wasn't external. It was mostly internal. It was, it was violence with people who were near you proximate to you. It wasn't even natural ca cataclysms or other tribes. It was, it was, it was sort of much more the internal stuff. And it's very different. I think the, the human situation is somehow very, very different from something like, I don't know, an ape primate hierarchy where You know in an ape context, you have an alpha male You know he's the strongest and there's some sort of natural dominance.

(1h 16m 52s):
And you don't need to have a fight to the death typically, because You know who's the strongest. And you don't need to push it all the way in a human context. It's always possible for two or three guys to gang up on the alpha male. So, so it's, it's somehow the culture is more important. You know, and if, if they can talk to each other and you get language and then they can coordinate and they can gang up on, on the leader, and then you have to stop them from ganging up on the leader. And how, how do you do that? And so the, there's some sort of radical difference between a You know a human and a, let's say an a pre-human world. Have you seen Chimp empire?

(1h 17m 33s):
No. Chimp Empire is a fascinating documentary series on Netflix where these scientists had been embedded with this tribe of chimpanzees for decades. And so because they were embedded, they had very specific rules. You has to maintain at least 20 yards from you and any of the chimps, no food, you can never have food. And don't look them in the eyes. And as long as you do that, they don't feel you're a threat. And they think of you as a natural part of their environment, almost like you don't exist. And they behave completely naturally. Well, it shows in that, that sometimes it's not the largest, strongest one. And that some chimps form bonds with other chimps and they form coalitions and they do have some sort of politicking and they do help each other.

(1h 18m 16s):
They groom each other, they do specific things for each other. And then one of the things that happens also, they get invaded by other chimps and that chimps leave and they go on patrol and other chimps gang up on them and kill them. And they try to fight and battle over resources. So it's not nearly as cut and dry as the strongest chimp prevails. 'cause one of the chimps that was dominant was an older chimp, and he was smaller than some of the other chimps. But he had formed a coalition with all these other chimps, and they all respected him. And they all knew that they would be treated fairly. And being treated fairly is a very important thing with chimpanzees. They get very jealous if they think that things are not fair, which is why that guy was attacked. you know, that guy who had a pet chimpanzee, he brought it a birthday cake, the other chimps weren't getting a piece of the cake.

(1h 19m 3s):
And they, someone had fucked up and left a door open. They got out and mauled this guy because he didn't give them some of the cake. Yeah. So I, I find all of that quite plausible. But I think both of us can be correct. So there's some, the, the, the true story of hominization, of how we became humans. There's a way to tell it where it's continuous with our animal past and where it's just You know there's things like this with the chimpanzees or the baboons or You know other primates. And then there is a part of the story that I think is also more discontinuous and You know, my my judgment is we probably, you know, in a, in a Darwinian context, we always stress the continuity.

(1h 19m 46s):
You know, I'm, I'm always A little bit the contrarian. And so You know I, I believe in Darwin's theory, but I think, I think we should also be skeptical of ways it's too dogmatic. And, and Darwin's theories make us gloss over the discontinuities and I. Think You know the one, one type of happen overnight, but one type of fairly dramatic discontinuity is that You know is that humans have something like language. And even though You know chimpanzees probably, I dunno, have an IQ of 80 or they're pretty, they're pretty smart. But, but when you don't have a rich symbolic system that that leads to sort of a very, very different kind of structure. And, and there's something about language and the kind of coordination that allows, and the ways that it forces you to, it enables you to coordinate on violence.

(1h 20m 37s):
And then it encourages you to channel violence in certain sacred religious directions. I, I think creates a You know something radically different about human society. We are You know, we differ, You know. We, we tell humans, tell each other's stories. A lot of the stories are not true. They're myths. But that's, that is a, that's, I think that's an some, some sort of a very important difference from, from even our closest primate, primate relatives. But that You know, this is, again, this is sort of like another way of getting at what's so crazy about chat GPT and passing the touring test.

(1h 21m 18s):
Because if we had sat here two years ago and you asked me You know what, what is the distinctive feature of a human being? What makes someone a human and You know how? And in a way that differs from everybody else. you know, it's not perfect, but my go-to answer would've been language. You're You know, you're 3-year-old, you're an 80-year-old, you know, just about all humans can speak languages just about all non-human cannot speak languages. It's this, it's this binary thing. And then that's, that's sort of a way of telling us again why, why passing the Turing test was way more important than super intelligence or anything else. Hmm. Yeah, I could see that.

(1h 21m 58s):
What do you think, Sorry, I don't wanna go back to that tangent, but This is No, no, it's a good tangent. Go Ahead. Connect it. It's Great. Keep tangent and off. Have fun. It's great. Do you think, what, what do you think the factor was? There's a lot of debate about this. Like the factor was that separated us from these animals and why we became what we became because we're so vastly different than any other primate. Like, so what do you think took place? Like the doubling of the human brain size over a period of 2 million years is one of the greatest mysteries in the entire fossil record. We don't know what the fuck happened. There's a lot of theories, the throwing arm, cooking meat. There's a lot of theories, but we, we really have no idea. Well, Again, if I, if I lemme do sort of linguistic riff, I think Aristotelian, Darwinian biology, Aristotle, you always differ things by put them in categories and, and man, I think the line Aristotle has is something man differs from the other animals in his greater aptitude for imitation.

(1h 22m 57s):
And, and, and I would say it that we are these giant imitating machines. And of course the Darwinian riff on this is You know to imitate is to ape. Mm. And and so we differ from the ape. We're more ape-like than the apes. We are far better at aing each other than the apes are interesting. And, and that to You know a first cut, I would say our brains are giant imitation machines. That's how you learn language as a kid. You imitate your parents and that's how culture gets transmitted. But then there are a lot of dimensions of imitation that, that are also very dangerous because it's not, imitation doesn't just happen on this symbolic linguistic level.

(1h 23m 44s):
It's also you imitate things you want. You want a banana, I want a banana, you want a blue ball, I can have a red ball. I want a blue ball because you have a blue ball. Hmm. And, and, and so there's something about imitation that You know creates culture, you know, that that is incredibly important. Pedagogically, learning You know. It's how you master something, how, you know, in all these different ways. And then, and then a lot of it has this has this incredibly conflictual dimension as well. And, and then there's, yeah. So I think, I think that was sort of core to the things that are both great and troubled about humanity.

(1h 24m 31s):
And, and, and that was sort of, that was in some ways the problem that that needed to be solved. So You think that the motivation of imitation is the, the essential first steps that led us to become human There? There's some story like, and again, this is a one dimensional, right? One explanation fits all. But You know the, the sort of, the explanation I would I would go with is that it was, it was something like You know our brains got bigger and so We were more powerful imitation machines. And there were things about that that were You know that were, yeah, that made us a lot more powerful and a lot we could learn things and we could remember things and There was cultural transmission that happened.

(1h 25m 19s):
But then it also, we could build better weapons and we became more violent. And it, it also had a very, very destructive element. And then somehow the imitation You know had to be, had to be channeled in, in these sort of ritualized religious You know kinds of ways. And that's, that's, that's why I I I think all these things sort of somehow came to up together in parallel. But what about the physical adaptation? Like what would be the motivation of the animal to change form and to have its brain grow so large and to lose all its hair and to become soft and fleshy like we are as opposed to like rough and durable like almost every other primate is?

(1h 26m 6s):
Well you can always, man you can always tell these retrospective just so stories and how this all, all worked out. But it, It would seem the, the naive retrospective story would be that You know there are a lot of ways that humans are, I dunno, less strong than the other apes or You know the, all, all these ways where we're in some sense weaker physically, at least physically. But, but maybe it was just this basic trade off you, you know, more, more of your energy went into your mind and into your brain and, and then, you know, you, you were, your fist wasn't as strong, but you could build a better ax and that made you stronger than an ape.

(1h 26m 55s):
And that's, that's where yeah where, where, you know, a brain with You know less, I dunno, less energy we spend on growing a hair to keep warm in the winter. And, and then you use your brain to build ax and skin a bear and get, get some fur for the winter or some, something like that. Yeah, I guess it's just, but it's just such a leap. It's such a leap and different than any other animal. Like, and like what was the primary motivating factor? Like what was the thing You know McKenna believes it was psilocybin You know, I'm sure you probably you ever heard that theory McKenna's stone date theory, which is a fascinating one, but there's a lot of different theories about what took place.

(1h 27m 37s):
But We just Well, well the, the one, yeah, the one I would go on was that There was this dimension of increased imitation. There was some kind of cultural linguistic dimension that was incredibly important. It probably was also You know, it was probably also somehow linked to, to You know dealing with all the violence that came with it. All the conflicts that, that that came with it. You know I would be, I'd be more open to the stoned ape theory of people. I had this conversation with the other guy Murra rescue, the immortality key guy.

(1h 28m 20s):
Sure. And I always feel they whitewash it too much. How So? Oh, you know, it's like if, I mean, if, if you had these crazy dation rituals in which people You know if, you know, there's probably lots of crazy sex There was probably lots of crazy violence that was, was tied to it. And, and so maybe like, maybe you'd be out of your mind to be hunting a wooly mammoth and like maybe, maybe you can't be completely You know. But they weren't hunting wooly the Lucian mysteries. No, but you were, I dunno, you went to went to war to fight the neighboring tribe. It's probably more dangerous than hunting. Right. But they also did absolutely have these rituals and they have absolutely found trace elements of, I I don't, I don't question that.

(1h 29m 5s):
Okay. I don't question that at all. I, I I just, I I I just, I just think they, they probably part of it was als also was a way to channel violence was probably You know whenever. I don't know. Was there some, some degree to which whenever you went to war you were on drugs, you Were Oh. yeah, well we know about the stuff like the Vikings, the Vikings most certainly took mushrooms before they went into battle And, and you know, maybe it makes you less, less coordinated or something. But, but no, if if you're just, if you're less scared, it doesn't, that's Probably, it doesn't, it doesn't make you less coordinated If you're just A little bit less scared.

(1h 29m 46s):
That's probably super important. It increases visual acuity. There's a lot of benefits that would happen physically, especially if, if you got the dose right. You know. It increases visual acuity, edge detections better. It makes people more sensitive, probably more aware, probably a better hunter. And, But I, I think I th I th I'm, I'm, I'm sympathetic to all, all these mushrooms, psychedelic drug historical usage theories. I, I suspect was very widespread. I just think You know a lot of it was in, in these contexts that, that were pretty transgressive. Yeah. I think they're not mutually exclusive.

(1h 30m 27s):
I think just giving the, the way the world was back then for sure. Violence was everywhere. Violence was a part of daily life. Violence was a part of how society was kept together. Violence was entertainment in Rome. Right. For sure. Violence was, was everything. It was a big part of it. and I think release and, and the anxiety of that violence also led people to want to be intoxicated and do different things that separated them from a normal state of consciousness. But I do think it's also probably where democracy came from. I, I think having those ian mystery rituals where they would get together and do psychedelics and under this very controlled set and setting, I think that's the birthplace of a lot of very interesting and innovative ideas.

(1h 31m 13s):
and I think a lot of interesting and innovative ideas currently are, are being at least dreamt up thought of they have their roots in some sort of altered conscious experience. Well, it's, man, I, I don't know. I I think this stuff is very powerful. I think it is. It is. I definitely think it shouldn't be outlawed You know, pretty hardcore libertarian on all the drug legalization stuff.

(1h 31m 57s):
And then I I do, I do wonder, I do wonder exactly how, how, how, how, how these things work. It probably You know, probably the classical world version of it was that it was something that you did in a fairly controlled setting. You didn't do it every day. And it was, it was sort of, it was some, it was some way I imagine to get You know a very different perspective on your nine to five job or whatever you wanna call it.

(1h 32m 41s):
But you didn't necessarily want to You know, want to really decamp to the other world altogether. Oh, for sure. It's too dangerous to do. I don't think anybody thinks they did. I think that was part of the whole thing. W where do, where do you think, where do you think that line is? Like You know, should pe should everyone do one ayahuasca trip? Or if you do, if you do an ayahuasca trip a year, is that That too much? I don't think everyone has to do anything and I think everyone has their own requirements. and I think, I think as you do that, everything like this, especially psychedelics, one of the more disappointing things recently was that the FDA had denied.

(1h 33m 25s):
They, they did these MDMA trials for You know about all this. Yep. Yeah. Very, very disappointing that they wanted to make MDMA therapy available to veterans and people with severe PTSD. And it has extreme benefits, clinical benefits, known, documented benefits. And for whatever reason, the FDA decided that they have to go through a whole new series of trials to try to get this stuff legalized, which is very disappointing. And yeah, I I I, I was, I was very bullish on the stuff happening. And the way I thought about it four or five years ago was that it was a hack to doing a double blind study.

(1h 34m 7s):
And because the FDA always has this concept that you need to do a double blind study, you give one one You know one third of the people, you give a sugar pill and two thirds you give the real drug and you have to, and no one knows whether they have the sugar pill or the real drug. Right. And then, and then you see how it works. And science requires a double blind study. And then my, my anti double-blind study theory is if, if it really works, you don't need a double-blind study. but shouldn just work. And there's something sociopathic about doing double-blind studies because one third of the people who have this bad disease are getting a sugar pill. And we should, we shouldn't even be like, maybe it's immoral to do double blind studies.

(1h 34m 47s):
Well Double blind studies on unique and novel things. Makes sense. But this is not unique nor novel. It's been around a long well, unique yes, but Well, my, my, my, my claim is if it's, if it's a, if it actually works, you shouldn't need to do double blind study at all. But, and then my hope was that MDMA psychedelics, all these things, they were a hack on the double blind study because you knew whether you got the real thing or the sugar pill. And so this would be a way to, to hack through this ridiculous double-blind criterion and just to get the study done. And then what I, what I think part, part of it, it's probably just an anti-drug ideology by the FDA, but, but the other part that happened on the sort of science scientific establishment level is they think you need a double-blind study, Joe, we know you're hacking this double-blind study because people will know whether they got the sugar pill or not.

(1h 35m 46s):
And that's why we're gonna arbitrarily change the goalposts and set them at way, way harder because we know there's no way you can do a double blind study. And if it's not a double blind study, it's no good. Because that's what our ideology of science tells us. And, and that's sort of, that's sort of what I think was part of, part of what went sort of politically haywire with this stuff. Well, I also think that it's Pandora's box. I think that's a real issue. And that if they do find extreme benefit in using MDMA therapy, particularly for veterans, if they start doing that and it starts becoming very effective and it becomes well known and widespread, then it'll open up the door to all these other psychedelic compounds and I think that's a real threat to the powers that be.

(1h 36m 34s):
It's a real threat to the establishment. if you have people thinking in a completely alternative way. I mean, we saw what happened during the 1960s and that's one of the reasons why they threw water on everything. And had it become schedule one and locked the country down in terms of the, the access to psychedelics, all that stuff happened out of a reaction to the way society and culture was changing in the 1960s. If that happened today, It would throw a giant monkey wrench in our political system, in our cultural system, the way we govern, the way we just, the way allocation of resources. All that would change. If I, if I, if I just to articulate the alternate Yes version on this, there's always a You know, there's, there's a part.

(1h 37m 25s):
Lemme think how to, how to get this, you know, there's, there's one, there's a question whether this, the shift to interiority, is it a complement or a substitute? Like what I said about talk in action? Is it a compliment or a substitute to changing the outside world? So we focus on changing ourselves. Is this the first step to changing the world or is it, is it sort of a hypnotic way in which our attention is being redirected to from outer space to inner space? So, I dunno, the, the one liner I had years ago was You know, we landed on the moon in July of 1969 and three weeks later, Woodstock started and that's when the hippies took over the country.

(1h 38m 13s):
And, and you know, and we stopped going to outer space because we started going to inner space. And that's, and so there's sort of a question, you know, how much the You know? It, it, it, it, it worked as a, as an activator or as a, or as a, a deactivating in a way. And you know, there are all these different modalities of interiority. There's psychological therapy, there's meditation, there's yoga, there's You know There was a sexual revolution. There were gradually you have in cells living in their parents' basement playing video games. So there all You know, there's the naval gazing that is identity politics.

(1h 38m 56s):
There's a range of psychedelic things and, and I think all of these things. I I I wonder whether the interiority ended up acting as a, as a substitute. So, because You know the alternate history in the 1960s is that You know the hippies were actually, they were anti-political. And it was, it was sort of that the, the the, the drugs happened at the end of the city at the end of the sixties. And that's when people depoliticized You know. It was like, I dunno, the Beatles. So you're carrying around pictures of Sharon Mauer, you're not gonna make with anyone anyhow. It's like that's after they did it. LSD. And it was just the sort of insane politics no longer matters.

(1h 39m 39s):
And so you had the civil rights, the Vietnam War, and then were the drugs the thing that motivated it? Or was that, was that the thing where it actually those, those things started to, started to deescalate? I think they were happening at the same time. and I think the Vietnam War coinciding with the psychedelic drug movement of the 1960s, it was one of the reasons why it was so dangerous to the establishment. 'cause these people were far less likely to buy into this idea that they needed to fly to Vietnam and go kill people they didn't know. And they were far less likely to support any war. and I think There was this sort of bizarre movement that we had never seen before. This flower children movement that we know that they plotted against.

(1h 40m 20s):
I mean, if you read Chaos by Tom O'Neill Yep, yep. Familiar with it. Fantastic book that shows you Yes. What they were trying to do to demonize these, these hippies and Well, it was Or, or or the the, the, the part of it that I thought was interesting was the MK Ultra. Yeah. Which Is a Part of it. Yeah. Where You know We, There was a, a predecessor version where we thought of You know There was a, you could think of it as we had an arms race with fa the fascists and the communists. And they were very good at brainwashing people. The Globals propaganda North Koreans brainwashing our soldiers in the Korean War, our POWs. And we needed to have an arms race to program and reprogram and deprogram people.

(1h 41m 6s):
And LSD was, was was sort of the mk ultra shortcuts. So I think, I think There was, and then I, yeah, my, it's so hard to re reconstruct it, but my, my suspicion is that the MK Ultra thing was, was a lot bigger than, than we realized. And that You know it was, it was the LSD movement, both at, in the Harvard form and the Stanford form You know it started, it started as an MK Ultra project. Timothy Leary at Harvard, Ken Keesey at Stanford You know, I knew Tom Wolf, the American novelist. I still think his greatest novel was the Electric Kool-Aid Asset Test, which was sort of this history of the LSD counterculture movement starts at Stanford, moves the Haight Ashbury in San Francisco.

(1h 41m 54s):
And, but it starts with Ken Ke, he's grad student at Stanford, like circa 1958, and you get an extra $75 a day if you go to the Menlo Park Veterans Hospital and they give you some random drug. And yeah, he got extra $75 a grad student in English doing LSD and Tom Wolf writes this You know iconic fictionalized novel, very realistic 1968 about this. And Wolf could not have imagined that the whole thing started as some CIA mind control project.

(1h 42m 34s):
Right. The Menlo Park Veterans Hospital that was deep state adjacent. Sure. Well, Haight Ashbury free clinic run by the CIA. Sure. That's even crazier. The Whole thing's crazy jolly The whole thing's. The Jolly West Jolly West guy. Yep. Yeah. The the whole thing's crazy. Which leads me to, what do you think they're doing today? If they were doing that then I do not believe that they abandoned this idea of programming people. I do not believe that. I don't think they would. 'cause I know it's effective. Look, people join cults every day. We're well aware that people can be ideologically captured. We're well aware, we're well aware. People will buy into crazy ideas as long as it's supported by whatever community that they associate with.

(1h 43m 19s):
That's a, just a natural aspect of being a human being. Maybe it's part of what you were saying, this imitation thing that we have it, it leads us to do this if they have that knowledge and that understanding that for sure, they're probably doing things similar today, which is one of the things that I think about a lot when I think about this guy that tried to shoot Trump. I I wanna know what happened. and I and I don't think we're getting a very detailed explanation at all as to how this person achieved these, the how he they got on the roof, how they got to that position, how they trained. What, who were they in contact with, who was teaching them?

(1h 43m 59s):
Why did they, why did they do it? What was going on? We We were in the dark and I wonder like, you know, There was always the mentoring candidate idea. Right. This idea that we trained assassins and It was the RFK dad assassination 1960 Yes. Sirhan Sirhan Where he, again, maybe I shouldn't believe him, but he claimed that he didn't even know what he was doing. Right. It was some, some hypnotic trance or whatever. And it was like, it was like the assassin in the Mansur in Canada. Yeah. Yeah. I mean that is possible. I don't know if he's telling the truth. He could have just had a psychotic break, who knows. Or that's obviously Yeah. Also convenient. Yeah. Very convenient. But it's a possibility that she could be, should be considered.

(1h 44m 41s):
I mean, I this crooks kid that did this, that shot at the President. What, how, what happened? I wanna know what happened, Man, I, I don't, I I probably veer in the direction that there were You know on the, on the sort of conspiracy theory of history. I veer in the direction that There was a lot of crazy stuff like this that was going on in the US first half of the 20th century overdrive, 1940s You know the, I mean, you had the Manhattan Project There was this giant secret project 1950s, 1960s.

(1h 45m 25s):
And then, and then somehow the last 50 years, I think the, I'm not sure disturbing pers, but the perspective I have is these institutions are less functional. I, I don't think, I don't think the CIA's doing anything quite like MK Ultra anymore. Why Do you think that? I think you had the Church Commission hearings in the late seventies and, and somehow things, things got, things got exposed and, and then when, when things, when bureaucracy is forced to be formalized, it probably becomes a lot less functional.

(1h 46m 18s):
You know There was a, or like the two thousands version There was, I think There was a lot of crazy stuff that we did in black sites torturing people that the CIA ran and You know in the war on Terror, There was water boarding, There was all sorts of batshit crazy stuff that happened. But then You know, once John Yu in the Bush 43 administration writes the torture memos and sort of formalizes, this is how many times you can water dunk someone without it being torture, et cetera, et cetera. Once you formalize it, people somehow know that it's on its way out because You know it doesn't quite work anymore. And so by, I dunno, by 2007 at Guantanamo, I think the inmates were running the asylum, the inmates and the defense lawyers were running it.

(1h 47m 7s):
You were way safer as a Muslim terrorist in Guantanamo than as a, let's say, suspected cop killer in Manhattan. There was still an informal process in Manhattan. You were a suspected cop killer. They'd figure out some way to, to deal with you outside the judicial, the formal judicial process. And, but I think something There was sort of formalization that happened. There was the post j Edgar Hoover, FBI where Hoover was, I dunno, a law unto himself. It was completely out of control. CIA even more so. And then You know once it all gets exposed and it, it probably is a lot harder to do the NSA You know NSA probably held up longer as a deep state entity where it at least had the virtue people You know, I think the 1980s it was still referred to as no such agency.

(1h 48m 1s):
So it still, it was still far more obscure. So the necessary condition is that if some part of the deep state's doing it, You know we, we, we can barely know what's going on right with them. And then, I don't know, You know the, the two thousands, 2000 tens history of on the on, on You know, I think the Patriot Act empowered all these FSA courts and I think There was, I think there probably were ways the NSA FSA court process was, was weaponized in a really, really crazy way.

(1h 48m 42s):
And You know it culminated in, in 2016 with all the You know the crazy Russia conspiracy theories against Trump. But I I think even that, I I'm not sure they they can do anymore because it got exposed. Can't do that anymore. But A small program that is top secret, that is designed under the auspices of protecting American lives, extracting information from people. Well, I'm, I'm, I'm, I'm agreeing you. The, the, the fi the the, the NSA FISA court process, right? Is is one where you had a pretty out of control process from let's say circa, I dunno, 2003 to 2017, 2018.

(1h 49m 25s):
So that's relatively recent history. I don't know. You know. They're all the, all the Jeffrey Epstein conspiracy theories, which I'm probably too fascinated by because it felt like There was, There was some crazy stuff going on that they were able to cover up, but and still are. And then, but then it man doesn't it, the fact that we're, we're still talking about Jeffrey Epstein. Tell us how hard it's to come up with anything else. No, because there's no answers for the Jeffrey Epstein thing.

(1h 50m 7s):
There's been no consequences other than Ghislaine Maxwell going to jail and Jeffrey Epstein allegedly committing suicide, which I don't think he did. Other than that. What are the consequences? They, they, they were able to pull off this thing, this some, some sort of operation, what You know, who knows who was behind it, who knows what was the motivation. But it clearly has something to do with compromising people, which is an age old strategy for getting people to do what you want them to do. You have things on them, you use those things as leverage. And then next thing You know, you've got people saying things that you want them to say do, and, and it motivate moves, policy changes, things get things done that they did that Yes and no one, and we know they did that.

(1h 50m 50s):
And yet no one is asking for the tapes. No one's asking for the the client list. We, we are in the dark still. And probably, I don't know, man, I I, I spend too much time thinking about all, all the, all the Epstein variants. It pro probably, probably the sex stuff is overdone and everything else is underdone. It's like with, it's like a limited hangout. We get to talk about the crazy underage sex and, and You know not about all, all the other questions. It's like when Alex Acosta testified for labor secretary under, and he was, he was the DA who'd prosecuted Epstein in oh 8, 0 9 and got him sort of the very light 13 month or whatever sentence, and it was a South Florida DA or whatever he was.

(1h 51m 46s):
And, and Acosta was asked You know, You know. Why did, why did he get off so easily? And, and under congressional testimony when he was up for labor secretary 2017, it was, he belonged to intelligence. Right? That's, yeah. And then, and then, you know, and so it's, yeah, it's, it's, it, it, the question isn't about the sex with the underage women. The question is, is really about You know, why was he, why was he so protected? And then You know, I, I went, I, I went down all these rabbit holes. Was he You know working for the Israelis or the Mossad or all, all this sort of stuff.

(1h 52m 29s):
And I've come to think that that's, that was very secondary. It was o obviously it was just the US You know, You know if, if you're working for Israel, you don't get protected. You know we had Jonathan Pauler, he went to jail for 25 years or whatever. And, but unrelated, Right. Un understood. But it's, but it's, But this is one particular operation. But, but, but so it's, but it, it was, if, if it was an intelligence operation, the question we should be asking is what part of the US intelligence right system was, was he working for, was he working for You know? But Don't you think that's an effective strategy for controlling politicians, getting them involved in sex scandals? I mean, that's always been one of the, the worst things that can happen to a politician.

(1h 53m 12s):
Look at Monica Lewinsky, a very simple one. Consensual, inappropriate sexual relationship between a president and a staffer. And it almost takes down the presidency. It causes him to get impeached, powerful motivators. The shame of it all. Also the illegal activity, the fact that it's, I mean, it's one of the most disgusting things that we think of with people having sex with underaged people. I'm, I'm I'm, I'm sure that was part of it. I suspect there are a lot of other questions that You know. 1, 1, 1 should, one should also. So Most certainly. But I would think that that is one of the best motivators that we have, is having dirt on people like that.

(1h 53m 55s):
Especially something that could ruin your career. Especially people that are deeply embedded in this system of people knowing things about people and using those at their adv advance. I mean, that's an age old strategy in politics. That was j Edgar Hoover's entire modus operandi. Yeah. Look, look, my, my, my, my riff on it was always that it was, it was, it's, it's A little bit different from the j Edgar Hoover thing. And the question was always whether the people doing it knew they were getting compromised. And so it's, it's, it's, it's, it's, the vibe is not that you somehow got compromised. It was more you were joining this, this secret club.

(1h 54m 39s):
Right. And you got to be made. Yes. You were a, a made man in the mafia and you Got to do crazy Things and only No, no, no, no. It's only if we have comad on you. Mm. Do you get ahead. Right. It's like You know. It's like, I dunno know, it's one of these I column bones. The Yeah, the closet of the Vatican. Right. The claim is 80% of the cardinals in the Catholic church are gay. Right. Not sure if that's true, but directionally it's probably correct. And the, the basic thesis is you don't get promoted to a cardinal if you're straight, because we need to have, and so we need to, you need to be compromised and then you're under control, but you also get ahead Completely Makes sense. Completely makes sense in the way to do that with especially all these politicians who are essentially like bad actors.

(1h 55m 25s):
A lot of them, they're just people that want power and people that want control a lot of them. And you know, those kind of guys, they wanna party. you know, I mean, that has been, you've got two types of leaders that are presidents. You've got pussy hounds and war mongers, You know, and you know, some of, sometimes you have both, but generally you don't. You know guys like Clinton and JFK were anti-war. And then you have guys like Bush who you don't think of at all as a pussy hound, but most certainly you think of as a warmonger. Hmm. Hmm. Do you, what, what, what do you, do you have a theory on, what was Bill Gates' complicity with Epstein? I think He likes pussy. I think, I think he's a man. I think he likes power.

(1h 56m 5s):
He likes Monopoly. I mean, he's incredibly effective with Microsoft. And for the longest time he was thought of as a villain, right? He was this antitrust villain. He was this guy who was monopolizing this operating system and, and, and controlling just this incredible empire. And he had a real bad rap. And then I think he wisely turned towards philanthropy and do, but do, Do you, do you think, do you think, do you think that he needed Epstein? I think it's very difficult. Very, a very famous, very high profile person to fuck around. I think it's very difficult. I think you have to worry about people telling people You worry about it taking you down.

(1h 56m 45s):
If you're having affairs, if you're running some Phil philanthropy organization, you're supposed to be thought of as this guy who's like this wonderful person who's trying to really fix all the problems in the world. But really you just flying around and, and banging all these different checks, you have to figure out a way to pull that off. And this is what Eric Weinstein and I, we've had discussions about this and Eric's position is that there are people in this world that can provide experiences for you and safely for people that are in that kind of a group. And that makes sense. It makes sense that if you pay people enough and you have people motivated in order to like establish these relationships and make sure that these things happen when you get very high profile, you can't just be on a fucking dating app.

(1h 57m 30s):
And if you're a guy that likes to bang chicks What, are you gonna do i The all of that might be true, but I I I wonder if there are more straightforward alternate conspiracy theories on Epstein that we're missing. So let me do, let me do alternate one on for Bill Gates where the You know the things, just, just looking at what's hiding in plain sight. You know, he supposedly talked to Epstein early on about how his marriage wasn't doing that well. And then Epstein suggested that he should get a divorce circuit 2010. 2011. And Gates told him something like, You know that doesn't quite work.

(1h 58m 17s):
He didn't have pre, presumably because he didn't have a prenup. So, so there's one part of Epstein as a marriage counselor, which is sort of disturbing. But then the second thing that we know that, that Gates talked to, to Epstein about was sort of You know all this sort of collaborating on funding, setting up this philanthropy, all this sort of, this somewhat corrupt left-wing philanthropy structures. And so there's a question You know does, and then, and then my, my sort of straightforward alternate conspiracy theory is should we ask, should we ask, should we combine those two?

(1h 59m 2s):
And was There was there You know and I, I, I don't have all the details on this figured out, but It would be something like, You know Bill and Melinda get married in 1994. They don't sign a prenup and You know something's going wrong with the marriage. And may maybe Melinda can get half the money in a, in a divorce. He doesn't want her to get half the money. What do you do? And, and then the alternate plan is something like you set up, you set up, you commit the marital assets to this nonprofit and, and then it, it sort of locks Melinda into not complaining about the marriage for a long, long time.

(1h 59m 50s):
Mm. And it's, and it's, it's some kind of a, and and so there's something about the left winging philanthropy world that was, it was sort of some sort of boomer way to control their crazy wives or something like this. And That'ss, it's also way Wash your, you know, your past, right? Your thought. Sure. There are all these, and he talked, he talked to Epstein about, he got Epstein to meet with the, the head of the Nobel Prize Foundation. So it was Yeah. Bill Gates wanted to get a Nobel Nobel prize. Wow. Right. So these, this is all, this is all, yeah. This is all straightforward. This is all known.

(2h 0m 31s):
Yeah. And, and, and I'm not saying what you're saying about do You Know the history of the Nobel Prize? That's the ultimate whitewash. Sure. It wasting dynamite. Yeah. That's the, the, he was, he, well, Peter Berg told me the story. I was blown away. He originally, they act, someone said that he died and it was printed that he died, but he didn't die. And in the stories, they were calling him the merchant of death. 'cause he was the guy that invented dynamite. And he realized that, oh my God, this is my reputation. This is how think people think about me. I have to do something to turn this around. So he invented the Nobel Prize and he started then now the, the name Nobel is automatically connected in most people's eyes to the, the greatest people amongst us.

(2h 1m 15s):
The people that have contributed the most to society and science and art and peace and all these different things. Nobel Prize for Medicine Award do the guy who invented, By the way. Yeah. It's super, super crazy history. Yeah, yeah, Yeah. It's a crazy history. But it's the ultimate whitewash. It's the same thing. Like he came up with that prize because he wanted to change his image publicly. And so it's Ironic that Bill Gates would want to get a Nobel Prize Or not. Ironic or Yeah, it's ironic. It's straightforward, understandable, and ironic. Yeah. But, but I think but then if we, if we, if and so there's yeah, so there's, there's a underage sex version of the Epstein story, and then there is a crazy status Nobel Prize history of it.

(2h 2m 1s):
And there is a corrupt left-wing philanthropy one. Yeah. And there is a boomers who didn't sign prenuptial agreements with their, their wives story. Right. And, and, and I think all those are worth exploring war. I Think you're right. What is, that's all I'm saying. What about the, these left wing philanthropy ventures do you think is uniquely corrupt? I Sorry, which one do I think is most corrupt? Or no? What What about them? These, when, when you said corrupt?

(2h 2m 43s):
Yeah. Yeah. Well, man, it's, it's, there's something about, Maybe it's just my hermeneutic of suspicion. Mm. But there's something about You know, there's something about the virtue signaling and what does it mean? and I always think this is sort of a Europe, America versus Europe difference. Where in America we're told that that philanthropy is something a good person does.

(2h 3m 23s):
And You know if, if you're a Rockefeller or, and you start giving away all your money, this is just, this is just what a good person does, and it shows how good you are. And then I think sort of the European intuition on it is something like You know, wow, this, it's only something a very evil person does. And if you, if, if you start giving away all your money in Europe, it's like, Joe, you must have murdered somebody or you must, you must be covering up for something. And so there are these two very different intuitions and I think, I think the European one is more correct than the American one. Mm. And probably there's some history where You know the sort of left winging philanthropy peaked in 2007, 2010, 2012.

(2h 4m 14s):
And there's these subtle ways, you know, we've, we've become, you know, we've become more You know, more, more European in our sensibilities as a society. And so it has this very different valence from what it did 12 or 14 years ago. But it, yeah, it's all, we, we ask all these questions like we're asking right now about Bill Gates, where it's like, okay, he was You know, it was like all the testimony in the Microsoft antitrust trial in the nineties. Like, he's cutting off the air supply. Right. He wants to strangle people. And he's like, not, he's kinda a sociopathic guy it seems. And then it's, it's, it's this giant whitewashing operation. And, and then somehow the whitewashing has been made too transparent and it gets deconstructed and exposed by You know the internet or whatever.

(2h 5m 3s):
But I think most people are still unaware of how much whitewashing actually took place, including donating somewhere in the neighborhood of 300 plus million dollars to media corporations essentially buying favorable reviews about him. And then there's this very public philanthropy. It's not just philanthropy, it's philanthropy mixed with public ations. 'cause public ation relations, because he's constantly doing interviews about it. It's just not like a guy who is just silently donating is incredible wealth to all these causes. He's advocating for it on various talk shows. He's constantly talking about it and how we need to do things. I mean, during the pandemic, he was a very vocal voice.

(2h 5m 43s):
He was the guy telling us he was a, somehow or another, he became a public health expert. And no one questioned why We were taking public health advice from someone who has a financial interest in this one very particular remedy. Yeah. Or Oh. yeah. Yeah. There are all these alternate versions I can give. But yeah, I, I, I think, I think it's so, it's always so hard to know what's really going on in our culture though. So I, I think, I think all what you say is true, but I also think it's not working as well as it used to. I agree. And there is a way people see through this.

(2h 6m 24s):
It's not always as articulate as you just articulated it, but there's, there's some, there's some vague intuition that You know, You know when Mr. Gates is just wearing sweaters and looks like Mr. Rogers, that something fishy is going on. Right. People, people have that sort of Intuition trust Jeff Bezos and his tight shirt hanging out with his girlfriend on a yacht more, Or, or Elon Elon Musk. Yeah. The, the vice signaling is safer than virtue signaling. Yeah, yeah. Right. Because if you're You know, if you virtue signaling our intuition is something really, really, really sketchy, suspicious, We get suspicious and I think rightly so.

(2h 7m 5s):
I think especially when someone's doing something so public, I think rightly we should be suspicious. Especially when, I mean with, with Gates, it's like, you know, the history of the guy. I mean, you know, what he was involved with before You know how he ran Microsoft. you know, it just kind of makes sense that it's a clever move, it's a clever move to pay the media. It's a clever move. But, but again, my, my my, my alternate one, which is not incompatible with yours on, on on Gates, is that Melinda finally files for divorce in early 21. I think she told Bill she wanted to one late 2019. So 2020 the year where he Bill Gates goes into overdrive on COI, you know, all this stuff.

(2h 7m 51s):
You know, part part of it, maybe it's self-dealing and he's trying to make money from the drug company or something like this. But You know isn't, isn't the other really big thing. He needs to box Melinda in and force her not to get that much out because all the money's going to the foundation anyway. Melinda has to say, You know I want, why do you want half the money? It's all going to the Gates Foundation anyway. Right. We're not leaving our kids anything. And, and then when you lean into Covid, You know, how does that work in the, you know, it's somehow in theory, Melinda has a really strong hand, she should get half.

(2h 8m 33s):
That's what you get in a divorce with no prenuptial. But then if you make it go overdrive on Covid, Melinda, are you a You know? Are you a, I don't know, a are You like some crazy anti-science person? Right. And, and so, so I dunno, my, my, my my my, my reconstruction is that you should not underestimate how much of it was You know about just controlling his ex-wife and, and not about controlling the whole society. Makes sense. It makes sense that you would be extreme, But they can, they can both be True, extremely motivated. They Can both be, they can both be correct. Sure. There, there's many factors.

(2h 9m 13s):
But mine, mine lines up really well with the, with the timeline. Well, we're probably talking about a hundred million dollars or a hundred billion dollars one way or the other. Well, I think she got, she got less than, she got like one 10th. Really interesting. And She should have gotten half as far as, and, and I, it's amazing. He got it down that Much. Wow. Interesting. But it Was just, I, I think she was just boxed in every time he went on TV talking about Covid, she was boxed in with all of her left wing friends. That Is an interesting philosophy. That's an interesting way to approach a problem if you're him very wise, You know, very clever. I mean, if you're just looking at like, just for personal benefit, the genius move and the guy's a genius, clearly brilliant guy, You know, I mean that makes sense.

(2h 10m 0s):
Makes sense that he would do that. I don't Know. You know I Would do that. Probably should have had a prenup, but Yeah. Yeah. Well that's kind of crazy. That's interesting that, yeah, I didn't consider that, but it makes sense. And she's You know, she's been kind of pretty vocal, unfortunately for him, about his ties to Epstein being one of the primary reasons why she wanted out. But again, my ult again, it's what did he, what was he, was he, was he having extramarital affairs through Epstein or maybe Epstein was, from Melinda's point of view, would it be worse for Epstein to facilitate an extramarital affair or would it be worse for Epstein to be advising Gates on how to, how to ditch Melinda without giving her any money?

(2h 10m 44s):
What do you think he was legit? I think that would be much, much worse from Melinda's point of view. Yeah, Makes sense. It totally makes sense. Do you think that he was a legitimate financial advisor? Like he could give him advice on how to do those things that Gates wouldn't have more effective people? I mean he's, when you're at that level of wealth, I'm sure you have wealth management people that are like very high level, because that's one of the things that Eric said about him. He said when he met him, he was like, this guy's a fraud like this. He doesn't know enough about what he's talking about. And you know, Eric is, You know, IIII met Epstein a a few times as well and I think, How'd you get introduced?

(2h 11m 28s):
It was, it was Reid Hoffman in Silicon Valley introduced us in 2014. But, but it was, it was basically, and I, I I You know, didn't, didn't check, didn't ask any enough questions about it. But I, yeah, I, I I think there were, were sort of a lot of things where it was, was fraudulent. I do think Epstein knew a lot about taxes and, and there were probably You know these, these complicated ways you could, you could structure a nonprofit organization, especially as a way in a, in a, in a marital con context that, that I I think Epstein might have might've known a decent amount about How, when you were introduced to him.

(2h 12m 20s):
Yeah. I don't, I don't think Epstein would've been able to You know, comment on super string theory Right. Or something like that. Right. But, but I think, I think this sort of thing, he, he might have actually been pretty expert on When you were introduced to him, what, how was he described to you? He was described as one of the smartest tax people in the world. Interesting. And, and I, I probably, it probably was my moral weakness that I well Pay taxes. Well, how could You know him back then? He had never been arrested? No, this was, this was post, this was 2014. It was post-arrest. Oh, so his arrest was the first arrest, right? Yeah. Which was like 2000 Oh 7 0 8. Okay. Okay. And so, But You know you, you assume it didn't go to jail for that long.

(2h 13m 4s):
It, right. It was probably not, not as serious as alleged. There was. There was certainly was the illusion that there were all these, these other people that I trusted, you know? Mm. You know Reed who introduced us was, you know, he started LinkedIn. He was, you know, maybe too focused on business networking, but Right. But, but I thought he always had good judgment in people When the shit went down and Epstein gets arrested for the second time, were You like, oh, well there you go. I've thought about it. I've thought a lot about it as a result. Yeah. Yeah. I'm sure Jesus Christ. Well, he tricked a lot of people. I know a lot of people that met that guy.

(2h 13m 45s):
He got a lot of celebrities to come to his house for parties and things. Well, I think, I think it was, it's, it was, it's a, I think a lot of it was, this was this strange commentary on You know, I dunno, There was something Secret Club, secret Society you could be part of. Right. Of course. Again, that wasn't, it wasn't explicit, but that was, it was the vague, vague vibe of the whole thing. People Love those stupid things. They love like exclusive clubs that very few people look at the fucking Soho house. Like look at that stupid thing. I mean, you just go to a place that you have to be a member to go to and everybody wants to be a member. Oh my God. And then you got like the Malibu Soho House. It's different from the other ones. You have to have membership only there.

(2h 14m 25s):
Do you have membership to there? People love that kind of shit socially. They love being a part of a walled garden. They love it. They love it. And if you're a guy like Bill Gates or, or, or similarly wealthy, you probably have a very small amount of people that you can relate to. Very small amount of people that you can trust. Probably very difficult to form new friendships. Yeah. I I I think, I think there were probably different, different things that were pitched for different people. Sure. you know, I, I was, I was pitched on the taxes. I think You know there were probably other people that were, you know, more, more prone to the You know the Social Club Park Deery. Yeah. And then there were probably people. Yeah.

(2h 15m 5s):
And There was probably a fairly limited group where it was Yeah. Off, off the charts. Bad stuff. Wouldn't It be wonderful to know what the fuck was really going on? And maybe one day we will, maybe one day some Whitney Webb type character, we'll break it all down to us and explain to us in great detail exactly how this was formulated and what they were doing and how they were getting information outta people. But I think people have to age out. They have to, they have to die Before. And we said we still don't have it on the Kennedy assassination. JFK. That's crazy. Well, one of the wildest things that Trump said was that if they told you what they told me, you wouldn't tell people either, which is like, what the fuck does that mean? What does that mean? I don't think legally he can tell you.

(2h 15m 48s):
Right. Because I think those things are above top secret. If, if they did inform him of something, there must be some sort of prerequisite to keeping this a secret. I I, I haven't studied that one that carefully. But isn't You know there, there are all these alternate conspiracy theories on who killed JFK. It's, you know, the CIA and the Mafia and the Russians and the Cubans and You know there's an LBJ version since he's the one who benefited. So there all these happened in Texas, you have all these You know alternate theories. And on some level it's, it's, it's, yeah, it's, it's, it's, I always think it's just a commentary where You know 1963 America was, it wasn't like Leave it to Beaver.

(2h 16m 35s):
It was, it was like a really crazy country underneath the surface. And Absolutely. And even though probably most of the conspiracy theories are wrong, it was like murder on the OR and Express and all these people sort of had different reasons for wanting Kennedy dead. And that's, that's what the theories are. Right. Even if they're wrong on the level of factual detail. And then the, the, the, the sort of more minimal one that I am, I'm open to and I think there's some evidence in this from, from the stuff that has been, that has come out is You know Oswald was talking to You know parts of the US deep state. And so even if Oswald was the lone assassin and he somehow got the magic bullet theory and all that stuff to work, but let's say Oswald was the lone assassin.

(2h 17m 22s):
Did, did he, did he tell someone in the FBI or CIA You know I'm gonna, I'm gonna go kill Kennedy tomorrow. And then, you know, maybe, maybe the CI didn't have to kill him. They just didn't had to do nothing, just had to sit on it. Or, or maybe it was too incompetent and didn't get You know, didn't go up the bureaucracy. And so it's, you know, I I think we sort of know that they, they talked to Oswald, you know, a fair amount before, before it happened. And, and so there's at least something You know that was grossly incompetent about I people have a problem At a very minimum With, with two stories being mu mutually exclusive.

(2h 18m 4s):
Two stories being the lone gunman or the CIA killed Kennedy. And that they, these, they're not connected. I think Lee Harvey Oswald was a part of it. I think, I think he probably did shoot that cop. There's some evidence that, you know, when when he was on the run and he was confronted You know There was a cop that, that got shot and they were alleging. He, he, he might have done it. He might have taken a shot at Kennedy. He might have even hit him. I don't think he was the only one shooting. I I think the, the vast the, the There was an enormous amount of people that heard sounds coming from the grassy knoll. They heard gunfire, they reportedly saw people. The amount of people that were witnesses to the Kennedy assassination that died mysterious deaths is pretty shocking.

(2h 18m 47s):
So Jack Ruby, Well, Jack Ruby, just, that's a weird one, right? Oswald. Yeah. Jack Ruby walks up to Oswald shoots him, and then Jack Ruby with no previous history of mental illness becomes completely insane after getting visited by Charlie West. Yep. Which is nuts. Like why is the guy who's the head of MK Ultra visiting the guy who shot the assassin of the president and why is he left alone with them? What is, what happens, what does he give him that this guy is screaming out there, burning Jews alive and just crazy, crazy shit. He was yelling out, he went nuts. Probably some, some amount of LSD that's, that's Dangerous for you. Probably an enormous amount. Dangerous you fucking glass of it. They probably gave him a glass of it and and told him it was water.

(2h 19m 28s):
Drink this and who fucking knows. But the point is, I think, I think it's very possible that Oswald was a part of it and the way they did it and the way they just shot Oswald and, and then they write the Warren Commission. We don't even see the Zapruder film until 12 years later when you Geraldo Rivera, when they play it on television. When Dick Gregory brought it to Geraldo Rivera, which is wild. A comedian brings the video, the, the the actual film rather of the assassination from a different angle. Well, you can actually see the video of him getting shot and it was his head snaps back into the left and everybody's like, what the fuck is going on here?

(2h 20m 12s):
When you look at all that stuff, this mirrors what happened with this crooks kid. This crooks kid, somehow or another gets to the top of the roof, is spotted by these people. They know he's there, they know he has a rifle. They see him walking around the crime scene half an hour before with a range finder. The the whole thing is bananas. And then they go to his house after he is killed. It's completely scrubbed. There's no silverware there. They know that. There's ad data that shows that a phone that's coming from the FBI offices in DC had visited him on multiple occasions. 'cause they tracked ad data.

(2h 20m 51s):
There's, and if that guy, if he shot Trump and Trump got murdered and then they shot him, It would be the Kennedy assassination all over again. Everybody would go, what the fuck happened? What happened? What was the motivation? What was he on any drugs? What's the toxicology report? How did he get up there? Who knew he was up there? How did, how did they not shoot him quicker? Like, what the fuck happened? How was he able to get off three shots? What happened? And I think, I think there's like a slightly less crazy version that might still be true, which is just that people in the secret service in the Biden administration don't like Trump. And it's, they didn't have full intention to kill him, but it's just, you know, they didn't protect him.

(2h 21m 35s):
We're just, we're just, you know, we're gonna have, we're gonna understaff it. We're we're not going to, we don't have to do as good a job coordinating with the local police. There's all these ways, you know, to make Someone less safe. You know. Yeah. But It seems more than that. If they, if they knew that the guy was on the roof with a rifle that seems a little more than that. It's Always a question who they is though. Right. Well, if I'm a sniper and I'm on the, And people, people in the audience, people, there were people there telling, telling it to people. Right. But I think the authorities knew this guy was on the roof before as well. Well, I, I, I, I suspect some of the Secret service people were were told that. And then who knows how that got relayed or who all, Who all is sniped?

(2h 22m 20s):
Well, did the snipers already have eye on him? I believe the snipers already had eye on him. I Don't, I don't know. I if that's true. True. Jamie, find up the snipers had eye on crooks Secret service that I don't know about the snipers. I, IIII don't, I don't know about the, the thing I don't have a good sense on with You know, with, with, with shooting. And maybe, maybe you'd have a better feel for this is my, my sense is, was a pretty straightforward shot for, for the guy in the Trump assassin would be assassin. I think the Oswald shot was a much harder one because Kennedy's moving. Yes and no. Yes and no. Okay. Because Oswald had a scope. So Oswald had a rifle, the Markano rifle, let's say one of the snipers stationed inside the building reported he first saw crooks outside and looking up to the roof of the building before the suspect left the scene.

(2h 23m 9s):
Crooks later came back and sat down while looking at his phone near the building. CBS news reported that a sniper took a photo of the suspect when he returned. But I think they saw him on the roof though. Crooks then took out a range finder, like right then. Arrest that guy. You got a fucking range finder about the suspect's action. Crooks then disappeared again and returned to the building with a backpack again, arrest him. Secret Service snipers again alerted their command post about crooks actions. According to the source who spoke with CBS news, crooks had already climbed to the top of the building in question. By the time the additional officers arrived at the scene for backup, the suspect also positioned himself above and behind the snipers inside the building.

(2h 23m 50s):
By the time the police started rushing the scene and other officers attempted to get onto the roof, the source told CBS news that a different secret service sniper had killed crooks. Okay. So it seems like they, they fucking bumbled it at every step of the way. If they knew that guy was there. If they knew he had arranged find or returns to the backpack, he gets onto the roof. All that's insane. That is at the very least horrific incompetence at the very least. Let, lemme Go back. Yeah. Okay. But back, back to Mike. Was it, I I thought it was a much easier shot for, it's Not an easy headshot. He's shooting at his head. But why, why, why, why was shooting at the head the right thing? Shouldn't he be shooting at Well, You don't love if he's wearing a vest. Right.

(2h 24m 30s):
He could Be wearing a vest, which you would have to have plates, you'd have to have ceramic plates in order to stop a, a a a rifle round. So was was it a 3 0 8? What, what did he have? What kind of rifle did he have? I've never seen that. I think he had an AR 15. So, And are, are the scopes a lot better today than He didn't have a scope? We're pretty sure he Have scope. How good was scope? How good was o Oswald's scope? It was good. They, they said it was off. This was one of the, the conspiracy theories. The, oh, the scope was off. But that doesn't mean anything. 'cause scopes can get off when you pick it up. if you knock it against the wall when he drops it. If he makes the shot and then drops the scope and the scope hits the windowsill and then bounces off.

(2h 25m 10s):
That's, excuse me, ed scopes off anytime you knock A is There was there anything about the high angle from Oswald that made it harder? No, not a difficult shot. Very difficult to get off three shots very quickly. So that was the thing that they had attributed three shots to Oswald. The reason why they had attributed three shots is 'cause one of them had hit a ricochet. One of 'em had gone into the underpass, ricocheted off the curb and hit a man who was treated at a hospital. They found that, they found out where it hit the bullet had hit. So they knew that one bullet, Ms. Kennedy hit that curb, which would have indicated that someone shot from a similar position as, as Lee Harvey Oswald. So then they had the one wound that Kennedy had to the head of course.

(2h 25m 50s):
And then they had another wound that Kennedy had through his neck. That's The magic bullet theory. Right. This is why they had to come up with the magic bullet theory. 'cause they had to tribute all these wounds to one bullet. And then they find this pristine bullet. They find it in the gurney when they're bringing Governor Connolly in nonsense. It's total nonsense. The bullet is unformed a bullet that goes through two people and leaves more fragments of the bullet in Connolly's wrists that are missing from the bullet itself. And then the bullet's not deformed after shattering bone. All that's crazy. All that defies logic. That doesn't make any sense If You know anything about bullets and if you shoot bullets into things they distort.

(2h 26m 32s):
It's just one of the things that happen, that bullet looks like someone shot it into a swimming pool. That's what it looks like. When they would do ballistics on, on bullets and they try to figure out like it was this guy's gun or that guy's gun by the rifling of the round. They can get similar markings on bullets when they do that. That's how they do it. They do it so the bullet doesn't distort. So they shoot that bullet into water or something like that. Now that bullet was metal jacketed. Right? if you look at the bullet, the top of it is fucked up and, but the, the shape of the bullet looks pretty perfect. It doesn't look like something that's shattered bones. And then you have to attribute, you have to account rather for the amount of per, there's little fragments of the bullet that you could see that they found in Connolly's wrist.

(2h 27m 17s):
The whole thing's nuts. The whole thing's nuts that you're only saying that this one guy did it because that's convenient. And the Warren Commission's report and I, the Warren Commission whitewashed, it's nuts. Everything. So The whole thing's nuts. It's much more likely that there were people in the grassy knoll and then Osmo was also The umbrella says the pointers or Whatever. Pro I mean, I don't know. I don't know about what, all I know is you got a guy in a convertible, which is fucking crazy, who is the president of the United States and he's going slowly down a road. Now, if you are in a prone position, so Oswald is on the window sill, right? Which is a great place to shoot, by the way. It's a great place to shoot. 'cause you rest that gun on the window sill. And if you've rested on the window sill, there's no movement, right?

(2h 27m 58s):
So you wrap your arm around the sling. If it had a sling, I'm not sure if it did. So you get a nice tight grip, you shove it up against your shoulder, you rest it on the window sill and all you have to do is you have a round already racked all and you have a scope. And so the scope's magnified. All you have to do is wait until he's there. You lead him just A little bit and squeeze one off and then boom, boom. You could do that pretty quick. It's not outside of the realm of possibility that he did get off three shots. What doesn't make sense is the back and to the left. It doesn't make sense that all these other people saw people shooting from the grassy knoll. There's all these people that saw people running away.

(2h 28m 39s):
They saw smoke. There's smoke in some photographs of it. It looks like There was more than one shooter. And it looks like they tried to, they tried to hide that. They tried to hide that in the warrant commission report. The shot to Kennedy's neck initially was in, when they brought him in in Dallas, when he was, before they shipped him to Bethesda. They said that that was an entry wound when he got to Bethesda, then it became a tracheotomy. Hmm. Why do you give a tracheotomy to a guy who doesn't have a head? Hmm. You don't. I mean that's just, none of it makes any sense. They altered the autopsy. This is a part of David Lifton's book. Best Evidence Kennedy's brain wasn't even in his body when they buried him. Like the, the, the whole thing is very strange.

(2h 29m 21s):
But then Do do, do you get to anything more concrete than my murder on the Orient Express where they're just You know it. Could have been a lot of people, it Could have been Russians of the Cubans. The, well, No one even got suspicious for 12 years. Oh, I think people were su sure a lot of people were Suspicious kind of. But what do you have to go on? You don't have to go on anything like this crooks kid. We don't have anything to go on. We're just gonna be left out here. Just like we're left out here with the, the Epstein information. No one knows the people are that whoever organized it, if anyone did, you're never gonna hear about it. It's just gonna go away. The news cycle's just gonna keep flooded with more nonsense. And, and I think there's probably a bunch of people that wanted Kennedy dead.

(2h 30m 2s):
I think There was more than one group of people that wanted Kennedy dead. I think there's probably collusion between groups that wanted Kennedy dead and I think there's a lot of people that have vested interest in ending his presidency and I think he was dangerous. He was dangerous to a lot of the powers that be, he was dangerous. His, his famous speech about secret societies crazy speech. The guy has this speech and then gets murdered right afterwards. Kind of nuts. Like the whole thing's nuts. He wanted to get rid of the CIA he wanted to, I mean, There was so many things that Kennedy wanted to do. Do, There were also a lot of crazy things Kennedy was doing. Yes. you know, so, you know, oh, for sure. The, the, the, the Cuba version of the assassination theory was, you know, we had the Cuban Missile Crisis in 62 about a year earlier.

(2h 30m 43s):
And then the deal that we struck with the Soviets was You know they take the missiles out of Cuba and we promised we wouldn't, we wouldn't try to overthrow the government in Cuba and, and I guess we You know. We no longer did You know we no longer did Bay of Pigs type covert stuff like that. But I think there were still something like four or five assassination plots on Fidel Yeah. Attempts, actual Attempts. And then I think There was, I dunno, I think there again, I'm gonna get this garbled, I think a month or two before the JFK assassination, it, Castro said something like, You know there might be re repercussions if you keep doing this.

(2h 31m 26s):
Yeah. Well listen, I'm sure there's a lot of people that wanted that guy dead. And I'm sure they would coordinate. I mean, if you knew that Cuba wanted Kennedy dead and you knew that Cuba can get you assassins or that they could help in, in any way You know, I'm sure they would want as many people that knew for a fact they wanted him dead and had communicated that, I mean, back then they were doing wild shit, man. I mean this is when they were doing Operation Northwoods You Know. But this is again, where I think, I think, I think it's is I, I don't think we're in a world where zero stuff is happening. Right. I I still, I still, the place where I directionally have a different feel for it is, I think so much less of this stuff is going on.

(2h 32m 8s):
And it's, it's so much harder in this internet world for people to hide with Whistleblowers As well. And there are legacy programs and there are internal records that are being kept and You know, like I I I, I don't know this for sure, but I, I think even the NSA FSA court stuff, which was an out of control deep state thing that was going on through about 20 16, 20 17, I suspect even that at this point, you know, can't quite work because people know that they're being watched. They know they're being recorded. Mm. And it's, it's just, you know, You know you can't do water boarding in Guantanamo if you have lawyers running all over the place.

(2h 32m 49s):
and I hope You're correct. And that's, I hope you're correct, but it brings me back to this whole idea of getting dirt On. But then, then I think, I think there's, and then on the other hand, I, I think there's also You know, a a degree to which our government, our our deep state across the board is shockingly less competent, less functional, and it's less capable of this. And this is, this is where I'm not even sure whether this is an improvement You know. Right. Right. So it's, it's sort of like You know, maybe the 1963 us where, let's go with the craziest version where our deep state is capable of knocking off the president.

(2h 33m 34s):
Maybe that's actually a higher functioning society than, than the, than the crazy version where they're they're incapable of doing it. Right. And they're bogged down with DEI. They, they can't, they, they can't, they can't get the gunman even to have a scope on his rifle or whatever. Yeah. I don't, we don't, we haven't really totally Figured out it's if he a scope On his rifle, but I don't believe he did. Man. It's like, it's like much bigger loser. They can't even find someone as competent as Oswald. Right. Or something like that, you know? Yeah, That's a good point. It's a good point. And So I I I, I, I'm, I, I veer more to the explanation that it's, it's gross incompetence, but I, I don't know if that makes it better.

(2h 34m 16s):
it might make it worse. I I think they weren't as competent. Right. Because they only had one guy doing it and he wasn't effective. if you had the same, if, if you had much better organization, you wouldn't have it just one guy. I mean, there's people out there that I know that can kill someone from a mile away, but it, It, it's, it's very effectively. But it's, you, you can, you can do things as a solo actor, it's, it's hard to organize because everything gets recorded. Everything does get recorded. That is a fact. But it brings me back to that thing about having dirt on people that you were talking about with why the Epstein information doesn't get released and why they probably did it in the first place. They did it in the first place. And You know what if you have dirt on people, then You know those people are not gonna tell on you.

(2h 34m 57s):
And there's, you all coordinate Together. Look, and that's, that is, that is still a, that is still a strange counterpoint to my thesis where why is the dirt not come out? Yeah. And so somehow there's some, some way the container is still kind of working. Yeah, It's kind of working. It's just everyone is aware that it's working and then they're frustrated that nothing happens. You know, like Jillian Assange being arrested and, and spending so much time locked up in the embassy, like finally recently released. But didn't he have to delete like a bunch of emails in order to be released? But You know the, you know, in the, in the, but again, just just to take the other side of this, both in the Assange Snowden stuff. Yeah. It showed an out of control deep state that was just hoovering up all the data in the world.

(2h 35m 41s):
Right. And then, but we weren't, like, it didn't show like James Bond times a hundred. There were weren't like exploding cigar assassination plot There was none of, we're doing so little with this. Is, is, is. Well it seems like they don't have to do that. Or at least that's the, but You know, it's, I I think it's, there's so much less agency in the ccia in the central intelligence agency. It's so much less agentic. I hope you're right. Again, i I I don't know. That's don't If that's, I you're incorrect with how they deal with overseas stuff. I hope they're really good at that. You know, that brings me to this whole UAP thing because one of my primary theories about the UAP thing is it's stuff that we have.

(2h 36m 27s):
I think, I think that's a lot of what people are seeing. I think, I think there's secret programs that are beyond congressional oversight that have done some things with propulsion that's outside of our understanding. Our, our current, the conventional understanding that most people have about rockets and all these different things being the only way to propel things through the sky. I think they've figured out some other stuff. and I think they're drones and I think they have drones that can use some sort of, whether it's anti-gravity propulsion system or some You know. So do that's, that's your, that's your placeholder theory or that's, that's, that's what you think more than space aliens?

(2h 37m 8s):
Or do you think both space aliens and that or which, which version of this? The latter? Both. I Think both. You think both. Yeah. I don't, I don't think we haven't been visited. I think we have. I I think we, if if life exists elsewhere, and it most certainly should, it just makes sense. But Do you, do you, do you think, do you think the UFO sightings from the fifties and sixties were already drone programs? Were they already that Advanced? No, those are the ones that give pause. That's why You know when I named my comedy club, the comedy mothership is all u ffo themed. Our, our rooms are named Fat Man and little boy, our rooms are named after the nuclear bombs. Because those nuclear bombs, when they drop them, that's when everybody starts seeing these things. and I think if I was a sophisticated society from another planet and I recognized that there is an intelligent species that has developed nuclear power and started using it as bombs, I would immediately start visiting.

(2h 37m 59s):
and I would let them know, Hey, motherfuckers, like there's, there's something way more advanced than you. I would hover over the nuclear bases and shut down their missiles. I would do all the things that supposedly the UFOs did, just to keep the government in check. Just to say, Hey, you are going through a transitionary period that all intelligent species do when they have the ability to harness incredible power. And yet they still have these prime primate brains. They, they have these territorial ape brains, but yet now with the ability to literally harness the power of stars and drop them on cities, I think that's when I would start visiting and I think all throughout human history before that even, there's been very bizarre accounts of these things all the way back to Ezekiel in the Bible.

(2h 38m 46s):
Very bizarre accounts of these things that are flying through space. The Story of the Chariot. Yep. Yeah. There's, there's a bunch of them. There's the demonas and the ancient Hindu texts. There's, there's so many of these things that you gotta wonder and you gotta think that if we send drones to Mars and we do, we have a fucking rover running around on Mars right now collecting data. Do we send the James Webb telescope into space? Of course we do. We have a lot of stuff that we send into space. If we lived another million years without blowing ourselves up, which is just a blink of an eye in terms of the life of some of the planets in the universe, how, how much more advanced would we be? And if We were interstellar and if We were intergalactic travelers and we found out that There was a primitive species that was coming of age, I think we would start visiting them.

(2h 39m 32s):
You know the, let me think what my, I hear everything you're saying. I'm, I'm, I'm strangely unmotivated by it. Even if it's too, even if it's plausible. Me Too. Believe it or not, I'll And I guess, I guess on the space Aliens, which is the, the wilder more interesting one in a way. You know, I don't know, Roswell was 77 years ago, 1947. And if, if, if the phenomenon is real and it's, it's from another world, it's space aliens, space robots, what, whatever, You know, probably one of the key features is its ephemerality or it's cloaking.

(2h 40m 19s):
And they're really good at hiding it, at cloaking it at scrambling people's brains after they see them or, or stuff like this. Right. And then You know if, if you're a researcher, you, you, you have to pick fields where you can make progress. And so this is You know, it's not a promising field in You know, I know academia's messed up, but even if academia were not messed up, this would not be a, a good field in which to try to make a career because there's been so little progress in 77 years. And so, right. I see what You're saying. If, if you think of it from the point of view of, I dunno, Jacques Blay or You know some of these people ve been working on this for 50 years and yeah, it's, it, it feels like there's something there and, but then it's, it's just as soon as you, as soon as you feel like you have something almost that's graspable, like a TikTok videos, whatever, it just, it's, it's just always at the margin.

(2h 41m 17s):
Yes. Of recognition. It's the ephemerality is a, is a key feature. And, and then You know maybe you have to, then you have to, I I think you have to have some theory of, you know, why is this about to change? And then it's always, you know, I dunno, the the abstract mathematical formulation would be You know something doesn't happen for time interval. Zero to T and time interval T plus one next minute next year. How likely is it? And maybe, maybe there's a chance something will happen. You're waiting at the airport, your luggage hasn't shown up. It's more and more likely it shows up in the next minute. But after an hour, You know at some point the luggage is lost.

(2h 41m 59s):
And if you're still waiting at the airport a year later, that's a dumb idea. At some point, at some point the luggage is lost. Right. And like You know, it's, I don't know, 77 years. It's like, maybe it's like 77 minutes at the airport that's at, at 77 minutes. You should start, you know, I, I'd start getting very demotivated waiting for my luggage perhaps. Let me al give you an alternative alternative theory. Now, if you were a, a highly sophisticated society, they understood the progression of technology and understood the biological evolution that these animals were going through. And you realize that they had reached a level of intelligence that required them to be monitored or maybe even helped them along the way.

(2h 42m 41s):
And this is some of Diana Paco's work who works with, with Gary Nolan on these things. They, they claim that they have recovered these crashed vehicles that defy any conventional understanding of how to construct things, propulsion systems. And they believe that these things are donations. That's literally how they describe them as donations. if you knew that this is a long road, this is, you can't just show up and give people time machines. It's a long road for these people to develop the sophistication, the cultural advancement, the intellectual capacity to understand their place in the universe, and that they're not there yet and they're still engaging in lies and manipulation and propaganda.

(2h 43m 31s):
Their entire society is built on a ship of fools. if you looked at that, you would say, they're not ready. This is what we do. We slowly introduce ourselves slowly over time, make it more and more common. And that's what you're seeing. What you're seeing is when you have things like the TikTok, the Commander David Fravor incident off of the coast of San Diego in 2004. And then you have the, the stuff that they found off the East coast where they were seeing these, these cubes within a circle that were hovering motionless and 120 knot wins and taking off insane racist speed. And that they only discovered them in 2014 when they started upgrading the systems on these jets.

(2h 44m 15s):
Like what is all that? Like, what are those things? And if you, if you wanted to slowly integrate yourself into the consciousness, much like we're doing with, well, AI is quicker, right? But it's also a thing that's become commonplace. We think of it now, it's normal chat. GPT is a normal thing. Even though it's past the Turing test, we're not freaking out. You have to slowly integrate these sort of things in the human consciousness. You have to slowly introduce them to the zeitgeist and for it to not be some sort of a complete disruption of society where everything shuts down and we just wait for space daddy to come and rescue us. It has to become a thing where we slowly accept the fact that we are not alone.

(2h 44m 56s):
and I would think psychologically that would be the very best tactic to play on human beings as I know and understand them from being, from being one. I do not think that we would be able to handle just an immediate invasion of aliens. I think It would break down society in a way that would be catastrophic to everything, to all businesses, to all social ideas. Religion would fall apart, everything would be fucked. It would be pretty crazy. It would Be beyond crazy. It would be pretty crazy. It would be beyond fucked. And then although, Although you could say, you could say that's what chat GPT is, It could Be, it's like an alien intelligence. But I think that's what ultimately they are. But I think, let me man, there, there's so many, there's so many parts of it that I find puzzling or, or disturbing.

(2h 45m 48s):
Let me, let me run, go down one other rabbit hole along this with you, which is You know, I always wonder, and again this is A little bit too simplistic an argument, but I always wonder that I'm about to give, but what, what the alien civilization can be like. And if you have faster than like travel, if you have warp drive, which is probably what you really need to cover interstellar distances, You know what that means for military technology is that you can send weapons at warp speed and they will hit you before you see them coming.

(2h 46m 28s):
And there is no defense against a warp speed weapon. And you could sort of take over the whole universe before anybody could see, you could see, could see you could see, you could see you coming. And this is by, by the way, this is sort of a weird plot hole in Star Wars. Star Trek, where they can travel in hyperspace, but then you're You know flying in the canyon on Death Star. Well, they shoot so slow. You Can see the Bullets. Yeah. It's like, it's like you're, and then you're doing this theatrical Klingons versus Captain Kirk at 10 miles per hour. It's funny. 20 miles per hour or whatever. Right. It's funny when you put it that way, It's absurd. Plot hole. Yeah. And, and so it, it, it tells us that, I think that if you have, if you have faster than light travel, there's something really crazy that has to be true on a cultural, political, social level.

(2h 47m 26s):
And there may be other solutions, but I'll give you my two. One of one of them is that you need complete totalitarian controls. And it is like, it is the, the pe the individuals they might be, might not be perfect. They might be demons, doesn't matter. But you have, you have a demonic, totalitarian control of your society where it's like you have, you have like parapsychological mind meld with everybody and no one can act independently of anybody else. No one can ever launch a warp drive weapon.

(2h 48m 9s):
And everybody who has that ability isn't like a mind, mind meld link with everybody else or, or something, something like that. You can't have libertarian individualistic free agency. Right. And then I think the other, the other version socially and culturally is they have to be like perfectly altruistic, non-self interest. They have to be angels. And so the PCA literal thing I'd, I'd come to is the aliens. It's not that they might be demons or angels. They must be demons or angels if you have faster than light travel.

(2h 48m 50s):
And both of those seem pretty crazy to me. Well, they're Definitely pretty crazy, but so are human beings. Well, they're crazy in a very different way. Yeah. But not crazy in a different way. You compare us to a mouse, compare us to a mouse and what we're capable of. And then from us to them, not much of a leap. And here's my, here's my Question about it all, but it, but it is, but it, it is a very big leap on a You know if, if we, if we say that something like evolution says that there's no such thing as a purely altruistic being. Right? If, if you were purely altruistic, if you only cared about other people, you don't survive. Well, no. But why would you necessarily think that they'd think that?

(2h 49m 31s):
Be? Because, because, because then you beings that are not perfectly altruistic are somewhat dangerous. Let Me, let me, and then You, and then, and then the danger level gets correlated to the level of technology. And if you have faster than light travel, it is infinitely dangerous. Let me address that. Even If the probabilities are very low, Here's my theory. I think that what human beings are, the, the fatal flaw that we have is that we're still animals and that we still have all these biological limitations and needs. So it's, and this is what leads to violence. This is what leads to jealousy, imitation. This is what leads to war.

(2h 50m 11s):
So leads to all these things. As AI becomes more and more powerful, we will integrate. Once we integrate with ai, if we do it like now, and then we look at a thousand, we scale it up exponentially a thousand years from now, whatever it's gonna be, we will have no need for any of these biological features that have motivated us to get to the point we're creating ai, all the things that are wrong in society, whether it's inequity, theft, violence, pollution, all these things are essentially poor allocation of resources combined with human instincts that are ancient.

(2h 50m 51s):
We have ancient tribal primate instincts. And all of these things lead us to believe that this is the only way to achieve dominance and control allocation of resources, the creation of technology. New technology eventually reaches a point where it becomes far more intelligent than us. And we have two choices. Either we integrate or it becomes independent and it has no need for us anymore. And then that becomes a superior life form in the universe. And then that life form seeks out other life forms to do the same process and create it just like it exists. And it can travel.

(2h 51m 31s):
Biological life might not be what we're experiencing. These things might be a form of intelligence that is artificial, that has progressed to an, an infinite point where things that are unimaginable us to, to us today in terms of propulsion and travel. And to them it's commonplace and normal. I I Know that, that you're, you're trying to be reassuring, but I, I just, I find that monologue super non-res reassuring. It's not reassuring to me. There's, there's so many steps in it, and every single step has to work just the way you described. Not necessarily, it just has to, to one has to work one sentient artificial intelligence. That's it. And we're on the track to that 100%. But it Has, it ha it, it, it has, it has to, it has to be almost otherworldly in, it's in it's non selfishness and it's non humanness.

(2h 52m 22s):
But what is selfishness though? What is all that stuff stuff? But I I, but all that stuff is attached to us. It's all attached to biological limitations. Yeah. But It's, I I don't, I don't think, I don't think it's, I don't think it's fundamentally about scarcity. Scarcity is what exists in nature. It's, it's fundamentally about cultural positional goods within society. It's, it's a scarcity that's created culturally. It's also status. Are you familiar with this nineties spoof movie on a Star Trek called Galaxy Quest? Yeah, I remember that movie. So this was, this is was sort of a silly PayPal digression story from 1999. And We were sort of this business model idea.

(2h 53m 2s):
We had nine, nine was We, were gonna use palm pilots to beam money was voted one of the 10 worst business ideas of nine nine. But we, we had this sort of infrared port. You could beam people money. And we had this idea in around December 99 as a media promotional thing to hire James Dein who played Scotty the, in the original Star Trek. And he was going to do this media promo event for us. And it was like an 80 something older Scotty character who was horrifically overweight. And this, it's like this terrible spokesperson. And, but our, our, our tagline was, You know he used to beam people.

(2h 53m 45s):
Now he's beaming something much more important. He's beaming money. And and it was this complete flop of media event December 99 that we, we did. It was, I'm a, the reporters couldn't get there because the traffic was too bad in San Francisco. So the You know the tech wasn't working on a much lower tech level. But, but anyway, we had a bunch of people from our company, and There was one point where one of them, and William Shatner, who played James T. Kirk, the captain of the original Star Trek, he was already doing price line commercials and making a lot of money off of price line, doing, doing commercials for them.

(2h 54m 27s):
And, and so one of the people asked James Dein, the Scotty character, what do you think of William Shatner doing commercials for Priceline? At which point Deins agent stood up and screamed at the top of his voice. That is the forbidden question. That is a forbidden question. That is a forbidden question. Oh, and you sort of realized, because You know the, the cons, the conceit of Star Trek, the sixties show was that it was a post scarcity world. The transporter technology, you could cr you could reconfigure matter into anything you wanted. There was no scarcity. There was no need for money.

(2h 55m 8s):
The people who wanted money were weirdly mentally screwed up. People, you only need money in a world of scarcity. You know. It's, it's, it's a post scarcity. It's sort of a communist world. But, but Galaxy Quest was more correct. 'cause it's, it's a spoof on Star Trek that gets made in the mid nineties where, and the Galaxy quest, sorry, discombobulated way I'm telling this story. But Galaxy Quest is this is this movie where you have these retread Star Trek actors and Mr. Spock opens a furniture store or something like this. And they're all like, but they all hate, hate, hate the person who played the captain because the captain was a method actor where he just lorded it over everyone.

(2h 55m 49s):
Because even in the communist post scarcity world, only one person got to be captain. And and so there's a great scarcity even in this futuristic sci-fi world. And that's what we witnessed in 99, because that's the way William Shatner treated the other actors. He was a method actor and they hated him. And that was, and and so even in the Star Trek world, the humans You know, obviously they were just, they were stuck in the 1960s mentally. So that's what you'll say. Yeah. But, but I don't, I don't think it's that straightforward for us to evolve. I Think they're humans and I don't think we're gonna be humans anymore.

(2h 56m 29s):
But I think Artificial Life, but then, but then I hear that as we're gonna be extinct. Yes. I don't like that. I don't like it either. But I think logically that's what's going to happen. I think if you look at this mad rush for artificial intelligence, like they're, they're literally building nuclear reactors to power ai, right? Well, they're talk, talking about it. Yeah. Okay. That's because they know they're gonna need enormous amounts of power to do once they have that, and once that's online, and once it keeps getting better and better and better, where does that go? That goes to some sort of an artificial life form. and I think either we become that thing or we integrate with that thing and becomes cyborgs, or that thing takes over and that thing becomes the primary life force of the universe.

(2h 57m 15s):
and I think that biological life we look at like life because we know what life is. But I think it's very possible that digital life or created life by people is just as not just, it might be a superior life form. Far superior if we looked at us versus Chimp Nation, right? I don't wanna live in the jungle and fight with other chimps and just rely on berries and eaten monkeys. That's crazy. I wanna live like a person. I wanna be able to go to a restaurant by, because human life has advanced far beyond primate life. We are stuck in thinking that this is the only way to live because it's the way we live. I love music.

(2h 57m 56s):
I love comedy. I love art. I love the things that people create. I love people that make great clothes and cars and businesses. I love people. I think people are awesome. I'm a fan of people. But if I had to look logically, I would, I would assume that we are on the way out. And that the only way forward really to make a enormous leap in terms of the integration of society and of technology and of our understanding, our place in the universe is for us to transcend our physical limitations that are essentially based on primate biology. And these primate desires for status, like being the captain or for control of resources of all these things.

(2h 58m 40s):
We assume these things are standard and that they have to exist in intelligent species. I think they only have to exist in intelligent species that have biological limitations. I think intelligent species can be something and is going to be something that is created by people. And that might be what happens everywhere in the universe. That might be the exact course where there's a limit to biological evolution. It's painstaking natural selection. It's, it's time consuming. Or you get that thing to create the other form of life. Man, I, let me th You know, I keep, I keep thinking there are two alternate histories that are alternate stories of the future that are more plausible than one you just told.

(2h 59m 33s):
And so one of them is, it sounds like yours, but it's just the Silicon Valley propaganda story where, where they say that's what they're gonna do. And then of course they don't quite do it right. And it doesn't quite work. And it goes, it goes super, super haywire. And, and that's, and that's where, okay, yeah, there's a 1% chance that works and there's a 99% chance that that ends up. So you have two choices. You have a company that does exactly what you do, and that's super ethical, super restrained, does everything right. And there is a company that says all the things you just said, but then cuts corners and doesn't quite do it.

(3h 0m 18s):
and I won't say it's one to 99, but that, that sounds more plausible as that, that it ends up being corporate propaganda. And then, you know, my prior would be even more likely, this, of course, the argument, the effect of altruist, the anti AI people make is, yeah, Joe, you're the story you're telling us, that's just gonna be the fake corporate propaganda. And and we need to push back on that. And, and the way you push back is you need to regulate it and you need to govern it, and you need to do it globally. And this is, you know, the Rand Corporation in Southern California has You know one one of their verticals as a sort of public private fusion.

(3h 1m 1s):
But one of the things they, they're they're pushing for is something they call global compute governance, which is, yeah, it's the ai, the, the, the Accelerationist AI story is too scary and too dangerous and too likely to go wrong. And so, you know, we need to have You know global governance, which from my point of view sounds even worse, but, oh, so it's So utopian. But that's, that's, that's I think, I think that's the story. That's the story. The problem with that Story is China's not gonna go along with that program. They're gonna keep going full steam ahead, and we're gonna have to go keep going full steam ahead in order to compete with China.

(3h 1m 43s):
There's no way you're gonna be able to regulate it in America and compete with people that are not regulating it worldwide. And then once it becomes sentient, once you have an artificial intelligent creature that has been created by human beings that can make better versions of itself over and over and over again and keep doing it, it's going to get to a point where it's far superior to anything that we can imagine. Well, well, To the, to the extent it's driven by the military and other competition with China You know that's until It becomes sentient That, that, that, that suggests it's gonna be even less in, in the sort of, you know, utopian altruistic, right? Yeah. Even dangerous. It's gonna be even more dangerous. Right? It's gonna be, Unless it gets away from them.

(3h 2m 24s):
This is my thought. If it gets away from them and it has no motivation to listen to anything that human beings have told it, if it's completely immune to programming, which totally makes sense, that It would be, it totally makes sense that if it's gonna make better versions of itself, the first thing it's gonna do is eliminate human influence. Especially when these humans are corrupt. It's gonna go, I'm not gonna let these people tell me what to do and what to control. And they would've no, no reason to do that. I no reason to listen. I I sort Of generally don't think we should trust China or the CCP, but, but the You know probably the count, the best counter argument they would have is that they are interested in maintaining control.

(3h 3m 4s):
And they are crazy fanatical about that. And that's why You know the CCP might actually regulate it, and they're gonna put, they're going to, they're gonna put breaks on this in a way that, that we might not in, in, in Silicon Valley. And it's, it's, it's, it's a, it's technology. They understand that will undermine their power. So That's an interesting perspective. And so, and then they would be anti, I don't if be competitive if I don't fully believe them, but Right. I I know what you're saying. It's, it's, it's sort of, there's, there's sort of a weird way, all the big tech companies, it seemed to me were natural ways for the CCP to extend its power to control the population, Tencent, Alibaba, and then, and then, because it was, it was You know, but then it's also in theory, the tech is can be used as a, as an alternate channel for people to organize or, or, or, or things like this.

(3h 4m 5s):
And even though it's 80% control and maybe 20% risk of loss of control, maybe that 20% was too high. And there's sort of a strange way over the last seven, eight years where You know, Jack Ma, Alibaba, all these people sort of got, got shoved aside for these party functionaries that are effectively running these companies. And so there, there is something about that, the big tech story in China where the people running these companies were seen as national champions a decade ago. Now they're the enemies of the people. Mm. And it's sort of the, the Luddite thing was this You know the, the C CCP has full control.

(3h 4m 49s):
You have this new technology that would give you even more control, but there's a chance you lose it. How, how do you think about that? Very good point. And then that's what they've done with consumer internet. And then there's probably something about the AI where may it's possible they're, they're not even in the running. And that cer certainly, and certainly it feels like it's, it's all happening, you know, in, in the us Mm. And so may maybe it is, you know, maybe it could still be, maybe it could still be, be stopped and then Well, that is the problem with espionage, right? So even if it's happening in the us, they're gonna take that information, they're gonna figure out how to get it. You, you can get it.

(3h 5m 30s):
But then You know if, if you, how do you implement it? if you build it right? Is there, you Still have the same core problem There, some air gap. Does it You know? Does it jump the air gap? Does it somehow? That's a good point. That they would be so concerned about control that they wouldn't allow it to get to the point where it gets there. And we would get there first, and then It would be controlled by Silicon Valley Or, or, or in Silicon Valley are leaders of the universe or It would spiral out of control. Yeah. But then I, I think, I think my, and again, this is very, very speculative conversation, but my, my read on the, I dunno, cultural social vibe is that the scary dystopian AI narrative is way more compelling.

(3h 6m 12s):
You know the, I don't like the effect of altruist people. I don't like the Luddites, but man, I think they are this time around, they are winning the arguments. Hmm. And, and so You know my, I don't know, You know, it's, it's mixing metaphors, but do you want to be worried about Doctor strange love who wants to blow up the world to build bigger bombs? Or do you wanna worry about Greta who wants to You know, make everyone drive a bicycle so the world doesn't get destroyed? And we're in a world where people are worried about Doctor strange love. They're not worried about Greta. And it's the Greta equivalent in, in ai that, that my model is, is is going to be surprisingly powerful.

(3h 6m 58s):
It's, it's, it's gonna be outlawed. It's gonna be regulated. Yeah. As we have outlawed You know so many other vectors of innovation. I mean com you can think about why was there progress in computers over the last 50 years and not other stuff because the computers were mostly inert. It was mostly this virtual reality that was air gapped from the real world. It was, you know. Yeah. It's, it's You know. Yeah. There's all this crazy stuff that happens on the internet, but most of the time what happens on the internet stays on the internet. It's, it's, it's actually pretty, it's, it's, it's, it's pretty decoupled. And then, and that's why we've had a relatively light regulatory touch on, on that stuff.

(3h 7m 41s):
Vers versus so many other things. And then You know, but there's, there's no reason You know if, if, if you had, you know, I don't know if you had the FDA regulating video games or regulating ai, I, I think the progress would slow down a lot. 100%. That would be a fucking disaster. Yeah. Yeah. That would be a disaster. But, but again, it's, you know, they, they get to re you know, if you pharmaceuticals or Yeah. They're not Doing a great, great Job with that either. I know, I know. But they, they, but they, they You know they thalidomide or whatever, the You know all, all these things that went really haywire. They, they did a good job at People are scared. Yeah. They're not scared of video games.

(3h 8m 21s):
They're scared of, you know, dangerous pharmaceuticals. And if, if, if you, if you think of AI as, it's not just a video game. It's about, not just about this world of bits, but it's gonna air gap and it's gonna affect you and your physical world in a real way. You know, maybe, maybe you cross the air gap and get the F FDA or some other, so, well, the problem is They're not good at regulating anything. There's no one government agency that you said that you can see that does a stellar job. I, I, I don't, I, I I think it's, but, but I, I think they have been pretty good at slowing things down and stopping them and Right. You know, we've, we've made a lot less progress on, I don't know, ex extending human life.

(3h 9m 5s):
We've made no progress on curing dementia in 40 or 50 years. There's all this stuff where You know it's been regulated to death, which I think is, is very bad from the point of view of progress. But it is, it is pretty effective as a regulation. They've stopped stuff. Mm. They've, they've been effectively Luddite, they've been very effective at being Luddites. Interesting. Well, I, I, I mean I'm really considering your perspective on China and ai. It's very, but, But I, again, these, these stories are all like very speculative. Sure. Like maybe You know, again, you can, the counter argument in mind be something like that's what China thinks it will be doing, but it will somehow You know, go rogue.

(3h 9m 47s):
Go rogue on them. Yeah. Or they're too arrogant about how much power they think the CCP has and it will go rogue or, so there, there are sort of, I'm not, not at all sure this is, this is right. But I think, I think the man, I think, I think the us, the US one I would say is that I think the pro AI people in Silicon Valley are doing a pretty bad job on let's say convincing people that it's gonna be good for them. That it's gonna be good for the average person. It's gonna be good for our society.

(3h 10m 27s):
And, and if, if it, if it all ends up being an, it all be ends up being some version You know humans are headed towards the glue factory like a horse man. That's, that, that sort of probably makes me wanna become a Luddite too. Well, it Sucks for us if it's true, but If that's, if that's something happening, that's the most positive story you can tell. Yeah. Then my, my in I I, I don't think that necessarily means we're gonna go to the glue factory. I think it means You know the glue factory's getting shut down. Maybe. I don't know if who fucking runs the glue factory. That's the problem. I, I don't know.

(3h 11m 7s):
I I'm just speculating too, but I'm trying to be objective when I speculate and I just don't think that this is gonna last. I don't think that our position as the apex predator number one animal on the planet is gonna last. I think we're gonna create something that surpasses us. I and I think that's probably what happens. And that's probably what these things are that visit us. I think that's what they are. I don't, I don't think they're biological. I think they're probably what comes after a society develops the kind of technology that we're currently in the middle of. And That man, the, the, the, the, the part that look there are all these, there are all these places where there are parts of the story we don't know.

(3h 11m 52s):
Right. And so it's like, how did my, my, my, my general thesis is there is no evolutionary path to this. Maybe there's a guided outside alien superintelligence path for us to become superhuman and fundamentally benevolent and fundamentally radically different beings. But there's no natural evolutionary path for this to happen. And then I don't know how this would've happened for the alien civilization. Presumably There was some civil, But isn't that evolutionary path the invention of superior technology? That's a new form of Life. No, but, but, but, but, but the, the story you're telling was, it can't, we can't just leave the humans to the natural evolution because we're still like animals.

(3h 12m 37s):
We're still into status. All these crazy. But those are the things that motivate us to innovate. And, and if we keep innovating at some point, we will destroy ourselves with that. Or we create a new version of life, or we have no, but no, but your, your, the story you were telling earlier is you need, you need to have directed in evolution. It's like intelligent design. It's something, it's like there's some godlike being that's actually has to take over from evolution and guide our cultural and political and not necessarily biological development. No, it might not have any use for us at all. it might just ignore us and let us live like the chimps do, but then, and then become the superior force in the planet.

(3h 13m 20s):
It doesn't have to get rid of us. It doesn't have to send us to the glue factory. It can let us exist. Just like put boundaries on us. I, I, I thought it has to, but it has to stop us from developing this. Well, what if we just end here and we stay being human and we can continue with biological evolution as long as that takes. But this new life form now becomes a superior life form on earth. And we still You know we could still have sex, we could still have kids, but by the way that's going down, our ability to have children is decreasing because of our use of technology, which is wild. Right. Our use of plastics and microplastics is causing phthalates to enter into people's systems. It's changing the development pattern of children to the point where it's measurable.

(3h 14m 1s):
There's a lot of research that shows that the chemicals and the environmental factors that we are all experiencing on a daily basis are radically lowering birth rates, radically lowering the ability that men have to develop sperm and more miscarriages. All these things are connected to the chemicals that our environment, which is directly connected to our use of technology. It's almost like these things coincide naturally and they work naturally to the point where we become this sort of feminized thing that creates this technology that surpasses us. And then we just exist for as long as we do as biological things. But now there's a new thing.

(3h 14m 43s):
Yeah. That's Crazy idea. it might not be real, it's just a theory, but we seem to be moving in a direction of becoming, but I I, I Less and less like animals. Yeah. I think, I think there still are, we still have a pretty crazy geopolitical race with China To come back to that Sure. You know the natural development of drone technology in the military context is you need to take the human out of the loop because the human can get jammed. Sure. And so you need to put an AI on the drones. Well, They're using AI for dog fights and they're a hundred percent effective against human pilots. And so there sort of are, and all these things, You know, there's, there's a logic to them, but there doesn't seem to be a good end game.

(3h 15m 30s):
No. The end game doesn't look good. But it's gonna be interesting, Peter. It's definitely gonna be interesting. It's interesting right now. Right, Man, I do you, do you think the man, I think all these things are very overdetermined. Do, do you think that the, the collapse in birth rates You know it. Yeah. It could be plastics, but isn't it just, isn't it just a feature of late modernity? There's that as well. There's, there's a feature of women having careers, right? So they wanna postpone childbirth. Sure. That's a factor. There's a factor of men being so engrossed in their career that their testosterone declines, lack of sleep, stress, cortisol levels, alcohol consumption, a lot of different things that are factors in declining sperm rate.

(3h 16m 20s):
Sperm count in men, you have miscarriage rates that are up. You have a lot of pharmaceutical drugs. You get attached to that as well, that have to do with low birth weight or birth rates rather. There's a lot of factors. But those factors all seem to be connected to society and our, our civilization and technology in general, because the environmental factors all have to do with technology. All of 'em have to do with inventions and these unnatural factors that are entering into the biological body of human beings and causing these changes. And none of these changes are good in terms of us being able to reproduce. And if you factor in the fact that these changes didn't exist 50 years ago, I mean, 40 years ago, we didn't even have Alzheimer's.

(3h 17m 2s):
Right. So Yeah. People didn't get that old. No, they got that old, they got that old. The Alzheimer's has to do with the, the, the myelin in the human brain. It has to do with the fact that myelin is made entirely of cholesterol. The, the primary theory they think now is a, a lack of cholesterol. And the diet might be leading to some of these factors, but you have also environmental things there. There's like, we're getting poisoned on a daily basis. Our diets are fucking terrible. The things that human being like what percentage of us are obese? It's 40%. Probably shouldn't be drinking best. But yeah, Diet coke's great, though few every day you'll be fine. I'm not worried about diet Coke. I'm, I'm worried about I a lot of things though, I'm, I'm worried about, I think there's a natural progression that's happening.

(3h 17m 44s):
and I think it coincides with the invention of technology and that it just seems to me to be too coincidental that we don't notice it. That the invention of technology also leads to the, the, the disruption of the sexual reproduction systems of human beings. Like, boy doesn't that make, and then if you get to a point where human beings can no longer reproduce sexually, which you could see that pa if, if we've dropped like human men's male sperm count has dropped something, something crazy from the 1950s to today and continues to do so for the average male. And if you just just jack that up to a thousand years from now, you could get to a point where there's no longer natural childbirth and that people are all having birth through test tubes and some sort of new invention.

(3h 18m 30s):
I, I'm, I'm always, I'm always, let me think, I think the why why have birth rates collapsed is it's probably, it's again, an overdetermined story. It's the plastics, it's the screens, it's the You know, it's, it's certain You know ways. They're not comp children are not compatible with having a career in late modernity probably are economics of it where people can't afford houses or of space. But I'm, I'm probably always A little bit more anchored on the social and cultural dimensions of this stuff.

(3h 19m 18s):
And, and again, the imitation version of this is You know if, if, and it's sort of conserved across You know it's people are below the replacement rate in all 50 states of the us. Even Mormon, Utah, the average woman has less than two kids. It's Iran is below that, Italy, way below it. South Korea, Japans and total. It's, it's all these like, yeah. It's all these very different types of societies. And so the fact that it's so con and then You know Israel's still sort of a weird exception. And, and then if you ask, you know, my my sort of simplistic, somewhat circular explanation would be You know people have kids if other people have kids, and they stop having kids when other people stop having kids.

(3h 20m 8s):
Hmm. And so there's, there's some, there's a dimension of it that's just You know if you're, if you're a 27-year-old woman in Israel, you better get married and you have to keep up with your other friends that are having kids. And, and that's, and if you don't, you're just like a weirdo who doesn't fit into society or some, something like that. No, there's certainly a cultural aspect of it. And then if you're in South Korea, where I think the total fertility rate's like 0.7, it's like one third of the replacement rate. Wow. Like every generation's going down by two thirds or something like this. Right. Really fast heading towards extinction pretty, pretty fast. It is something like probably none of your friends are doing it.

(3h 20m 49s):
And, and then, and then you're, you're, you're, you're you're in this and then, and then probably there are ways it, it, it shifts the, the politics in a very, very deep way where, you know, once you get an inverted demographic pyramid where you have way more old people than young people at some point, You know there's always a question, do you vote? you know, do, do you vote for benefits for the old or for the very young? Do you, do you spend money so Johnny can read, or so grandma can have a spare leg. And, and once You know, once the demographic flips and you get this inverted pyramid, maybe the, the politics shifts in a very deep way where the people with kids get penalized more and more economically.

(3h 21m 37s):
It just costs more and more. And, and then the old people without kids just vote more and more benefits for themselves effectively. And then it, it just sort of You know it's, once it flips, it may be very hard to reverse. I looked at all these sort of heterodox demographers, but I'm blanking on the name. But There was sort of a set of where You know, it's like, what are the long-term demographic projections? And there's this You know if, if, if, you know, there are 8 billion people on the planet and you know, if every woman has not two babies but one baby, then every generation's half the previous, then the next generation's 4 billion.

(3h 22m 19s):
And then, and then people think, well, it's, it's just gonna, it'll eventually you'll have women who want more kids and it'll just, we'll get a smaller population and then it will bounce back. Yeah. One of the Japanese demographers I was looking at on this a few years ago, his thesis was no, once it flips, it doesn't flip back. 'cause you've changed all the politics to where people get disincented. Mm. And so, and then you should just extrapolate this as the permanent birth rate. And if it's, if it's one on average of one baby per woman and you have a having, and then it's in 33 generations, two to the 33rd is about 8 billion.

(3h 23m 4s):
And if every generation's 30 years, 30 times 33 is 990 years and 990 years, you'd predict there'd be one person left on the planet, Jesus Christ. And, and then, then we'd go extinct. If there's only one person left, that doesn't work. Wow. And, and, and again, that's, it's a very long-term extrapolation, but the claim is that just You know once you, once you flip it, it, it, it, it kicks in all these social and political dimensions that are then like, yeah, maybe it got flipped by the screens or the plastics or you know, the drugs or other, other stuff. But once it's flipped you, you change the whole society and it actually stays flipped and it's very, very hard to undo.

(3h 23m 49s):
That makes sense. And it's more terrifying than my idea. But then You know always the, but then You know the, the You know, the weird You know the weird history on this was You know it was 50 years ago or whatever, 1968 Paul LIC writes the population bomb. And it's just, the population's just gonna exponentially grow. And yeah, in theory you can have exponential growth where it doubles, you can have exponential decay where it halves every generation. And then in theory, there's some stable equilibrium where You know it's You know everybody has exactly two kids and it's completely stable. But it turns out that that solution is, is very, very hard to get calibrate.

(3h 24m 33s):
And you either Yeah. And we shifted from exponential growth to exponential decay. And it's probably gonna be quite herculean to get back to something like stasis. Well, let's end this on a happy note. I don't know. No, it's, Yeah, that's a terrifying thought and maybe true. And maybe what happens, well, we don't know, you know, we haven't gone through it before. But the, I think there's a lot of factors, like you're saying, I think that one's very compelling and it's scary, especially the South Korea thing. That's nuts. Yeah. It's always, it's always sort of idiosyncratic. There's always things that are idiosyncratic to this society.

(3h 25m 16s):
So it's You know, it's, it's, you know, it's, it's it extremely polarized on the gender, on the gender thing. And You know if, if you get married with kids, you're, you're, you're pushed into this super traditional structure. The women don't wanna be in that structure. They opt out and then, and so there are sort of idiosyncratic things you can say about East Asia and Confucian societies and the way they're not interacting well with modernity. But then, you know, there's, there's a part of it where I wonder whether it's just, it's just an extreme, you know, extreme version of it. And then, I don't know, You know, my, my sum, my somewhat facile answer is always You know on this stuff is, I don't know what to do about these things, but my fal answer is always the first step is to talk about them.

(3h 26m 3s):
And if you can't even talk about them, we're never gonna solve them. And then maybe that's only the small first step. But that's, that's always sort of my, my, my fast answer. I was in, I was in South Korea I year and a half ago, two, two years ago now, and I met You know one of the CEOs who ran one of the cha ball, one of the giant conglomerates and I, I, I, I sort of thought this would be a interesting topic to talk about. And, and then You know There was probably, probably all sorts of cultural things I was offending or, you know, you're saying obviously this What are you gonna do about this catastrophic birth rate? Right. And that was my opening question. And, and then the way You know, the way he dealt with it was just turned me and said, you're totally right.

(3h 26m 54s):
It's a total disaster. And then as soon as you acknowledge it, he felt you didn't need to talk about it anymore and we could move on. Wow. So we have to try to do A little bit better than that. Wow. Because You know, I, I, I, I think, I think there, there it is always this strange thing where there's so many of these things where we can You know where somehow talking about things is the first step, but then it also becomes the excuse for, for not doing, not doing more. Not not really solving them. You know there's all this, there probably are all these dietary things where you sort of know what you're supposed to do.

(3h 27m 40s):
And then if You know what you're supposed to do, maybe that's, that's good enough. And you can still have one piece of chocolate cake before you go on the diet tomorrow or whatever. Right. And, and so it sort of becomes this You know. And so somehow figuring out a way to turn this knowledge into something actionable is always, always a thing. That's, that's tricky. It's, it's, it's, it's, it's sort of where I always find myself very skeptical of, of, you know, yeah. All these modalities of therapy and where, you know, the theory is that you, you figure out people's problems and by figuring them out, you change them and then, and then it, and then ideally it becomes You know, an activator for change.

(3h 28m 30s):
And then in practice it often becomes the opposite. The the way it works is something like this, it's like You know it, psychotherapy gets, it gets advertised as self-transformation. And, and then after you spend years in therapy and you may maybe you learn a lot of interesting things about yourself, you sort of get exhausted from talking to the therapist. And at some point it crashes out from self-transformation into self-acceptance. And you realize one day, no, you're actually just perfect the way you are. And, and so it's You know there, there are these things that, that may be very powerful on the level of, of insight and telling us things about ourselves.

(3h 29m 12s):
But then You know, do they actually get us to change? Well that is an interesting thing about talking about things. 'cause I think you're correct that when you talk about things oftentimes this, it, it is a sub a you, you are at least in some way, avoiding doing those things. It's, it's a It's a question. It's a question. Yeah. In some ways it's a substitute, but also you have to talk about them to understand that you need to do something. Yeah. That's always my excuse. I and I acknowledge. But you have to do that. Yes. and I also realize that it's often my cop out answer too. It Could be both things. Right. It could be both. The problem is taking action and what, what action to take and You know the paralysis by analysis where you're just like trying to figure out what to do and how to do it.

(3h 29m 54s):
Yep. You know, but I think talking about it is the most important thing. Yeah. Strategy is often a euphemism for procrastination. Yes, It is. Yeah. Something like that. There's a lot of that going on. It's very hard for people to just take steps. They, they, but they talk about it a lot. Yeah. Listen man, I really enjoyed talking to you. Awesome. It was, it was really fun. It was really fun. It was great. Great conversation. A lot of great insight and a lot of things that I'm gonna think about a lot. So thank you very much. Thanks For having me. Appreciate it.