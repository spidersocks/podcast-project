
Welcome, welcome, welcome to Armchair Expert Experts On Expert. I'm Dan Rather, and I'm joined by Modest Mouse. Hi. Hello. I've been talking about this book quite a bit over the last six months, the world's ic, Curiosity, Exploration, and Discovery at the Dawn of AI by Dr. Fafe Lee. She is an expert on computer vision, machine learning, and cognitive and computational neuroscience. She's a computer science professor at Stanford University and founding director of Stanford Institute for Human Centered Artificial Intelligence. So we've had a lot of ai, but I'll say that this, what makes this episode so special is Dr. Fefe Lee's personal story is so compelling.


I mean, the fact that people can land in this country, not speaking English deep into school and fucking be pick it all up and then master all these fields become Better than Everyone. Oh my God, it's so impressive. Yeah. Oh, I loved her. Please enjoy Dr. Faye Haley.


We are presented by Amazon Prime. It's more than just fast, free shipping. Whatever you're into, it's on Prime. So keep listening, keep watching, keep on keeping on. To hear more about why we love Prime during the fact check.


He's an object. This is a very, very sinking. I Know. We're up to a terrible start. Do you wanna stop? You wanna sit in this chair or you can. I feel like I'm going through a therapy version. Yeah. Well, that is the goal. We do want people to feel Very comfortable, relaxed, too comfortable, really. Yeah. If the spirit moves you to lay down supan, you're invited to do so.


I might, I woke up so early. What time did you wake up? Probably five 40 something. That's early. Yeah. What time do you normally rise? Not that much later. My alarm is six 20. Okay. Mine's six 40. Oh, okay. I'm aspiring. But you know what's funny? Today it was six 20. You have kids? I have kids. How old are They? Nine and 11. Mine is eight and 12. You Have eight and 12. Yeah. So we're in the same stage of life. Boys or girls? 12 is boy, eight is a girl. How about you? Girl? Girl. Aw. Yes. I'm so lucky. Although 11, about to be 12. I'm starting to get an inkling of what's coming my way. Yeah, yeah, Yeah. In a house with three ladies.


Yeah. In fact, yesterday was a very emotional day. I'm barely hanging on. Oh, What happened? I don't know what's going on with my three ladies, but all of them are in some kind of hormonal sleep, hormonal turmoil. Interesting. And every variety, which is fun. Have We started? Oh, yeah, yeah, Yeah, yeah, yeah, yeah. We're always recording. We'll call it a VR. Always be recording. Always Be recording. Okay. So you have 12 and eight. And are they close? They're Very close. He's a good big brother. He totally is. Sweet. Sylvia's your husband. Yeah. Yes. And does one of them have Sylvia's personality and one have yours? Well, I can tell you one of them has Sylvia's hair.


Okay. Which is A lot of curls. Curls, World of curls. Yeah. World of curls. Well, you're here because I read your book maybe two months ago. I was having dinner with Ashton Kutcher. Do you know who that actor is? Yes. He just text me last night. He's like, you're seeing my friend X. Oh, good. Yeah. So we were at dinner and we were just chatting about people we thought were really interesting. And then he asked me if I had read your book, and I hadn't. I went into it thinking I would get a history lesson on ai, which I did. I hope so. And a very thorough one. But I would not have invited you for that. Your life story is so interesting and beautiful, and the way you write about it, you're an incredible writer.


Thank You. I do wanna give credit to my friend Alex, who co-wrote the book with Me. Okay. That's very big of you. Who's Alex? Alex is a friend of mine. He does not claim to be a writer, but he's a very talented writer, and we've known each other for years. He loves ai and we talk about it. So when I was invited to write this book, I do feel like I want Alex to co-create this with me. So we became a creative team. It was a really fun process. How Do you know Alex? I know Alex. Through Ted 2015. I gave my first Ted Talk. I watched it. Yeah, thank you. Yeah, yeah. About image, how hard it is for a computer to see.


Yes. And that's how I got to know Alex Because he worked with Ted in some Capacity. I think so, yeah. He was in some kind of partnership with Ted, and he was helping me to put together my slides. Since then, we become friends and we talk about ai, and he's also helped me in some of this Stanford HAI, human-centered AI Institute stuff. You're kind of creative partners. Yes. It's very interesting. 'cause book writing is very different creation compared to doing science. We wrote almost three years or two and a half of those years. During the day, I do my science and some of the evenings I do the creative writing. It's such a different part of the brain. Yeah.


Yes. Which one do you find more exhaustive? Both. Both in different ways? No, but they are very different. Of course. I've been a scientist for almost three decades, so I'm more familiar with being a scientist. But the creative writing journey, I loved every minute of it. When I say I love, it's not necessarily happy love. It's enjoyable, it's a painful love, some part of it. But I really loved it. That's what I wanna start with. 'cause I'm curious, when you sat down with Alex, I'm sure the historical part, the scientific part, that stuff is probably easy. But had you ever told your life story to anyone in that detail? No. And I didn't want to, and I still don't. Yeah. Do you think that's a, a personal disposition or where you come from culturally?


I think of the story of your father, which we'll get to, and how little he told you about his own childhood until the time was right. And I glean from that. Oh, this isn't a culture that is just divulging all this emotional trauma and baggage. Well, I have to say, I think culture in the case of an individual sometimes is too broad. A brush stroke. Yeah. I think it's more individual. I'm a relatively shy person, and Alex and I wrote the first version. It was purely scientific. It was the first year of COVID. We talk on the phone almost every night, and one of my best friend is a philosopher at Stanford called John mdi. He's a very revered, higher education leader.


He was Stanford's provost for 17 years, and he is co-director with me at Stanford, human Centered AI Institute. So I was really proud. I wrote this first draft. I showed it to him. It was during Covid, after like two weeks, he called me, he said, Fefe, you and Alex should come to my backyard. That's how we meet, because we were social distancing. And then we went and he said, you have to rewrite. Ah. I was like, what? That's The last thing I wanted to hear. He said, you are missing an opportunity to tell your story. Tell AI story through your lens. And I was just so rejecting that idea. Yeah. I was like, who wants to hear my story?


I wanna write about ai. I call him Edge. Edge said There are many AI scientists who can write a so-called quote unquote objective story of ai, but your angle would be so meaningful. Your voice to the young people out there, the young women, immigrants, people of all kind of background. And we were sitting his backyard with a triangular shape, three chairs. And I looked at Alex. He was almost jumping off his chair With excitement. He said, I told you. He said, I told You So many times. Of course it only takes the edge to tell you that. Well, let's jump to a really big philosophical question about that.


I think when reading your story, you came here, this huge language barrier, such a fish outta water. But your work, if good enough, would speak for itself and it would be a meritocracy. And so it's not surprising to me that someone who got to where they wanted to go with that belief would have a hard time thinking, wait, I was trying to transcend this otherness. This otherness is the thing that would be most interesting and worthy of attention and affection. What a gap. It's very subtle. You caught that. Because when I go into the world of size, I don't think too much about meaning other things. I just follow that light, follow the Curiosity.


And to this day, even when I was writing the book, it's AI that fascinates me. And I wanted to write about ai. So it was very strange that someone wants to read about me. Yeah. Well, I think even the notion that you're struggling so hard, I gotta set up your story more. This is the last thing I'll say outta context. Monica's like, not everyone's read the book more, but just, of course, math was appealing because math didn't have a language barrier. Yes. But I do wanna be honest. Even when I was a young kid in China, I loved math and physics. I love physics. I would say even more than math itself. I saw math more as a tool. I saw more beauty and fascination in physics.


Yeah. There's more philosophy. Yes. Okay. So let's start in China. In 1976, you're the only child of your parents. Yeah. And talk about your mother. 'cause she's very interesting. She is very interesting. My mom come from a normal family, but as the book says, her family is in a difficult position because of the history. So she was a very good student. I think the intellectual intensity I have a large part of it, come from my mom. She was a curious student. She was very intense. But her dream was pretty shattered when she was not able to go to a normal high school when she had a dream for college.


And that carried her through. And then you arrive and you show this great aptitude, and now she has, in a sense, a second chance at this dream. But she starts recognizing pretty soon your path is gonna be stilted as well if you stay there. So what's happening? What is she noticing as you start getting educated and show this aptitude? A lot of this is hindsight, because I didn't talk to my mom in this way. Right. I think it was a combination that my mom has her own belonging to be more free maybe. And in hindsight, I don't know if she, how to translate that. Yeah. In the world she was living in.


And the opportunity to go to a new world was as appetizing to her as it is for her on my behalf. It's also true. She saw me as a bit of a quirky kid. I think that blend of what she was longing for and what she was longing for on my behalf without me realizing was the motivation of many of the changes, the decision of immigration. Well, what would've been your trajectory had you stayed in China in 1988 when you're 12? Am I misremembering that your mom felt like they weren't giving you the attention and encouragement that she was hoping you would get? My mom was not looking for attention for me.


My mom was looking for freedom for me and for herself. A lot of that is projection, was looking for a world where I can just be who I am. She wasn't necessarily looking for attention. What do you mean By quirky? This goes to my dad. I didn't follow rules in the average way. In hindsight, maybe it was just me being immature. Sure. But also there is a part of me, why should girls not play soccer? Why should girls be told they are biologically less smart than boys? I was told at least more than once, watch out that girls would, in general, be less smart by the time you hit your teenage time.


This is what I'm remembering from the book, that you are explicitly told you're not as smart as boys. I wasn't told in the context of one. One, like, let me sit you down Fefe and tell you. I was told in the way that teachers will say things to boys. Yeah. Or the context. Society had a whole different expectation for boys. I was very lucky. My own family protected me, but they can only protect me so much. As soon as you enter a school system, as as soon as you interact with society, all that came through from that point of view, I was not following the normal path. I was reading different books.


You know, I was so passionate about flights, UFOs, physics, special relativity. I would grab my classmates to talk about that, but that was just not normal. Yeah, Yeah, yeah. Who was exposing you to all that stuff? That's A great question. I was trying to ask myself that question when I was writing the book, and I still don't have a strong answer. I think the early Curiosity, the exposure came from both my parents. My dad loved nature. My mom loved books and literature. But how did, I fell in love with physics and UFOs and all that? I'm not totally sure. It could be my dad, before he came to New Jersey, he was ordering me some magazines outside of the school reading.


And that exposed me to those topics. And because my parents protected my Curiosity, when I say protected, it really just meant they left it alone. They did a medal with it. I kind of followed it through myself. So Your dad leaves when you're 12. He goes to New Jersey, he's there for three years on his own, and he is setting up a landing for you and your mother. Yeah. Yeah. Do you remember that? Three years missing him terribly. How was that experience? It was tough. I mean, it was early teenagehood. There was no internet. Phone calls are extremely expensive to the point of being prohibitively expensive. So it was mostly letters every couple of months.


But then I was a teenager, so I had my own world to explore as well. So it wasn't like I was sitting in the room crying or anything. Yeah, Yeah, yeah. So then you come your sophomore year. Yes. You start a public high school in New Jersey For SY High School. One of the experiences you had, I came in and told Monica immediately about, and you were in a class, some kind of a study hall or something, Library. Library. And you were with a group of other ESL kids, English as a second language kids. And you saw a very, well, no, I wanna say how insignificant this first interaction was. Like benign brushing up against a kid's backpack or something. Right. And what happened, A group of ESL students were in the library and then the bell ran or something we have to file out of the library door.


And I remembered it was crowded. I honestly did not see what happened to that boy. But all I knew was my ESL friend was on the floor. By the time I realized there was some commotion being kicked and punched, I think there was nose bleeding and he was holding his head. Yeah. He said he had got a concussion and a broken nose and there's two boys kicking him. Yeah. And that's not even maybe the most traumatic part. It's that after he's gone for a couple weeks, he comes back and he's just not the same boy. Yeah. I mean, nobody would be the same after going through something like that. Definitely. It's huge impact. It was a experience that was definitely pretty intense for all ESL students.


Nobody felt safe for a long while. Yeah. I think it changes your worldview on a dime, which is, Ooh, this new place I'm in can get pretty violent and a little out of control. And if you're other, this could happen. I have to imagine. Yeah. That's an incredibly scary recognition of where you're at. Yes. But also I do wanna give more colors. Right. Yeah. I love that your show focuses on the messiness of being human. Being messy is being multidimensional. But it was also an environment where there was so much support, there was so much friendliness and there was also so much opportunity. So it was very confusing.


I'm not trying to say that experience itself is not heavy. I don't feel lucky about that experience. And I mean there was anger and all that, but in the meantime, the fuller context of that community was also quite a supportive community. So it was very confusing. It give me the multidi dimensionality of the new country I landed in. Everything's happening. Yes. A lot of opportunity is happening as promised. And then a lot of xenophobia and violence is happening. Right. Yeah. Did you feel like you had to after that sort of like keep your head down? Maybe it's just my own personality. I always felt I had to keep my head down. Right. Especially as an immigrant, sometimes I feel that way.


Even now, especially given the AI world we live in, I feel I need to keep my head down to do work. Of course, that particular event probably added a layer of complication, at least for a while. But they also taught me you have to stand up for yourself. It did open different insights to me. I don't know if you would rank these things in your life of like serendipitous things happening, but meeting Mr. Ella has to be minimally in the top 10. And I would hope in the top three. Oh yeah. Minimally. Yeah. It's possibly in the top three for sure. Meeting Mr. Ella was so lucky for me. Yeah. I find this to be one of the sweetest stories I've ever read about and and kind of makes me hopeful for people how generous they can be.


But in a nutshell, minimally you're thinking, I'm gonna do good at math. I don't have to go to my dictionary back and forth like I do in every other class. And you're in math and you're getting problems wrong. And you yourself cannot identify any pattern in this. You don't know what's going on. And you go to see Mr. Ella in his office. That's Your teacher? Yes. Mr. Ella was my math teacher. I got into calculus. And then ity high school doesn't have calculus BC we only had AP calculus for B. So he had to teach me during his lunch hour for bc. But this story you're talking about was earlier. It was during some pre-calculus stuff. And it turned out I was using a broken calculator that They had gotten in a garage.


Shell, her father loves garage shells. It was his favorite thing in the world. I know. Every weekend they go does, he still does. I love garage sale. I don't have time to go to garage sale, but I love it. So Mr. Isabella was tough. He is a tough love kind of teacher. So even though I was ESL, I was this mousy girl. He didn't think I needed any extra. He Didn't pity you? No, not at all. I, for one quarter of semester, I got 89.4 or something. I still remember that. I was like, oh God. Point six. I would get to at least an A. And he would not gimme that A, You asked about extra credit and he was like, get real.


How about good? A good grade on the test? Yeah. And he would say, there are many smart kids in the class. You just have to work hard. But it sounds in the retelling, like the breakthrough. And I think this scene would be in a movie. If I were writing the movie, you're There, he discovers the tan symbol on your calculator as malfunctioning. He helps her figure this out. 'cause he too can't figure out the pattern of all these errors. And then somehow you guys start talking about books and he asks if you've read a certain science fiction writer, you try to tell him you haven't read that one. But you really love a million kilometers under the sea. You can't translate it. And you can't pronounce Jules Verne. But he figures out you've read Jules Verne. Yes. And he is like shook. He's like, you've read Jules Verne.


Yes. And then you go on to say yes. And you've read Hemingway and you've read everything. Well, I've read everything my mom gave me, which is so odd. Which was Extensive. Yeah. If I were him. And this young girl from China comes in and she has read most of the classics that's so real. Like, what am I dealing with here? Yeah. I gotta imagine for him at least, that was a moment where he is like, okay, I'm betting on this horse. I Think he saw a person he could be friend with. Just the way I saw in him. Later on, I realized, again, this is hindsight, that he does that to so many students. And he used this way of opening up in different ways.


Not necessarily science fiction or classic literature to really get to be so helpful for him and me beyond math and calculator. When we started talking about science fiction and the English classics, he realized that he was seeing me more than ESL kid at that point. And he is also a shy person himself. Later, his wife, Jing and Bob later, I call him Bob. We became such good friends, Many, many year, way longer than maybe Jing said he's such a bookworm. Even during his family parties, he'll be by himself reading. Yeah. So he's totally an introvert in a way that we just had chemistry.


Yeah. But this is one thing I was not able to fit into the book, is that for years he would keep a diary and his diary talks about just his teaching life. And I know in this diary there are so many stories about different students he helped with, not in the sense of bragging, it's just he's a writer. Right? Yeah. So years later, before he passed away, we didn't know he was gonna pass away. I told Bob, I said, Bob, you've gotta turn this into a book. Of course we can anonymize. But this is an American teacher story of so many students. Many of them are immigrant students because they lack the support.


They lack the family. Some of them are in high school by themself, families overseas. Many of them are like me. Parents are so busy that the students don't have that emotional support. And he supported so many students. I can sit here and tell you endless story. And then he wanted to translate that into a book, but somehow he just couldn't bring himself to do it. Maybe he's too shy. Maybe he's too humble. Yeah. I think he's struggling with the same issue you're struggling with. You don't feel entitled to tell this story. Right. I feel so strongly he needed to write this book. I almost felt like one day I would write it for him. But of course he passed away so suddenly because of the brain tumor.


So when I was writing my book, I realized, let me tell the Bob Sabella story. Let me tell the story on behalf of so many American public school teachers. They don't have much of a voice. Nobody knows their name, but they work above and beyond every day for the students in their community. They don't care which part of the world they come from, which kind of family background they come from. But they invested so much in these students and they changed lives. Yeah. They're very unsung heroes. They're not tenured professors at elite universities. They're Totally unsung heroes. And they're the ones that get the people to those destinations.


Yeah. Yeah. It's a really beautiful story. How instrumental was he in you finding your way to Princeton? He was instrumental more than Princeton because he was instrumental as the second dad. He helped me to be grounded. Well, you, you're an immigrant kid. A ESL kid. You land in the country without speaking the language and going through so many things. It feels so unstable. I think you're underplaying your story. If you came here in seventh grade and ended up at Princeton, that's one story. You had two years to, I know yourself ready to learn English to start Princeton. And you didn't speak any English. You're very much under. Which is fine. I think so. Would your teacher Admir?


Yeah. You feel maybe that's self-indulgent or something. But that's really bonkers. It is. Again, AI aside to land and go, okay, if you drop me in Russia and told me I have two years that land at their most elite university, Most state university, It's not gonna happen. It's not gonna happen for 99.999% of people. Let's talk for a second about you going to Princeton. This is another fun moment for me in the book, because there's something so much more important about Einstein than the theory of special relativity. And I can't really articulate what it is, but I know you have a good dose of it. So what was it like going there and seeing the statue of Albert Einstein and imagining that you would in some way be touching that reality?


So the first time I saw the statue of Albert Einstein before I was applying for college, it was probably early junior year. My dad continued to find things for us to do. That's free. It's very important. It's free. Princeton's Natural History Museum was free. So that's why we went there. Garage sales free. Exactly. Museums free. Yes. See instance, Daru was kind of symbolic for me that I'm getting back to where really my soul wanted to be at. 'cause as a teenager, landed in a new country trying to learn language, deal with all the messiness, you know, Chinese restaurant walking dogs.


Yeah. You're working a ton of hours. Yeah. Yeah, exactly. I didn't forget about physics. I was taking physics class in school. But I forget about the sense of love Romanticism. Yeah. It really is. That first love. And it kind of got me back to that rekindled something. Well, don't You think it left an imaginary word where this person existed and it put it in your own three-dimensional reality? Yes. Suddenly, I feel so much closer to that person and that person symbolizes the entire world of physics. I feel so much closer. I was literally in Princeton. Right? Yeah. Yeah. That felt very different. And he lived there for what, 30 some years or? Yeah, maybe more.


I think that would be a special moment as well. I'm sure you watch the movie Oppenheimer. Yeah. Yeah. Do You remember the opening scene? Was I Einstein in front of that little pond? Yep. Yep. Talking with Oppenheimer, Right? He was first there by himself. Yeah. I call that my pond. That pond literally exists. It was very close to my dorm. Ah, okay. By the time I got to Princeton and I would go there a lot. 'cause I know that was close to the Advanced Institute where Einstein worked. Yeah. So like when the thing came out, Sylvia was sitting next to, I'm like, Sylvia, this is my poem. It's such a full circle. Yeah. Yeah. I'm currently stuck in a rut where I'm learning a lot about physicists, historical physicists.


And I'm wondering, have you read when we cease to understand the World, have you read that book? No. Or have you read The Maniac? Either of those? No. The maniac's all about Yanu Von Neumann. I'm reading a different bio of him, but not You are the Maniac. Which one? Oh, It's in my phone. Yeah. Same. Don't worry about it. This one's fun. 'cause it has the perspective of a million different people in his life. Like a student. He was friends with the school, one of his wives, people who worked with him. And you get this really comprehensive view. Another Princeton Guy. Yeah. I'm obsessed with all these guys. And them when we ceased to understand the world is many of these physicists who were so brilliant at a time, who ultimately became crazy. And how many of their breakthroughs in the math of quantum mechanics coming to this guy in a nine day, 106 degree fever, writing down the matrices and not understanding the math when he comes out of it.


But it holds, there's a lot of weird magic in this space, I think where people have these breakthrough thoughts and they touch some understanding and they're in a compromised state mentally is just fascinating To me. So mystical. Yeah. Yes. Physics is absolutely the discipline that pushes you to think so audaciously, that you have to transcend that immediate reality. Yes. That's What I loved. I loved about Einstein, I loved about modern physics. Even Newton Classic physics. You have to think. So beyond the immediate reality, Although stories of him getting asked a question and then answering it two and a half days later and he hasn't left the chair and the person left.


Right. Like he went away for two and a half days and then came back with the answer. Or just the notion. I think one of the most intriguing parts is like you are going to have thoughts that cannot be expressed in language, but can only exist in math. That already is like what There is actually even beyond math. Right. And then there's a realm beyond math. Yes. It's the closest thing. I think we have to magic where it's like completely outside of our grasp, but for a handful of people. I love that you call it magic. It is also the furthest thing we have to AI is that humanity in us, that magic, that creativity, that intuition, that almost un graspable way of intelligence.


Yes. We should keep that in mind. So You're at Princeton, you're also working a ton, right? Yes. When do your parents start the dry cleaners? So we started very quickly right after my freshman year started because my mom's health was going so badly. They were working in Newark, New Jersey. I don't know if you guys know that part of, I know Newark. Yeah. New Jersey from ity to New York. New Jersey is a very difficult drive. My mom's health was bad and it was long working hours. I was really worried about, the doctor was worried. We finally decided if we can do a local thing in ny, it would be better for the family.


And it was very important for me that the business is a weakened business because that way I can do the lion's share of work. But there are pretty much three kind of weakened business for immigration. Families like us open a restaurant, open a grocery store, or open a laundry and restaurant and grocery require very late working hours for restaurant and groceries. Very early. You have to go to Chinatown to get supplies. So neither of these work for my mom's health. Whereas dry cleaning was actually perfect. 'cause it's a daytime business. It's very long hours during the weekend, but it's at least daytime. And a lot of my mom's work, especially when it comes to alteration, she can sit in front of the sewing machine Because your mother had had a reoccurring fever as a child and it greatly degenerated some of her heart valve.


Yes. So she was really struggling with heart issues. Yes. She carried that illness with her all her life. And there's no money in the dry cleaning. There's only money in the seamstress scene, whatever we call it. The Tailoring. The tailoring. I mean, there's no money in any of these. Yeah. More the spirit. But having that tailoring ability was nice because it helps a little bit. And my mom is incredible. She never learned this. She was a bookworm. And she is kind of a brainy. She should have done what you did, right? Yeah. I don't think she would love physics, but She, but You know what I mean. She should have probably been an academic. Yeah. She would've been an academic, but then she just kind of figured out tailoring by herself. I still don't know.


Like I tried. I could not, the only thing I can do is sit there and unstitch things for her. Sure. I think a chimp can do that. Yeah. Thank you. Yeah, Exactly. I say that 'cause I know how to remove stitches from garments. Yeah. And I don't have more skills than a chimp. Yeah. So we open the dry cleaner shop during the middle of my freshman year, and that became my entire memory of my undergraduate. Here's a fun fact. Princeton is organized by residential dorms. I lived in one of them called Forbes. It turned out Forbes is very famous for its Sunday brunch. Oh, I didn't know there was a Sunday brunch because I was home doing dry cleaning.


Yeah. He said he didn't go to a single party. Right. But then when I went back to Princeton as a faculty, Forbes was very kind. They made me a faculty fellow. And I discovered Sunday brunch That was like, you what you've been missing years later, instead of the freshman tent, you gained the 30 10. Yeah. Right. The faculty tent. So I felt so good. I finally got my Sunday brunch. And I think it's worth mentioning when you guys were trying to open that dry cleaners, you were trying to raise a hundred thousand dollars and you were $20,000 short. And again, Mr. Isabella Monica, she gave The money. Yeah. It was a total shock to this day, actually, as a 19-year-old, as much as I appreciated Gene and Bob, I did not realize the extent.


We're talking about late 1990s, there are two teachers, public school teachers with two kids about to go to college. Wow. It's unimaginable. He Said Gene, and he decided to do that. I mean, at that moment I was very, very grateful. But now, after I became a grownup, this is unimaginable. It's impossible that someone would do that. It's Unimaginable. Especially he later told me, I think I was returning the money. He said, I didn't realize you'll be able to return. I like what? Of course you have to give it thinking you'll never give it back. Yeah. Yeah. I guarantee he and his wife were like, we're giving this money away. I did not know that he did use the word lend.


And of course, in my mind, I was like, of course I'm gonna retire. Like I'll do anything to return. And Bob did not Expect that. They could not have assumed that. So the money was Being raised to help your mom start The dry cleaner? No, to help my family. To start the business. To start, Yeah. We as a family, I still consider myself the CEO of the dry cleaner. I live in Silicon Valley. You have to claim yourself to be a CEO of something. C-Suite. Exactly. So Bob and Jing. Oh, it's incredible. I don't even think their kids knew about this till they read my book. Oh Wow. Oh my God. How proud I'd be of my dad. Oh, okay. So you graduate from Princeton and you have a degree in physics as well.


Some kind of computational, yeah. So Princeton's a quirky school. It didn't have minors. Yeah. So it has these certificates, but they're just minors. I had a computational mathematics as well as a engineering physics minors. And when you are there, unless I'm misremembering, you had a very singular focus on being a physicist. But while you're there, you start realizing you're maybe open to something different. It's Actually really interesting. I never necessarily thought I would be a physicist, but I wanted to be a scientist. That was almost a sacred calling for Me. It was an identity. You Love it. Yeah. It was an identity. For some reason, this girl who works in dry cleaners just wanted to be a scientist.


Yeah. And then I loved physics, but I loved physics for its audacity and Curiosity. I didn't necessarily feel I'm married to a big telescope inquiry. So I was just reading a lot. And what really caught my attention was the physicists I admired so much. I instead Schrodinger, Roger Penrose, they actually are curious beyond just atomic world. They were curious about other things, especially life intelligence minds. And that was immediately the no point. And the eyeopener for me, I realized I love that. Yeah. Understanding how this brain works, brain works, Intelligence works.


It's crazy. The overlap that has now been proven. But at that time, that's not an obvious, we haven't figured out neural pathways. No. And we're not gonna map that onto computers yet. So these seem on the surface very different fields. One's biology and one is, you know. Right. But for me, it was the science of intelligence. I always believed it's the science of intelligence that will unite our understanding of both the brain and the computers. Right. Okay. So then you choose Caltech to go to graduate school. Yes. What did you think of California? I mean, my God, what a place. Right. I Know we're 15 minutes away from Caltech here. 20 minutes. So I was choosing among MIT, Stanford and Caltech, an honest god.


I almost chose Caltech because of the weather. Yeah, that's fair. It Was so true. And the vibe. Yes. The turtles, the garden like campus. And of course I walk into this building. I think it was more building at Caltech. And guess whose photo was there? It was Alber is sure. Oh my God. I was like, what? It turned out calling. He was visiting and of course there was Richter Fryman. Yeah. The fryman lecture. So I just followed these physicists apparently. And New Jersey was cold. And also, I really have a issue with cold because my mom's illness is exacerbated by cold. So every winter she suffers a lot.


So I have this negative affinity to coldness coming from taking care of my mom. So coming to Southern California, I was like, oh my God, I love this place. Did your parents come later? They did in the middle of my grad school. They did. Were you worried about that leaving? I had to switch from being on site to remotely run the dry cleaning. The dry cleaning was stabilized that the customers are all returning customers. So my mom would be able to handle with one part-time worker. And Bob Ella was doing bills for my mom. Oh my God. Yeah. Sweet. He was just helping me. And another thing he helped me as a young graduate student, I would be entering the world of writing scientific articles.


That's pretty intense. Yeah. He would still proofread my English for me. All my papers. Tell Me about on North Star and how you discovered yours. 'cause this happens at Caltech. Yes. The prelude of the North Star was, my education from physics is always about asking the right questions. If you go to the Nobel Museum in Stockholm, there is a Einstein quote about much of science is asking the right questions. Once you ask the right questions, solutions follow right, you'll find a way for solutions. So some people call it hypothesis driven thinking. I've always been just thinking this way.


So as I was studying computational neuroscience as well as artificial intelligence at Caltech, I was always kind of seeking what is that audacious question I wanted to ask. And of course, my co-advisor, Pietro Perona and Christophe Co, they were great mentors guiding me. But many things start to converge not just my own work, but the field people working on visual intelligence from neuroscience, from AI start to orbit around this idea that the ability to recognize all kinds of objects is so critical for human visual intelligence.


When I say all kinds of objects, I really mean all kinds. I'm sitting here in your beautiful room. There's table bottles, couch pillow, a globe books, flower, vast plants, T-Rex skeleton. Okay. That's behind. That's Behind you's about to eat you. Yes. Shirts and skirts and boots and tv. So the ability for humans to be able to learn such a complicated world of objects, Oh, millions and millions of objects. Yes. Is so fascinating. And I started to believe along with my advisors, this is a critical problem for the foundation of intelligence and that really start to become the north star of my scientific pursuit, is how do we crack the problem of object recognition.


Okay. So now I think is a great point to just go through a couple of the landmark events that take us to where the technology is at that time. So I guess we could start with touring. We could start in 1956. Give us a couple of things that have happened in computing up to that point. Right. So that's the parallel story. I was writing the book, now That I have people hooked into you as an individual, now we can get a little protein in this and learn some stuff. Right. Well, the field of computing, thanks to people like Alan Turman, Neuman was starting during World War II time, basically, of course for the world of ai. A very important moment was 1956 when what we now call the founding fathers of ai, like Marvin Minsky, John McCarthy, Claude Shannon.


They get together under, I believe a US government grant. DARPA funded it or something. DARPA funded to have a summer long workshop at Dartmouth with a group of computer scientists. At that point, the field of AI was barely kind of born, not boring. Yet they got together and wrote this memo or this white paper about artificial intelligence. In fact, John McCarthy, one of the group leaders, was responsible for coining the term artificial intelligence. I think we could get even more rudimentary. Right? So up until that point, a computer was something that could solve a problem.


It could do computations, It could calculate. And this notion of artificial intelligence, what it really meant is could we ever ask a computer questions that it hadn't been pre-programmed to answer? Right. What are the hallmark things that separated at that time, artificial intelligence from just computing? Because I think we've just fast forwarded to everyone saying ai, and I don't think they really even take a second to think of what that step is between computing and computation and thinking. Right up to that point, you can think no matter how powerful the computer was, it was used for programmed calculation. So what was the inflection concept? I think two intertwined concept one is reasoning.


Like you said, if I ask you a question, can you reason with it? Could you deduce if a red ball is bigger than a yellow ball, A yellow ball is bigger than a blue ball, therefore the red ball must be bigger than the blue ball. Right. Without having been programmed that. Yeah. Without directly saying red ball is bigger than the blue ball. Yes. So that's a reasoning. So that's one aspect. A very, very intertwined aspect of that is learning. A calculator doesn't learn whether you have a good 10 button or not. It just does what it is. Yeah. You had a bad one Once. I had a bad one. So artificial intelligence software should be able to learn. That means if I learn to see Tiger one, tiger two, tiger three, at some point when someone gives me tiger number five, I should be able to learn, oh, that's a tiger.


Even though that's not tiger. 1, 2, 3. Right? Yes. So that's learning. But even before the Dartmouth workshop, there were early inklings like Alan Touring's staring question to humanity, can you make a machine that can converse with people, QA with people, question and answer so that you don't really know if it's a machine or a person. It's this curtain setup. Yeah. That he conjectured. So it was already there. But I think the founding fathers kind of formalized the field. Of course, what's interesting is for the first few decades, they went straight to reasoning.


So they were less about learning, they were more about reasoning. They were more about using logic to deduce the red bull yellow ball, blue ball question. So that was one branch of computer science and AI that went to during the years, predated my birth. But during the years of my formative years, without me knowing I wasn't in there. Right. But there was a parallel branch. That branch was messier. It took longer to prove to be right. But as of last week, we had the Nobel Prize awarded to that, which was the neuro network. So that happened again in a very interesting way.


Even in the fifties, neuroscientists were asking questions, nothing to do with AI about how neurons work. And again, my own field vision was the pioneering study about cat mammalian visual system. And Hubo. And Viso in the 1950s and sixties were sticking electrodes into cat's visual cortex to learn about how cat neurons work. Details aside, what they have learned and confirmed was a conjecture that our brain or maum brain is filled with neurons that are organized hierarchically layered.


They're not like throw into a salad bowl. Right. Okay. That means information travel in a hierarchical way Up these columns On your brain. Yes. For example, light hits our retina. Our retina sends neuro information back to our primary cortex, our primary cortex processes. Send it up to say another layer, and then it keeps going up. And as the information travels, the neurons process these information in somewhat different ways. And that hierarchical processing get you to complex intelligent capability. That's a mouse I'm seeing. Yes. If I'm A cat or this tiger's sneaking up on me.


And I think this could be a bad analogy, but you might be misled to think, oh, well a camera can take a picture and then the computer can show the picture so the computer understands that's a photo. But really the camera has broken what it's seen into a thousands of pixels. They are coded with a numerical sequence. The computer reconstructs those colors. It's a grid. And virtually that's what our eyes do. Our eyes are, are just grabbing photons and they're sending back the ones and zeros and then back here in the cortex. It's assembling it all. Yes. And how did evolution assemble us so that we can recognize all this beautiful world? Not only we can recognize, we can reason with it, we can learn from it. Many scientists have used this example is that children don't have to see too many examples of a tiger to recognize a tiger.


It's not like you have to show a million tigers. Right, right, right, right. Two children. So we learn really fast. And as you point out in the book, it took us 540 million years of evolution to get this system. Exactly. So just to finish, so the neuroscientists were studying the structure of the maum brain and how that visual information was processed. Fast forward, that study got the Nobel Prize in the 1980s because it's such a fundamental discovery. But that inspired computer scientists. So there is a separate small group of computer scientists who are starting to build algorithms inspired by this hierarchical information processing architecture.


You build one algorithm at the bottom that's maybe generic. No, it's a whole algorithm. But you build mathematical functions that are layered. Okay. So you can have one small function that process brightness, another that process curvature, I'm, I'm being schematic. And then you process the information. But what was really interesting of this approach is that in the early eighties, this newer network approach found a learning rule. So suddenly it unlocked how to learn this automatically without hand code.


It's called back propagation. And also Jeff Hinton, along with others who have discovered this was awarded the Nobel Prize last week. Okay. For this. But that is the algorithm neur network. Could you think of it as almost a filtration device, which is like this data comes in, we filter out these three key points that then filters up, and then we come to our conclusion at the top of this hierarchy. You could actually, because It's just like all this raw info at the bottom. And then we kind of recombine it into this layer. And then another process filters. Right. Well, it's not a school bus, it's not this, You just keep filtering it. Yeah, of course. You combine it in mathematically very intricate way.


But it is like layers of filtration a little bit. Right. Okay, great. So, and now also, when you find your north star, another thing that's happening at the same time is word now, right? Yeah. This is kind of a big breakthrough for early ai For linguistics. So word that had nothing to do with ai, it had nothing to do with vision. But what happened for my own North Star is that I was obsessed with the problem of making computers recognize millions of objects in the world. While I was obsessing with it, I was not satisfied because my field was using extremely contrived datasets, like dataset of four objects or 20 objects.


I was really struggling with this discrepancy because my hypothesis was that we need to learn the much more complex world. We need to solve that deeper problem than focusing on a very handful of objects. But I couldn't really wrap my head around that. And then again, southern California, I remember that beaterman number in my book is that I read a psychologist paper, Irv Derman, who was up till two years ago, a professor at University of Southern California. He projected that humans can recognize tens of thousands of object categories. So we can recognize millions of objects, but categories are a little more abstract.


Animal food, furniture, German Shepherd Transportation. Yeah, sedan, fighter jet and all that. Yeah. So he conjecture that, but that conjecture didn't go anywhere. It was just buried in one of his papers. And I dug it out and I was very fascinated. I called it the beat number because I thought that number was meaningful. But I don't know how to translate that into anything actionable. Because as a computer scientist, we're all using datasets of 20 objects. That's it. And then I stumbled upon WordNet. What WordNet was, was a completely independent study from the world of linguistics.


It was George Miller, a linguist in Princeton. He was trying to organize taxonomy of concepts, and he feels alphabetically organized. Dictionary was unsatisfactory because in dictionary and Apple and a appliance would be close to each other, but then Apple should be closer to a pair. Oh, I see. Than appliance. So how do you organize that? How do you regroup concepts? So he created WordNet, which hierarchically organized concept according to meaning and similarity, rather than alphabetical ordering. Does word not not lead to the machine that can read the zip codes?


No, it doesn't. What's that called? That's what I meant to bring up. That was Confident convolutional neural network. That's happening as you're getting your idea about the images. Right. We've trained a machine to read zip codes. Basically handwritten zip codes. Okay. So that was Young KO's work in Bell Labs. That was the early application of Neur network in the 1980s and 1990s, where that your network at that time was not very powerful. But giving enough training, example of digits scientists in Bell Labs were able to read from zero to nine or the 26 letters. And with that, they created an application to read zip codes to sort mail.


But its dataset was, I forget it was like a thousand or something. Or wasn't that It was a lot of handwritten digits. Yeah. And common mistakes. They would feed it. Yeah. That dataset was probably tens of thousands of example. But we're talking about just letters and digits. What they had proved in concept you're gonna try to do in images, but the lift for images is so exponentially larger than getting the machine to read. Exactly. By a factor of what I mean. When you lay out what it's gonna take for you to prove this theory you have and you figure out how long it's gonna take, it's gonna take like a decade of you feeding the right. There's some moment where the amount of images you're gonna have to feed this computer to train.


It can't almost be done by the group of you. So I think what you were referring to was the process of making ImageNet. Yes. And that process was once we realized, thanks to the inspiration of WordNet and also Betterman's number and also many other previous inspiration, we realized what computers really need is big data. And that was so common today because everybody talks about big data. You know, open eye talks about big data, but back in the 2006, 2007, that was not a concept, but we decided that was the missing piece.


So we need to create a big data set. How big is big? Nobody knows. My conjecture went with Berman's number. Why don't we just map out the entire world's visual concept? Oh my God. Yeah. Why don't We, and you wrangled someone in that this wasn't even really their North Star. Okay. So Professor Kylie at Princeton, he was very supportive of me. He was a senior faculty. But what was really critical was he recommended his student to join my lab, Ja Den. And Ja was just a, during the headlight as a young first year graduate student, he didn't know what's going on. He got this crazy assistant professor me and told him that we're gonna create a data set that map out the whole world's visual concept.


He's like, sure, yes. You know, I don know what you're talking about, but let's get started. Yes. So he and I went through the journey together. I mean, he's a phenomenal computer scientist and many hoops we jumped through together. It was just a solution that got us through This level of plotting that you were able to take on is unique to you. And I think it's moving here in 10th grade and looking at that fucking dictionary back and forth and back and forth and back and forth, that kind of really unique dedication and unwavering plotting. A million other scientists could have had your idea. But I think it's that thing right there that makes you capable of creating image.


Now. That's a interesting observation. Yeah. It's not, I think we like to think of these things very simplistically. Like, oh, you had a great idea. Who gives a shit? A lot of people had great ideas in graduate School. I do tell my kids ideas are cheap. Yeah, Exactly. Hollywood, someone's like, that was my idea. Oh really? Did you write the script? Did you execute it? Did you cast it correctly? Did you motivate everyone? Your idea is 1% of the equation of a great movie. Yeah. Thank You for Putting it that way. When I reading, you were saying that data is coming in, it feels like, and tell me if I'm mischaracterizing it, the deeper you got into this experience, you were just learning every day it was gonna be harder than you originally anticipated. Yes. It just kept getting worse and worse and worse and worse for years. Right. It was pretty bad.


When I'm reading it, I'm like, I would've quit a trillion times. I'd be like, maybe computing will get to a point. Well, this job will be made easy, but right now it's too hard. How Do you even start something like that? Do you literally just look around the room and you're like, okay, Here we go. Yeah, I'll start with this room and write everything. Well, okay, so first of all, I've had years of training as a scientist. So after you formulate a hypothesis, you do have to come up with a plan. My PhD thesis had a mini version of image that, so I got a little bit of practice. But yeah, our idea was to create a data set and a benchmark to encompass all the visual concepts in the world. So we had to start with WordNet.


We had to figure out what is visual. We have to figure out what are the concepts we need, and then where to get the source images and how to curate it every step of the way. Like X were say we were just way too optimistic at the beginning. Naivete is the best asset you can have. Yeah. Yeah. I was just fearlessly stupid. Yeah, it's a great gift. Yeah. And then we start to hit all these walls and I and other students, but J was the main student. We had to just deal with every obstacle that came. Now science is a funny thing, right? Sometimes serendipity makes a world of difference.


What was really critical was the Amazon Mechanical Turk, the crowdsourcing platform, Amazon, nothing to do with us. We're like, oh, we have all these servers sitting in our data centers and we have nothing better to do. Let's make a online worker platform so people can just trade little tasks A marketplace for that computer labor. Exactly. Which I didn't know it exists. I was in New Jersey, Princeton, and trying to pull my hair out. And then some student who did his master at Stanford came to Princeton and just mentioned it casually. I said, do you know this thing?


That was really, really quite a moment for me. Yeah, that cut this process down by 80% or something? Yeah, 10 x. That was one of the technical breakthrough that really carried this whole project. They're years down the path and they're calculating how much further it's gonna be. And they know they have years and years into ahead until this moment, Not only years and years, the budget hiring undergrads or whatever doesn't cut it. The budget was not gonna cut it. My tenure was the underlying, it was a dicey few moment. Scary. So to fast forward to the end, you create ImageNet and you can feed in a picture of a boy, pett a elephant, and the computer knows that's a boy and that's an elephant.


Might be a different size than the other elephant I saw, but I know that's an elephant. And this is huge. This earns you the title of Godmother of ai. I know you don't have to comment. I know you don't want that. And I want to fast forward now you've accomplished this incredible thing. You teach at Princeton for a while, as you say. And then you take up a teaching position at Stanford where you still currently are. You become one of these people that undergrads would then study about, which is fascinating. And you go to work for Google during a sabbatical for like a year and a half. Yes. And there's a moment where part of your job is to go meet with the new recruits that are gonna start their employment at Google. Yes. Is it fair to say this is one of your, I don't wanna call it a crisis of conscious, because that would be too strong, but how would you say it?


You have an opportunity to talk to those people and it sounds to me like you went rogue a little bit. Yes, I did go rogue a little bit. Yeah. So It's very important to call out the year. My sabbatical at Google was 2017. In 2018. That was my first sabbatical. I finally had a sabbatical and it was a conscious decision for me to go to Google. 'cause this is right after AlphaGo. So AI was having its first hype wave, at least public moment. And Silicon Valley, of course, was ahead of the curve and knew AI was coming. So I had multiple choices, but I really wanted to go to a place for two reasons. One is to learn the most advanced industry, AI and Google was by far the best, but also to go to a place where I can see how AI will impact the world.


And Google Cloud was a perfect place because cloud business is serving all businesses. So at cloud, being the chief scientist, I was able to see the technology translating to product and product impacting healthcare, hospitals, financial services, insurance companies, oil and gas companies, entertainment, agriculture, governments and all that. But in the meantime, it was confirming my hypothesis that this technology has come of age and will impact everyone. It was the first tech lash. 2017 was right after Cambridge Analytica.


Let's remind people. So Cambridge Analytica figured out how to maximize Facebook politically, and people were very upset by that. Yeah. Social media's algorithmic impact can drive societal changes. It was also around the time face recognition bias was being publicized for the good reasons of calling out bias. It was also around the time that self-driving car accidents start to happen. So before that, tech was a dar, the media does a report tech as a force of badness. But I do want to point out, 'cause I heard you pointed out, which is in the early advancements, it had all these peaks and valleys ai and there was a moment in the seventies where it looked promising and immediately people went to robots, were gonna take over the world.


So we also do have this immediate sense. We do jump to that. They jump to it in the seventies. It's worth pointing out. That's True. Hollywood is always ahead of the curve on that. Okay. Yeah. Well, we sell fear and excitement, so. So it was a tech lash that came at us very fast. And Google has had its own share. I was actually also witnessing the struggle that Google was coming to terms with defense. Yeah. They had taken a contract to develop some drone phase recognition stuff, and the people at Google were told that they were only working on nonprofit stuff. There was a bit of a revolt. And you were there during all that, Right? Yes. In hindsight, it was a mixture of many things.


It wasn't a single event. I remember it was summer of 2018 and we were just coming off this turmoil. In hindsight, they're small. But yeah, at that point, and I was just like, I'm about to speak to, maybe my memory is wrong, but I thought it was several hundred interns from worldwide who worked at Google that summer, and they're the brightest from the whole world. And they were hand selected by Google. You know, Google is really a machine of talents and what do they wanna hear from me? Of course I can talk about come work at Google. That's my job as someone who was working at Google.


But I felt there was more I should share really coming from the bottom of my heart at that point. Something that you'll appreciate is that the math behind technology is cling, but the human impact is messy. Technology is so much more multidimensional than equations. Yeah. They're all benign. It's how we implement all neutral. They're neutral. There we go. But Once they start to interface with the world, the impact is not necessarily neutral at all. And there is so much humanness in everything we do in technology and how do we connect that? I decided to talk about that with the interns.


And is this the first time you articulate that you want a human-centered development of ai? Yeah, It was around that time, 2018 March, I published the New York Times op-ed. I laid out my vision for human-centered ai. So let's parallel your speech to the interns and then also getting to go in front of Congress. So what is your overarching sense of how we keep this technology going in a direction that does serve humans? My overarching thesis is that we must center the value of technologies, development, deployment, and governance around people.


Any technology, AI, or any other technology should be human centered. As I always say, that there's no independent machine values. Machine values are human values, or there's nothing artificial about artificial intelligence. So it's deeply human. So what are the practical things we do? What are the legislative things? What does that mean? How do we do that? So centered AI should be a framework, and that framework could be applied in fundamental research and education. That's what Stanford does. Or creating business and products that's Google and many other company do. Or in the legislation and governance of ai, which is what governments do.


So that framework can be translated into multiple ways, fundamentally is to put humans dignity, humans wellbeing, and the value that a society care about into both how you create AI or how you create AI products and services, or how you govern ai. So concrete examples. Let me start from the very basic size upstream at Stanford, we created this human-centered AI institute. We try to encourage cross-pollinating interdisciplinary study and research and teaching about different aspect of ai, like AI for drug discovery, AI for developmental studies, or AI for economics and all that.


But we also need to keep in mind, we need to do this with the kind of norm that reflect our values. So we have actually a review process of our grants. We call it ethics and society review process, where even when researchers are proposing a research idea to receive funding from HAI, they have to go through a study or a review about what is the social implication, what is the ethical framework? And are you bringing in philosophers? Yes. And anthropologists and psychologists. Yes. This is the interdisciplinary aspect. That's the Very fundamental research example. Now translate to a company, when we think about a AI product, let's say I would love for AI to detect skin condition for diseases.


That's a great idea. But starting from your data, where do you curate data? How do you ensure data fairness? So if I play out that experiment, it's like, yes, I would love to take my phone, scan my face, and know if I have a melanoma. That's all. Sounds great. Where does the results of that get stored? Does my insurance provider have access to that? What all happens? It's not just me that's gonna find out I have this melanoma. Exactly. What about the scan of the face and also the algorithm that detects melanoma is a trained on Just white folks? Yes, exactly. Narrow type of skin or all skins. What's the impact of that algorithm? Well, It disproportionately help some group alienate another.


And do you Have to pay? Because if you pay, you'll probably get a certain group more than you'll get another Group, right? So all this are messy human elements. And then you ask about legislation, then we come to government. Of course, there is always a tension between how much regulation, how do you regulate, is good policy only about regulating. For example, I firmly believe we actually should have good policy to rejuvenate our AI ecosystem to make our AI ecosystem really healthy. For example, right now, the gravitational pool is that all the resources, the data, the computation and the talents are all concentrated in a small number of large companies.


It's all for commerce. Yeah. Universities can't really compete at The level that Not at all meta. Google, my own Lab at Stanford has zero Nvidia H 100 chip. There you. There you go. Yeah. Like that's always been the good corrective mechanism we've had. Societally is the world of academia. Yeah. And it competed pretty robustly with any private sector. And it's not just competition. It is that the problems we work on are Curiosity driven. And sometimes they are really public good. For example, my own lab, we're collaborating with hospitals to prevent seniors from falling. That is not necessarily a commercially lucrative technology, but it's humanistically important.


Yes. And universities do all kinds of work like that. Now, our universities in the age of AI is so under-resourced that we cannot do this kind of work. I have been working really hard in the past five years with HAI, with Washington dc, with Kroger's people, senators, white House agencies to try to encourage the resourcing of AI through national AI research, cloud and data. And then we have legislation and regulation. How do you thoughtfully put guardrails so that individual lives and dignity wellbeing are protected, but the ecosystem is not harmed.


So all of this I'm always on board with. I love it. I'm so grateful there's people like you pushing us in that direction. But we just had Yuval Harra on to talk about his take on it. And what I ultimately get so discouraged and defeated by is we're not doing this on an island. We're doing this while many other countries do this simultaneously. So how do you see us dealing with the competitive nature of these AI technologies emerging? And us may be proposing we're gonna do it in this way, but being realistic in saying, well, Russia might not have those guidelines and China might not have those guidelines. And if they have a product that people like, we can't compete now with it. So do you believe there could be cooperation?


We could outlaw faking humans. Okay. So the US has outlawed faking humans. No one else does. And those fake humans are really convincing and entertaining and all these things. And then that industry takes off somewhere else. Like how do we do this in a world that there are no barriers of this technology? I was also chatting with JoVE. Did he give the C minus grade to humanity? Did he say that? I think I didn't get the C out of him. He said that humanity has gotten a C then. And I was like, you, you know, I'm a teacher and a mom. When a kid comes home with C, you don't throw the kid out. We help the kid get better. So first of all, you are right. We're not living a vacuum.


And AI also is not living in a vacuum. AI is just one technology that's among many. So I absolutely do believe that there can be cooperation. How exactly we cooperate, who we cooperate with, and what are the parameters of cooperation, is much, much more complicated. Look at humanity. We have gone through this so many times. I mean, you've always right? We have many messy chapters, even nuclear technology. But we have gotten to a state that there is a fine balance at this point of nuclear powers. I'm not saying that's necessarily comparable.


I think it is. And then I think what's really important, and I only know this 'cause I'm on my second Von Neuman book, but Von Neuman was employed in the wake of the Manhattan project to deal with how this proliferation was gonna work. Yes. And he was so analytical and so realistic that he said, mutually assured annihilation is the solution. He knew that was the only outcome. It felt sociopathic to say it and to commit to it. But he is like, look, I'm modeling this out. This is the only way it works. It's mutually assured annihilation. That's what we ended up with. And so I'm having a little vannoy feelings about like, no, I think it's a race to who can win until everything gets neutralized. I don't know another comp other than the nuclear arms race.


Well, Here's the difference between AI and nuclear technology is AI is so much more an enabler of so many good things. True. So that's very different from nuclear. Of course nuclear can be a energy. We're coming back around to it. Yes. Right. But AI can help discover drugs. AI can help breakthrough infusion. AI can personalize education. AI can help farmers. AI can map out biodiversity. So AI is much more like electricity than it is like nuclear physics. So that's the difference. So from that point of view, the viewing angle of ai, at least I do not think it has to only from the competitive lens, because it should be also through the enabling lenss, the enabling of our world of so many good things that can happen.


And that's the challenge is how do we keep the dark use of AI at bay? How do we create that kind of balance somehow, but in the meantime, encourage the development of AI so that we can do so many things that's good for people. So I accept that the nuclear analogy falls short in that there's so many benefits to this. Totally agree. But I will say, again, to parallel nuclear arms race in this moment in time, I think it would be only the second time where international cooperation is at its peak where it's most needed. We have got to recognize this as a moment where we have to be getting closer to all these places and not further away.


Our competitors are geopolitical adversaries that if ever there were a time where everyone stands to gain other than the nuclear arms race, this is the time where it's like we gotta really figure out how to cooperate a bit. Because everyone will experience the downside if we don't. Yeah. The Climate two would be the other more recent thing. There's a Paris Accord and there is things that globally people have come together. I Agree with you, but I will just say that climate to me is a little dicier simply because you have all of these burgeoning industrial economies that we would be slapping rules on. It's easy for us to adopt a lot of things that it's not for Sri Lanka, it's not totally fair.


There actually should be areas of the world where they are allowed to pollute more as they pull themselves. You know? Like Yeah. I Mean I think that's part of it. Yeah. It's just an acknowledgement globally that we're all gonna have to do something. And especially the superpowers do need to take more on than others. But it's just getting on the same page that I think we've done okay at. Yeah. And at least there's some consensus there. So there could be some consensus here potentially. Yeah. I just hope that we recognize this is a moment to be making friendships a lot better and not doubling down. I do think we must always recognized cooperation is one of the solutions. Do you get to the guardrail point in the conversation with the legislators? Do you have certain we do guardrails that you believe should be like I like you've all, you've all said we shouldn't ever be able to fake humans.


And I also think there should be a disclaimer on all AI generated things that you at least know it came from that source. I do think we should pay a lot of attention on where rubber beats the road. Because AI can sound very fancy, but at the end of the day, it impacts people. So if you use AI through medicine, then there is a regulatory framework. For example, my mom again does imaging all the time. 'cause the doctors have to use MRI, ultrasound, you name it, to monitor her. Honestly, do I care if that MRI is fully automatic or is it operated by humans or it's a mixture.


As a patient family, I probably care more about the outcome. If the result of the MRI can be so accurate. 78% of an AI or a human does it at 40. It's a no brainer. Exactly. But all I care are two things. One is it is the best result my mom can get. Second is it's safe. Right? I don't care if it's that kind of mixture. So that regulatory framework is there. I'm not saying FDA is perfect, but it is a functioning regulatory framework. So if there's a AI product that goes into the MRI, I would Like It to be subject to the regulatory framework. There we go. Yeah, yeah, yeah.


Right. So that's where rubber meets the road. The same as finance, environment, transportation, you name it. That's a very pragmatic approach. It's also urgent because as we have AI products that's entering our customer's market and it takes away from, in my opinion, the science fiction rhetoric about existential crisis machine over Lord that can stay with Hollywood. Yeah, yeah, yeah. Yeah. I mean, I believe the downstream application is where we should put our guardrail attention at. Right. I really wanna encourage people, even if people have only a cursory or no interest in ai, I really think your book is one of my favorites.


I've read. It's just your personal story as reluctant as you are to embrace it or talk about it is a really special story. Thank you. I mean, what ground you've covered. Do you give yourself any moments where you go, God damn girl we got here. That's very sweet. That's the problem of always chasing after North Star. I, I try to like look forward. One thing I do reflect back is how grateful I am. I'm not here by myself. I'm here because of the Bob Sabella, Jean Isabella, the advisors, the students, the colleagues that I feel very, very lucky. Yeah. There's a lot of sweet people in the world still. Yeah, It's good.


Yeah. It's hopeful. Oh well fei. Fei, this has been a delight. I hope everyone gets your book, the World's I see Curiosity, Exploration, and Discovery at the Dawn of AI. And boy, those lucky people that get to have you as a Oh Man. So jealous teacher. I also love the narrator of your book. Have you listened to it on tape? A little bit. I didn't finish the audio. You didn't finish right. Yeah. It's hard to listen to your own stuff. Well, it's not her. I know, but your own stuff. Yeah. Yeah. I spent so much time writing it. Right. I'm like, do I have time? I should finish my v Norman book. Yeah. And you should read Maniac. Yeah. You got a couple new Books to read. I'm So grateful. You like the book. Oh, I love it. It's just really beautiful.


I love the narrator, but I was having the moment where I was like, I was only introduced to you through this book. I was completely ignorant about you. And then there's a narrator when I was doing research on you, I'm like, oh, we're gonna find out what the real voice is. No, I had that. I felt a little self-conscious because of my accent. Oh really? Because I consider if I should narrat my own book. But I feel like my accent is probably too strong for that. That wouldn't be the reason I'd advise you not to do it. I think it's way, way harder than people think. And there's a lot more acting involved. I've heard some writers narrate their own book. You gotta be a performer. Right. Forget your accent. There's like a performance to be done. Right. And that's how many hundred pages. Yeah. You Also probably need to put your time there.


You have a lot of other stuff around. Don't waste your time on That. Well, I hope you come back and see us again sometime. Much thank much. I'll so much be following everything you do. And thank you for trying with all your might to make this a human centered development. Thank You. It's so important. And I do think creators and creators voices are so important because we started this conversation with what's different from human intelligence, ai and that creativity, the insight is a huge part of it. And now that we have the generative AI trying to create things, I think the collaboration with humans is so important. Yeah. Alright. Well be well. And thanks for coming. Thank you.


Hi there. This is her and Permian, if you like that. You're gonna love the fact check Miss Monica Imani. Hi. We had so much fun yesterday, didn't we? We did. We I did. I did. We shot a commercial. So much fun. So much fun. Yeah. I had a really fun full circle moment. Okay. Yes. Please tell because I got out of the car. You know, I haven't acted in a while. Sure. We're, we're ball rusty. Yeah. I got out of the car and I started recognizing some of the people on set and I realized I had worked with a lot of that crew on some commercial previous commercials in my day.


Sure. One of the many, many thousands of commercials you had done. Done. It felt so nice and, and cool. Like I, you know, I'd be, I had done these commercials as just this actor auditioning and doing this thing. And now we're doing a commercial Where they asked you to be in it. Yeah. Before And we're doing it together. Yeah. Not for this podcast, but, But because of this podcast. Yeah. Yeah. And it, there was something really cool about it. I agree. I liked it. And it, I think it's 'cause my ring is fixed. I have some housekeeping. Okay, great. You know, I read the comments and so, and this is so embarrassing, and I read it a couple times. I'm like, these people are crazy. That's, I, I didn't say So people were like you said, the wrong voice of Darth Vader in the Morgan Freeman intro.


And I thought they were saying, I had said Morgan Freeman was the voice of Darth Vader. And I'm like, I know I didn't say that. 'cause I know he's not. And James Earl Jones was the voice of Darth Vader and I said, Edward James almost. So I did say it wrong. It was another three name copy actor with an Edward in it. I see. Yeah. That's hard. So I fucked that up in my apologies. Oh. And then the other thing was they had quite as interrupt us. 'cause we were chatting and I was gonna say, I, I had, I was gonna give a Danny Ricardo update 'cause I had ridden motorcycles with him. Oh. But I guess then we got sidetracked and I never did. So all these people who are rightly concerned about our sweetheart, Danny Ricardo, how he doing, were left hanging.


And I'm here to report that he's so happy. Yeah. He's doing great. He's so, so happy. We were riding motorcycles for all day long and we chatted a bunch and, and he said, he's just very, he's just very happy. I'm glad. Yeah. He's just, he's just doing really, really good. So people should rest assure that Danny Rick is thriving. Yay. Yay. Love to hear that. Yeah. Do you wanna tell people what Toto texted you? It was so funny Is I had text him to say, Hey, people really loved the episode. And me in particular, I really loved it. Thanks for doing it. And he said, how are the numbers?


You know, I am a lap time guy. Oh. So playful. Oh god. God, I gotta say, I wanna say out loud, that really put a lot of wind in my sails. That made me so happy to have that episode come out. It, it really rightsize my perspective as I've vocalized on here. It's been a challenging transition. I've been really stressed. Yes. There's been bad news and challenges and this came out and I was like, oh, right. Dumb ass. You get to meet people that you are obsessed and in love with Holy Lottery. Yeah. I just was, I was, I was beaming all day Wednesday from it. Yeah.


It was a great episode. And so yeah. Just so cool. We get to talk to anyone we wanna talk to. Not anyone. I still have a list. We still got t Liquid Death. I'm just pointing to objects Monkey with huge balls. No, we already had Machine Gun Kelly. We did. We did. Okay. There's another fun update. But this, I'm starting, I'm getting worried that people are gonna be afraid to text me. I guess these people should know. I run it through my analysis. Okay. And I would never say anything that was in a text that I didn't think was just lovely. You know what I'm saying? So I get worried about it. I know. Don't you like, you know, someone's got a private exchange with me. Yeah. And then I'm reporting on it.


There's an ethical dilemma here. Sure. But sometimes they're so funny and I think the person would Like It Anyways. So I sent Pit the clip of Toto talking about, oh, me telling him that Pitt said he was a good dancer. And then Toto talking about him coming to dinner. Yeah. And then he's, he said, I made up the thing about him being a good dancer. And I said, Oh no. I said, I can't believe you made that up. In fact, I don't believe you made that up. I still believe he's a great dancer. Yeah, me too. But he did say, because Toto was like, how, when did he see me dance? I know. But then he just had to, he had to go, well, I don don't understand how that happened, but I'm gonna take that.


He was just, he's being funny. He was doing a yes. And He was doing a bit. Yeah. He was like, you're not gonna believe this. He's also a phenomenal dancer, but I he is just with him. I believed it. Yeah. I think the, Who wouldn't believe it? The Crux of that story is I'm gullible. I think he is a great dancer. Can we talk about charisma a little bit? Sure. I got the fever as much as I've ever had it. As hard as I've ever had it. Let me tell you what's happening. So, so far from our homework. Yeah. We watch Christmas vacation already. Home alone. One and two. Side note, I've never heard Delta laugh harder in my life than the 27 minute set piece in home Alone. Two where he's hitting the guys with bricks. Oh, sure. She was laughing uncontrollably for like 27 minutes.


She said at one point it doesn't get old. Like they threw a fifth brick or whatever. Yeah. And she's Like, It doesn't get old. And IWI, there's, I got so much joy out of watching her have Aw, that big of a laugh at something. So cute. Okay, so Home Alone two, we did Gremlins, another Christmas favorite for us. Okay. Last night we did The Grinch Who, so Christmas original cartoon. And I want to go out and say for the record, it's the number one Christmas cartoon to ever be made. It is the most creative. We all watched it and I think end of it. And how many More Christmas cartoons are there? There's a lot. You've got Rudolph, you've got Oh sure. You got the Chuck Brown. Oh yeah. You've got the, there's a bunch.


Okay. But I'm saying I'm, maybe even Christmas. Anything it ends And I said, you know, Dr. Sous should really be regarded as like Salvador Dali. He had such a unique Yeah. Imaginative world. He created in the words, in the upset pieces. And I mean, I, that's one of the most creative people to ever live. Of course. I think he is given his do props. Yeah. You know, there's a Seuss land. There Is. Yeah. One of the parks There is, I think. Yeah. Okay. Seuss Landing in Orlando, Florida. Yeah. In Orlando, Florida.


I should go. You should go. You should pay your respects. I like when people use the term Sian. Did you ever hear anyone use that? No. But I Like It. Yeah. It's cool, right? Yeah, yeah. Like Newtonian or like, it's a, it's a paradigm, But it kind of sounds like Sian. Yes. Which is my favorite word. Which did I tell you My favorite word anymore? You taught me that word. Yeah. And I thank you for that. To remind people, Sisyphus pushed the rock up the hill every day. That's right. There's a Buddhist take that like, si That's was, people interpret that as a story of not wasted effort, but like, you know what I'm saying? Yeah, Yeah. A fool's errand. Yeah. But there's a Buddhist way of looking at it, which is like, this person had purpose every single day, all day long and was not suffering.


Probably. Well, it's a story of suffering, but It was a huge rock. Well, first of all, he's probably Jack be belief Strong. So strong. But that's an interesting way to reframe it. That like, no, this person every day of their life had purpose. Yeah. Probably very happy. That's A lovely way to look at it. Yeah. It's actually Ian. Ian. Yeah. I like Sian. Me too. And I, I'm, I maintain it. Yeah. Okay. So you're in Christmas, the Christmas spirit. Yes. And I wake the girls up every morning. I wake up about 20 minutes before the girls to meditate. And so now I am, they wake up to me playing from my phone over the Sonos Christmas music.


Wow, that's so nice. And I wanna make a great recommendation to people who are using Spotify. And you can make a station, go to the Charlie Brown Christmas album and then go specifically to the song. Christmas time is here, make a station out of Christmas. Time is here. Oh. And it's the best Christmas mix I've ever had. Ooh, That sounds lovely. It's, and it's on all the time. And so, you know, the, the tree is, is over decorated. Yeah. You know, we get one tree and Kristen gets a tree in the kitchen and hers is artistic. Yeah. And this year it's wicked. Oh, Cute. Yeah. And our tree is a throw up of color. And I have those old fashioned bulbs that the water bubbles up in them.


They're almost impossible to get to sit vertical on your tree. I've spent most of my free time positioning all of them. And then they, I pull the cord and they all fall down. It's, it's a ian task. Wow. Ding ding, Ding. I didn't expect it to come around that quick. I had all this anxiety about presents, but I knocked a bunch of presents out the other day. Nice. You, you used a little bit of my, I used gift Guide. Your gift guide almost exclusively. There Were good gifts on there. Complain about your gift guide though. You make things sell out. Your gift guide is moving markets. Yeah. Well, I picked great items. Yeah. I have To say you do, I Have to say you have exquisite taste. Thank you.


Some of your recommendations were so good that I found myself dancing around on the websites. Yes. That's the goal. Yeah. Yep. And yeah, There's fun stuff abound. There's fun stuff. So, So, and let's just, so your tree has colored lights, right? So many. Yeah. And Kristen's, I have four strands, really long strands and four of those bubbly light strands. Sure. And the tree's touching the ceiling. Yeah. It's a Clark Griswold. It's too big. And I'd cut up foot Also. No, I just wanna talk about lights. Oh, okay. Okay. My apologies. Miss Monica. Miss Monica, I'm sorry. I get so carried away sometimes when the spirit moves me, I don't leave my apartment much.


So really enjoy decorating it. Get all his colors. Makes me optimistic. I wonder how Hermia, do you have a, does he have a delivery service? How does he get his tree? I have a cousin who's not working at the moment and he loves going to department stores and plazas and shopping malls and strip malls. Wow. And well, I'll call him on the landline. That's what I have Miss Monica. I pick up the phone and I call his, his name is Burt. Oh yeah. He's my, did I say my brother-in-law or my cousin? He's a cousin. Yeah. He's my cousin. I just remembered, weirdly enough. He's also my brother-in-law, but it's my stepsister. Oh, okay. So it's all, all Up and up. Everything's above board as they say.


Okay. Okay. I call up Bert and I say, here's what I need. Bert six water weenies. Oh, 10 spatulas. And Bert, it takes him a while. Sometimes four or five days. And then he comes over and he, he does charge me a little more, but that's okay. Sure. And then he's doing a lot of work. Then I have to call him back up and ask him to deliver the presents. Wow. That's okay though. He charges me for that too. Okay. Getting little taken advantage of. But that's, you seem, that's fine with it. Okay, great. Mom. No, remember I'm not your Mom. Okay. Miss Monica. Mom. Monica, Mrs. Mom. Color lights. Yes, the lights.


Because Chris and I assume on her nice tree has white lights. Yep. Yep. Yeah. And this is, you know, this is a, a big thing. I don't know if it's Rob. Yes. What color lights do you have? Well, First of all, do you have the lights you want? Yes. Okay. I do. I like the, like yellowy White light kind Of warm gold. Yeah. White lights. That's white. I think there's shades of white too. Like we lights Natalie argue about That. White lights. He's trying to, he's trying GG to walk in the middle and be nice. But really he has, he has white lights. White lights. And he likes them. I have white Lights, but they're kind of yellowy. Yeah, I know what you mean.


There's like a warm and a cool. Yeah. Now listen, sometimes you complain about there being two boys, one girl in this situation. But you have to admit Rob is a perfect middle girl. Yes. Like, if Aaron was here, it would, it would suck. Well, Yeah, but he's, He disproves my gender stereotypes quite a bit. Yeah. Yes. Because Aaron grew up exactly like you, so it's not fair. You just assume it's men because you and Aaron believe it. That's right. Monica. So, that's right. Miss Monica. So yes. Rob did not grow up with you and like you Oh, He's from the big windy, so I don't think it's gender, but I do think some people love the, the nostalgic colored lights.


Yeah. And then other people who care about aesthetics love the white light. I could really get on my high horse about it. I used to have a really strong stance on it. Yeah. And it's all my class warfare stuff. Yeah. Which is, It's so tired. It's, is that what you're gonna say? No, I wasn't gonna say that. Your life does not match that mentality anymore. Doesn't At all. But did you see Chris Rock's latest standup? He said, I am rich, but I identify as poor. Yeah, That's fine. Okay. For him. Yeah. Okay. But for me, and also, yeah. You, you aren't, you're of the highest class in this country. Yeah. Well, there's a lot people with a lot more money than me, but I do have You're Of the highest class.


Okay. Okay. And you, you also hobnob with the highest class. Yeah. But you know what? I act like myself and I have color, here's what I'll say. The white, all white Christmas tree Yeah. Is like, occasionally I'd see that at people's houses who had a, an extra living room that no one went into and you weren't allowed to go in there. You know, take off all your, shoot your, you know, you get in a fucking Intel outfit to go in the room and all of it seems stuffy and not playful and fun and colorful. This felt very presentational. And where's your tree?


But I used to be judgmental of that. Yeah. I don't, I still don't Like It, but I'm not as judgmental because Your, your second tree is in your second living room. Okay. Okay. You know, I gotta keep you, I gotta I gotta just remind you. I Know I'm spoiled. I know I'm spoiled. Yeah. Okay. I'm really spoiled. It's Just class to me, the class warfare thing, I would hope you now see That it wouldn't be fair for a stranger to hate me just 'cause I have money. Yeah, Yeah. Yeah. I, I would feel that way on the other side of it, but I wouldn't expect anyone to feel that way. Not be on the other side of it. Because I get it.


Okay. So I have white lights obviously. Yeah, I know that. I would, I would know that. Yeah. Everyone would know that. You Don't need to tell me that. I know that. Well, and I'm not judgemental of you. I'm, I'm so glad you're having the Christmas you've always wanted. Thank you. Yeah. Yeah. Jess and I had pig day and we went to home. We just missed you, I guess. 'cause we really, it seems like the timing. Yeah. 'cause we were there at like 11:00 AM on a Saturday and you were there at 11:00 AM But I, I gotta say this is my record of all time. I was so fast and there was no fighting. This is like first year and a few that day is very triggering for our family. I think It's hard for families to have to decide. You Gotta compromise. And everyone has their things they care about. And luckily Jess and I have the same thing.


We don't like bald, called bald puss. You call the tree a bald puss. Bald pussy. Bald pussy. If there's bald spots. Okay, great. And we don't like that. Okay. And you Like more of a Brazilian tree? No, Brazilian is, That's shaped in full Brazilian. Yeah. Isn't a Brazilian like you have a landing strip. I Thought Brazilian is clean. Clean Rob. And do I, do you want me to Google? Yes I do. Just Definition of Brazilian wax And pictures. Yeah. Pictures. You can do that on your own time. Sure. You get it removes most of, most or all of the hair from the pubic region, including the front sides back and often the area around the anus.


Yeah. Okay. I'm glad I What's the landing? The landing strip's? Just the landing strip. Yeah. There's like, you can just get different kinds, but Okay. Brazilian generally means all hair. Do you think any dudes get a landing strip? I was just thinking I want to go do that just as a bit. I've Done that as a joke. You have for Natalie. Oh. Oh my God. That's so funny. Did she like, did make her Laugh, Make her horny? No. No. Yeah. It was, it was not meant to be. That's really funny. Stay tuned for more armchair expert If you dare.


Okay, let's take a break from the fact check to thank our presenting sponsor. Amazon Prime. Prime has you covered with movies, music, and everything you could possibly need to make the holidays perfect. Whatever you're into. It's on prime. This is very exciting. It's holiday party season. Yes, it is. That time of year Work parties, family parties, parties with friends, Party parties. Parties with your animals. If you're as popular as Monica, you're hitting the party circuit. It's a great reason to shop for new clothes or accessories and really like, spice up your wardrobe. Make it fancy. Prime can help with that. Especially if you decide last minute you wanna buy something new. You are set with primes, fast free shipping, and hey, what you're buying for holiday parties depends on whether you're a guest or a host. If you're hosting, if you're going deep on Prime to find everything you need to make your home feel fun and festive and perfectly like you. Oh, tell me about it. I really like to make my house feel very me. During the holidays, you could be decorating the outside of the house, getting some lights, something for the windows. Grab some new holiday towels, some festive hand soap. Oh, I love a good festive hand soap candles. You really, you can do it all. Absolutely. And you can get all those things on prime. Oh, and one other thing, Amazon Music is here to help with the playlist. Curating the party playlist. It's an art. Amazon Music will get the vibe right. Listen, what we're saying is, anything you need for a holiday party is on prime. Nice sweaters, goofy sweaters for the ugly sweater party. Holiday decor gifts for the host, or fun small stuff for a gift exchange at work. The sky is the limit. When prime's fast, free shipping is at your fingertips from streaming to shopping, it's on prime. Visit amazon.com/prime to get more out of whatever you are into.


Now, we were also so quick, so quick. In fact, it was almost eerie. We walked in and we were doing just like a quick look. And Jess just beelined. He, he knew his Like this, his vacation, there was a beam of light shining down on it. Yes. And he knew his daughter. Yeah. And it was the one Are You his daughter? Because I think you view more of his mom. No, the tree is our daughter. Oh, okay. Okay. That makes worse. We have, we co-parent. Okay. But she lives at my house. Yeah. So, gotcha. So he's a little bit of a Debbie dad, but whatever. And she's really pretty. She's so nice. Mm. She's, we said, 'cause last year archery was a boy and he was a model.


Oh. Like he was gorgeous. Striking. Was striking. And, and very sim like perfect. Angular. Exactly. Not interesting. Very angular, not round features. This girl is, she's not a model, but she's a star. Oh yeah. That's my, that's the kind I like. Exactly. And I've been trying some different hats on her toppers. Oh, okay. Hats I haven't decided yet. Is there no part of you that feels sad? Like what I really, the softest spot in my heart I have is for Charlie Brown's Christmas, when they get that really bad tree, Charlie Brown did a bad job and they hated the, they're yelling at Charlie 'cause of the tree.


But then they decide to love it. And it's a good little tree. It's A sweet story. And I always am drawn to the shitty tree there. 'cause I think no one wants this tree. And we'd have a great Christmas with this tree. I have a real, I get emotional about it. Wow. Yeah. I wanna like rescue this shitty tree. Oh my God. You're, the way you feel about the trees is like how Kristen feels about the dogs. That's right. That's right. And all because of Charlie Brown, I think. Wow. So, yes. So the girls have one agenda, which is to never like the same tree, of course. I think as their agenda. And then mom has an agenda. Mom's very aesthetic. You know, it's very important to her. So for Her trees are not dogs. She wants a pretty one. Yeah. Yeah. Like me. She got something in her mind. She's looking for.


Yeah. My singular goal is when you pull into Home Depot, you can either park and then go by the tree and then enter the line Yep. To pull up where they'll put the tree in and all I want to just pull into the line and know that they can get that tree fast enough that by the time it inches up to the front, we'll have gotten a tree. So my only objective is to get the trees in time. By, by time I'm pulling the Truck. Because in the truck, because stay in the Car. No. In previous years they go in and I wait. Okay. In the car this year I went to, so What'd you do with the truck? I Just parked it and I'm like, I'm gonna run in, I'm gonna see if I find a tree, it's not gonna move up that fast. They gotta load a tree. I didn't hold anyone up.


Okay. And then we got the trees by the time I pulled up. So that was my goal. Okay. Mine's way less aesthetic and way more time management. Yeah. I don't feel bad for the, for the You don't. I don't. How could you not? Well, a tree that no one wants Monica. It's Already dead. Dex is already dead. It got chopped down. I, I always get a tree that has a little bit of personality. And by personality I mean missing parts. Bald puss. Miss Monica, I don't know what you just said, but please don't say it again. You want talk about size? I'm here to buy a big old Christmas tree.


Tell me about your tree. Oh, does it have a Brazilian? Ew, what? Stop. What do you put on video? Make Em go away. Make em go away. I can only take, I can't, I I for kind of forgot. He sounds Though, like you guys are very Fritos. When you're shopping for this tree, you're just not doing the voice. Talking about ball. I don't even wanna say it either. Oh my God. And you're saying it's your daughter. This is twisted. Certainly don't want Jess talking about his daughter in that fashion. No. Last update. It was time for a crop, A harvest. Everyone already knows that. I feel like people are gonna have a bunch of judgment about this. I guess. Fuck them.


Delta's like, I wanna shave my legs. Will you shave my legs? Yeah. I'm like, okay. People are gonna be like, you shouldn't shave your kids' legs. I can already feel that coming, but I don't give a fuck. She wants me to shave her legs. Yeah. Why not? She feels left out. I did it. Okay. Monica, her leg hair is also cashmere. It is. So we now have two fields in rotation. And so I want you to see what an enormous are you Combining? Yes. It's now father daughter cashmere. Oh. And I want you to, you remember how much we had just Yeah. Not practically none. Wow. At the amount of cashmere we now have.


Wow. It's, it's like quadrupled in size. I, I was making a joke that we might get a mitt or a scarf in 10 years, but I actually think that's a real possibility. Now look at the amount in there. Now. This Is really, you know, what? Do you want to feel heard? I do. Okay, go ahead. Okay. Do I wanna touch it? But also I, last time we touched it, Some of it disappeared. Yeah. That's okay. Now we got two growers. Wow. There's so much. Yeah. Now you have two growers. We got basically a mink farm. Are They separated? These? There's no real. Okay. Yeah. It's just, I think it's separated on. Wow. It's so soft. Yeah. I think hers might even be softer than my back hair.


Oh my God. But that's got a time limit. Her leg ha work. Exactly. Will turn into shitty hair. Like our leg hair. Exactly. But currently she is growing cashmere. Oh my God. You think I need to get a work permit for her? Because she is now kind of acting Probably illegal. It's like, yeah, it's illegal. Yeah. I don't, I don't wanna out her. 'cause she did such a great job link and shaved my back. Did a great job. Yeah. But she was, she thought she had some cashmere on the razor and she emptied a little bit into our pouch. And then I discovered no, that, that, some of that was beard hair. So I had to actually go in and pull. And now I'm getting embarrassed. It sounds like a bit, but then you realize, no, it's not a bit. He's really, that happened.


Did you use tweezers? No. I just, I could feel and I'd pull that out. Oh, wow. I probably lost a lot of really good products. I know. That's okay. Yeah. We live And learn. This is an r and d situation. It's only The second harvest, so. Wow. Still learning a lot. It's so Exciting. All right. Oh, oh. One more thing. One, one cool thing that happened that I wanna put out there in the world. 'cause I think it's good for me to manifest this. Okay. When Kelly and I were shopping, we went into one store and I bought some cute little boxer shorts. Okay. As we were leaving, Callie was in front of me and someone had held the door open for her to come out. And like some woman walked in and then Callie walked out.


And then he, this person continued to hold the door for me. And I was like, oh, thank you. And then I kept walking. Is it, I, I don't know. He's a mystery man. Oh, Oh, oh, oh, Okay. And he, It looked like the look on your face was that it was a famous person. It was the most Gorgeous, Gorgeous person I've ever seen. Really? And not And male or female? Male. Well, gimme age, height. Describe He is kind now, he's like, build it for me. But now he's sort of a haze. Oh. Like, I don't, I don't remember. I don't like That part. I know, I know. But part of it was, I, it, it happened so fast.


He took my breath away. Yeah. And, and I think it read, you know, it read. Okay. Your face betrayed you. Yeah. And he smiled. And I don't remember if he showed teeth or not flirting, but no, he just like, that's who he is. Okay. And I turned, you know, I, I turned and I said, oh my God, that guy was so hot. And she said, I know Kelly was fucked up too. Yes. So we, so this is an undeniable situation. You should have gone back inside to talk to the third woman who entered. Well, I think they were together. Oh. Well, I don't know. Okay. There's no way to know. So this is a lost person's report. Exactly. If you opened a door for Kelly and Monica at the farmer's market.


Brentwood Country Mart. Brentwood Country Mart. Yeah. On Black Friday. On Black Friday. Probably around noon. Okay. Yeah. Contact, I guess comment in this. I, I'll read it. I'll read 'em all. Okay. Comment or don't, No. Catfishes. Exactly. I Guess you'll be able to see the photo though. And you'll know I'll Re Oh, I'll know. And No one could fake it. No. Because you know, when I walk through the world, I'm extremely unobservant. I don't notice people. You're basically, I really am. Yeah. And speaking of blind, I got some soap in my eye this morning and it was Blinding. I thought I, I was, did some permanent damage. Of course. Okay. So anyway, I walk around so unobservant and yet this person penetrated strong.


He pulled me out. It was shocking. He's like a lifeline. He was, he was so attractive. How many more times did you think about him? Later day. That day. Yeah. That day. A lot Of times. A ton. Yeah. Did you like whip up fantasies? I know you're prone to fantasies. I'm prone to fantasies. I, I didn't actually, I was more just like Thunderstorm taken. I Was just taken Love at first sight A little bit. Oh my God. And I don't even believe in that, but like, maybe. Anyway, that was a big mystery. Yeah. Wow. And I wonder, and how often have you thought of him since then? Daily or once every few days? No, it's starting to dissipate. Oh. And I don't remember him myself. I Sure hope he reaches out in the comments.


Me too. Also, no bullshit. No catfishing. Yeah. Guys, seriously. Stop catfishing everybody. Seriously. Okay. Anyway, so that, we'll add that to the mystery pile with the guy I met at in New York, the restaurant guy. Oh, right. That mystery is awesome. Catfish Is so delicious. Did you ever eat a big catfish sandwich? Monica? I don't give him permission to say my name. What do you want him to call you? I Don't want him. Don't leave it. Don't let, let him decide. Okay. This is for Fefe Lee. Oh. And a ding, ding ding. We just just interviewed someone who knows her intimately.


Yeah. You not intimately. Yeah. That means sexually. He, the colleague, we just interviewed a colleague And he was giving her a lot of props and reverence. Yes. Yep. That she really deserves. She was, I loved her so much. I Loved her so much too. She was a delight. Yeah. Now some facts for her. How long did Einstein live at Princeton? He lived in Princeton, New Jersey for 22 years. From 1933 until his death in 1955. He purchased a house at one 12 Mercer Street, which became his home until his death, the house was for him, his wife, Elsa, stepdaughter. Margot and Secretary Helen Duces, His secretary lived with him. I guess. So.


Interesting. I bet it's more like an assistant nowadays. We'd call it an assistant. You're probably right. Yeah. I guess secretaries were just assistants. Okay. Oh, we talk about Cambridge Analytica, which was the whole thing that happened with Facebook. I encourage people to listen to acquired the podcast, acquired they do an episode on Meta. Fantastic episode. Yeah. And they talk about what happens with the Facebook Cambridge Analytica scandal. And a lot of, it's very misunderstood. A lot of what the public thinks you are missing. We're all missing a ton of real, of information. It's kinda like a Martha Stewart thing. Exactly. Well we all think she traded her company.


Exactly. And that's didn't not what it was Didn't where did she even do any insider training? I know she still went prison. I know. Yeah. But yeah, the nefarious activity was on the, was on Cambridge Analytic, not meta. Right. But also they, and They were just using existing tools that anyone could have been using, But they were using old information from an old quiz Or Quiz or something that Facebook did a long time ago. And that's what they used. Oh, okay. They weren't using current information and Yeah. They like Facebook didn't sign off on, they didn't hand over this information. Yeah. Everyone should listen to acquired just period. It's such a good podcast. It Is, it is.


I'm always shocked. Yeah. If you like a deep dive, that's the show for you In the business world. Yeah. Like learning. I mean, you listen, I mean they're four hours long, this medal six. Yeah. They spend a month researching a company and then they, they just tell you everything about the business and how it came to be and all of it. And you do leave feeling like you went to, like you took a course in Business. Oh, big time. Yeah, yeah, yeah. I recommend acquired. And that's it. That was it. Yeah. Okay. I just adore. I wish her the best. Me too. I'm grateful for Me too. Yeah. That's the line we learned from the Lisa Kudrow fact check that we say to people that I'm just grateful for you. I'm grateful you exist.


Oh yeah, yeah, yeah, yeah, yeah. Now we know. And I'm grateful for her existence. Yeah, me too. Okay. And Toto iss a great dancer. Don't listen to anybody else. You's great. Love you. Love you.