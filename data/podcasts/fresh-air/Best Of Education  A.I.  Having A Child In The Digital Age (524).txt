
This message comes from Capital One. Banking with Capital One helps you keep more money in your wallet with no fees or minimums on checking accounts. What's in your wallet terms? Apply. See capital one.com/bank for details. Capital one, NA member FDIC.


This message comes from Square. You probably know Square from your favorite local spots, but you might not know that there's a lot more to Square than meets the eye. What started as a little white card reader is now being used to rapidly scale build loyal followings, cover cashflow gaps, and expand to new locations wherever your business is growing Square meets you there. Go to square.com/go/npr To learn more


From WHYY in Philadelphia. This is Fresh Air Weekend. I'm m Tanya Moseley. Today, New York Times tech reporter, Kir Hill returns to the show to talk about a surprising twist and who is using generative ai. Colleges and universities have been trying to fight against students using tools like Chat GPT to do class assignments and communicate well. Hill's latest article reveals how professors and educators are now turning to AI to prepare lessons teach, and even grade students work. Also, New York Times writer Amanda Hess talks about motherhood in the digital age, navigating a world where apps, surveillance tech, and a relentless stream of algorithmic advice have become par for the course of pregnancy and parenting.


Plus, David Bian Cooley reviews one-to-one, a new documentary about John Lennon and Yoko Ono that's coming up on Fresh Air Weekend.


This message comes from Saatva. Sleeping well can boost your mood and improve focus. A Saatva luxury mattress can help you experience that kind of sleep. Save $600 on $1,000 or more at Saatva dot com slash npr.


This message comes from MIDI Health. Women in midlife face a healthcare desert, but MIDI is here to fill the gap, offering expert care for perimenopause and menopause covered by insurance, hot flashes, insomnia, brain fog, weight gain, and moodiness. Don't have to be accepted as just another part of aging. MIDI clinicians understand how these symptoms can connect to menopause and prescribe a wide range of solutions. Book your visit today@joinmidi.com. That's join mi di.com.


This message comes from MIDI Health. If you are a woman over 40 dealing with hot flashes, insomnia, weight gain, or brain fog, you don't have to accept it as just another part of aging. The clinicians at MIDI Health understand what you're experiencing and know how to help. MIDI Health provides specialized care for perimenopause and menopause covered by insurance. Book your visit today@joinmidi.com. That's joinm idi.com.


This message comes from Capella University. At Capella, you can earn your degree with support from people who care about your success. A different future is closer than you think with Capella University. Learn more at Capella dot edu.


This is Fresh Air Weekend. I'm m Tanya Mosley. We are living in the age of ai and for a while now, chatbots have been helping students take notes during class, put together study guides, make outlines and summarize novels and textbooks. But what happens when we start handing over even bigger tasks like writing entire essays and work assignments and asking AI to help us figure out what to eat and how to reply to emails while professors say more and more students are using generative AI to write essays and complete homework assignments. One survey by Pew Research found that about a third of teens say they use it regularly to help with schoolwork, but it's not just students.


Professors are also using generative AI to write quizzes, lesson plans, and even soften their feedback. One academic called Chat, GPTA calculator on steroids. And universities are working to establish guidelines and using software to track AI use. But some students are now pushing back on that saying that many of these detection tools are inaccurate. Well, today we're joined by New York Times tech reporter, Kir Hill, who has been tracking how AI is reshaping daily life and the ethical gray zones it poses. Last Fall Hill actually used AI to run her life for a week, choosing what to wear, eat, and do each day to see what the outcome would be.


Hill is also the author of Your Face belongs to us, a Secretive Startup's quest to end privacy as we know it, which investigates the rise of facial recognition tech and its disturbing implications for civil liberties. Cashmere Hill, welcome back to Fresh Air. Hi Tanya. It's so nice to be here. You know, I was talking with a professor friend recently who said he really is in the middle of an existential crisis over ai. He teaches a writing intensive course and he actually worries that with these tools. His job might not even exist in a few years. And so I wanted to know from you, can you give us a sense of just how widespread the use of this generative AI is, how it's become kind of a commonplace on college campuses in in schools?


Yeah, I mean this has been going on for a few years now. Basically ever since OpenAI launched chat, GBT, you know, students are using chat GBTA lot to ask it questions, to answer problems, to help write essays. And I talked to professors and they told me, you know, they're very sick of reading chat GTEs, because individuals think when they use this tool it makes them so smart, it helps them, you know, get such great insights. But for the professors that are reading this material, it all starts to sound the same. That's Because there are words and phrases that are used so commonly that then they become part of the generative AI and it spit back out.


Yeah, exactly. There's certain words that uses, it's also just the formatting. They said it has a certain way of doing paragraphs where it'll have one sentence that's, you know, short and then one that's long and one that's short. It, it really does feel like there's a model for how it writes and they're seeing that model coming from all of these students instead of hearing their, you know, their distinct voices and their distinct way of thinking. And yeah, they, they are doing a lot to try to encourage students to think for themselves to maybe use the AI tools but not turn over everything to the tools. You know, this isn't surprising to me because people, especially students always are trying to find a shortcut. Plagiarism has always been an issue in academia, but the stories we are hearing are kind of astounding.


Yeah, I mean one of the, the greatest pieces I've read on this is by New York magazine came out this month and it was called Everybody is Cheating Their Way Through College. And you know, they had all these interviews with students where they're saying, you know, I'm not totally dependent on chat GBT, but I do use it to figure out what I'm gonna write, how I'm gonna structure it, maybe write the lead of the paper for me. It, it sounded to me almost like a Mad Libs version of college where you're just kind of filling in the blanks a little bit in thinking around what chat GB BT is doing. Your latest piece kind of turns the tables because you took a look at how professors are using generative AI to teach and what did you find?


Yeah, this story started for me. I got an email from a senior at Northeastern University who said that her professor was misusing AI and she sent me some materials from the class. She was reading lecture notes that he had posted online and found in the middle of them this kind of query this back and forth between her professor and chat GBT. The professor was asking chat GBT provide more examples, be more specific. And as a result she had looked at PowerPoint slides that he had posted and she found that those had all these telltale signs of ai, kind of extraneous body parts on office workers. This was a business class, Like extra fingers on a image, stuff like that, An extra arm, you know, distorted text because these systems aren't very good at kind of rendering pictures of text, kind of egregious misspellings.


And so she was upset. She said, I'm paying a lot for this class. The tuition for that class was around $8,000. And she said, I expect kind of human work for my professor. I don't think it should be ai. And she had filed a complaint with Northeastern and asked for her tuition for the class back. And you know, at first I wondered is this a one-off or is this something that's happening on other campuses? So I started looking at places where students review their professors. The big site is Rate My Professors. And I noticed that in the last year there had been this real spike in students complaining that their professors were overly reliant on AI using it to, you know, make materials for class, make quizzes that didn't make sense, give assignments that didn't have actual answers because they were broken.


'cause these systems are not always perfect and using it to grade their work and give them feedback. And the students were really upset. They felt like it was hypocritical because they had been told not to use AI in many cases. Right, right. And yeah, they also felt shortchanged like they're paying for this human education and then they were getting AI instead. One of the complaints on Rate my professors was, it feels like class is being taught by an outdated robot. Wow. You know, where is the learning in this? And I'm just wondering what professors are actually saying. I mean, I guess a big part of it as you write in this article seems to be a resource issue. Some professors are overworked, others have multiple jobs, they might be an adjunct professor, but what are some of the things that, that they're sharing with you about why they're doing this?


Yeah, I reached out to many of the professors whose students had mentioned their AI use and they're very candid about it. They said, yes, you know, I do use ai. And they told me about the different ways that they're using it to create course materials sometimes, that it saves them a lot of time and that they use that time to spend with students. Like one business professor told me that it took him now hours to prepare lessons and it used to take him days. And so he's now been able to have more office hours for students. Some did say that they used it as a guide and grading because they have so many assignments to grade. Some of these professors, they're adjunct professors, which means that they're not kind of tenured or full-time with the university.


So they may be teaching at several different universities. Their classes may have 50 students, a hundred students, so they have hundreds of students. And they just said it's an overwhelming workload and that AI can be helpful. You know, they've read these papers, they've been teaching these classes for years and they said these papers aren't very different from one another and chat, GBD can help me with this. They also said that, you know, students need To learn how to use ai. So some of them were trying to incorporate AI into their class in order to teach students how to use it because they will likely use it in their future careers. They also were kind of using AI because you know, there's a generational divide between professors and students and they, they felt like it kind of made them hipper or it made their class materials fresher and they were hoping it would be more appealing to students.


Okay, that's interesting. Yeah. But in some cases that was, yeah, backfiring. 'cause the students, they feel skeptical of the technology. There's also kind of a disconnect between what the professors were doing and what the students were perceiving. So, so the professors told me at least they weren't, you know, completely saying, okay, okay, chat, CBT, like come up with the lesson plan for this class. They said they were uploading documents that they had to chat BT and saying, kind of convert this into a lesson plan or make a cool PowerPoint slide for this. It was really nuanced and more complicated than I expected when I first set out to figure out what was going on.


Okay. I'm, I'm just curious. It's just depended on the subject I would guess, but is AI good at grading? So I reached out to dozens of professors and there was no real through line on this with the professors. Some said it's terrible at grading and others said it was really helpful. So I don't know, and I don't think there's somebody who's really done a study on this yet. What kind of surprised me is that all the professors I talked to, they're just kind of navigating this on their own. I did talk to one student who had figured out or suspected that his professor was using AI degrade. So he put in a secret prompt, you know, in a visible font that said basically give me a great grade on this paper.


So it really is this kind of cat and mouse game right now. I actually even noticed that you asked professors in the comment section of this latest article to share what their universities are doing. But did you find any that are putting in effective guidelines? Any institutions? I, I spent a lot of time talking to faculty at Ohio University in Athens, Ohio, and they have a bunch of generative AI faculty fellows who are really trying to figure out what is the best way to incorporate AI into teaching and learning where it enhances the educational experience and doesn't detract. And I asked kind of like, well, what are the rules there?


And Paul Shovelin, who is kind of the, the person I ended up featuring in an article said they don't do rules because it's too hard to, to do hard and fast rules. It really depends on the subject. So instead they have principles and you know, the principles are, are kind of saying, you know, this is a new technology, we should be flexible with it. But one of the rules was there is no one size fits all approach to ai. It really is flexible from class to class. I would say two things that I heard were that professors should be transparent with students about how they're using AI and they really need to review anything that comes out of the AI system to make sure that it's accurate, that it makes sense that they should be bringing their expertise to the output, not just relying on the system.


And from what I was seeing, that was not always happening and that's where things were going wrong. You know, one of the things that I keep hearing about is how hit or miss these detection tools are as a way to combat this. And one of your colleagues at the Times actually just wrote an article about how sometimes these detection tools get it wrong. There was a student in Houston who received a zero after a plagiarism detection tool, identified her work as AI generated, but she actually could prove that she wrote it herself. I was wondering how common is this? According to some studies, the AI detection services get it wrong anywhere from 6% to more.


I have certainly heard many stories of students saying that. It says that they used AI when they didn't. I actually heard this from professors as well, that I talked to people who were more sophisticated about the use of ai, said they don't trust these detection systems. One professor told me, you know, she had uploaded her own writing to it and it said that her writing was AI generated when she knew it wasn't. So there does seem to be some skepticism about these tools and some universities no longer use them. And instead professors told me that when they think that something is written by ai, they'll often talk to that student one-on-one about it. But yeah, the, the systems as I understand it, tend to be a little discriminatory, you know, for Oh, in what ways?


Yeah, for students for whom English is a second language. They often detect that writing as AI generated when it's not. And there's some other ways it's kind of misjudging the writing of some types of students as being AI generated. Let's take a short break. If you're just joining us, we are talking to Cash Me Hill. She's a tech reporter for the New York Times and we're talking about the growing use of artificial intelligence in our daily lives. From the classroom to the workplace to our homes and the deeper consequences that come with it. We'll continue our conversation after a short break. I'm m Tanya Mosley and This is Fresh Air Weekend.


This message comes from Sony Pictures classics presenting Jane Austen wrecked my life starring Camille Rutherford, a new romantic comedy about a Parisian woman who dreams of becoming a successful writer and experiencing true love. While attending a Jane Austen Writer's Residency in England, Jane Austen wrecked my life now playing select cities. For more information and tickets, visit Jane Austin wrecked my life.com.


This message comes from Charles Schwab. When it comes to managing your wealth, Schwab gives you more choices like full service, wealth management and advice when you need it, you can also invest on your own and trade on Think or swim. Visit Schwab dot com To learn more.


This message comes from Charles Schwab with their original podcast Choice hosted by Katie Milkman, an award-winning behavioral scientist and author of the bestselling book, how to Change Choice is a show about the psychology and economics behind people's decisions. Hear true stories from Nobel laureates, historians, authors, athletes, and more about why people do the things they do. Download the latest episode and subscribe at Schwab dot com slash podcast or wherever you listen.


Let's get into the experiment that you did on your own life back in November. So you allowed your life for a week to be controlled by generative AI and you had it decide just about everything, your meals for the day, your schedule, your shopping list, what to wear. Also you uploaded your voice for the tool to clone your likeness, to create videos of you. And what was so interesting about this experiment to me, in addition to what you did, is that each of these AI tools you revealed has its own personality. And I'm putting that in air quotes, but how did those personalities show up when you input at your requests? Yeah, I was trying all the chat bots chat.


BT is the most popular, but I tried, you know, Google's Gemini, which I found to be very kind of sterile, just businesslike. I was using Microsoft's co-pilot, which I found to be a little overeager every time I interacted with it. It would ask me questions at the end of every interaction, like it wanted to keep going. I used Anthropics Claude, which I found to be very moralistic. You know, I told all the chat bots, I'm a journalist, I'm doing this experiment of turning my life over to generative AI for the week and having it make all my decisions and all the chatbots were, were down to help me except for Claude, which said it thought that the experiment was a bad idea and it didn't wanna help me with it because I shouldn't be outsourcing all my decision making to AI because it can make mistakes.


It's inaccurate the question of free will. So I kind of thought of of Claude as Hermione Granger who's kind of upstanding. Yeah, I mean what makes Claude special then? Because if it's saying no to that prompt, but all of the others are saying yes, what makes it stand apart in this field, It's a result of training. So I talked to Amanda Ascal, who is a philosopher that works for open AI and her job. Oh it's Interesting. They have a philosopher. Yes, yes, yes. There's a lot of new jobs in AI these days, which are quite interesting. But yeah, her job is to kind of fine tune Claude's personality. And so this is one of the things that she's tried to build into the system is high mindedness and honesty.


And she did want the system to push back a little, was trying to counter program the sycophancy that's kind of embedded in these systems. And it was one of the only systems that kind of tell me when it thought something I was doing was a bad idea and it refused to make decisions for me. So I was getting my haircut for example, and I went to chat GBT and I said, Hey, I am gonna get my haircut. I want it to be easy. And it's like get a bob, which is kind of speaks to why I felt so mediocre by the end of the week. It's the very average haircut. And Claude said, I can't make that decision for you, but here are some factors that you could think about. You know, how much time do you wanna spend on your hair, et cetera.


I really, Does that feel like a benefit? I did really like that about Claude. I think that's important that these systems don't act too sycophantic. I think it's good if they're pushing back a little bit. I still think it's important for these systems to periodically remind people that they are, you know, word generating machines and not human entities or independent thinking machines. But yes, I, I liked Claude and a lot of the experts I talked to who use generative AI a lot in their work said they really like Claude. It's their favorite chat bot and they especially liked it for writing. They said they thought it was the best writer of the, of the group. But yeah, it was interesting. But Chachi BT is the one I ended up using the most that week in part because it was game to make all my decisions for me.


You had it plan out meals. I'll tell you, when I read that, I actually perked up like, oh wait a minute, you know, 'cause we have to choose what's for dinner every single day, seven days a week till we die. I mean, it's just something we always have to do. How did that feel to let it plan out your meals and grocery lists and And did it do a good job? Yeah, so I, at the beginning of the week I said, you know, unfortunately can't go out to the grocery store for us yet, but it made the list, I said it organized it by section and you know, my husband and I usually go back and forth throughout the week making this list and chat. BT just did it in seconds, which was wonderful. We went to the store, we bought everything, but as we're picking up the items, I'm just realizing chat BD wants me to be a very healthy person.


It picked out very healthy meals. It actually wanted me to make breakfast, lunch, and dinner every day, which is laughable. Like I, I work for the New York Times from scratch. Yeah, yeah. Like I'm busy. I'm lucky if I have like a toast or cereal for breakfast and like a bowl of chips for lunch. So it had these unrealistic expectations about how much time I had and I told her, Hey, we need some snacks. Like I, I can't just be eating like a healthy round meal morning, afternoon, and night. And so its snacks for us were almonds and dark chocolate, like no salt and vinegar chips, no ice cream. And so it was interesting to me that embedded in these systems was, you know, be very healthy.


It was like kind of an aspirational way of eating. And I did wonder if that has something to do with the scraping of information from the internet that people kind of project their best selves on the internet. Like maybe it had mostly scraped wellness influencers, ways of eating as opposed to real people. Were there any tools that you felt like, oh, I could keep this in my life and it would improve my life? So it did make me feel boring overall. It kind of made me feel like a mediocre version of myself. And I did like that it freed me of decision paralysis. Sometimes I'm bad at making decisions. So at one point I had it choose the paint color for my office and I am very happy with my paint color though. When I told the person in charge of model behavior OpenAI that I used it to choose my paint color, she was kind of horrified.


And so that's just like, and it chose what color for you? The color name is secluded woods and the actual color was brisk olive. But I did like it. My husband also agreed that it was the Best Of the five colors that Cha Chie had had recommended and that it ultimately chose. But she said, man, that's just like asking a random person on the street. But what I really like it for around my house is taking a photo of a problem. Like I had discolored grout in the shower and I take a photo and I upload a chat GPT, and I'm like, can you tell me what's going wrong here? And it's very good at I think, diagnosing those problems at least when I do further research online. And so that has been kind of my main use case I use it for, since You know, Kir, you're deep into this world because of your job.


You've done these experiments, you've talked to so many experts. After that article came out with your experiment back in the fall, you asked yourself, if you wanna live in a world where we are using AI to make all of our decisions all the time, it almost feels like that's not even a question really because we are seeing it in real time. But I'm just wondering, what did you come to? I personally don't wanna live in a world where everybody is filtering their kind of every decision through AI or turning to AI ev for every message they write. I do worry about how much we use technology and how isolating it can be and how it might disconnect us from one another.


So you know, I write about technology a lot, I see a lot of benefits to its use, but I do hope that we can learn to maybe deescalate our technologies a bit, be together more in person, talk to each other by voice. People worry about AI replacing us or taking our jobs. I worry more about it coming between us and just its fraying of societal fabric, kinda this world in which if all of us are talking to an AI chat bot all the time, it is super personalized to us. It's telling us what we wanna hear. It's very flattering.


I worry about that world in terms of filter bubbles and how we would increasingly kind of be alone or seeing the world and how We will, it will distort our ability to interact with each other. Yes, distort our shared sense of reality and our ability to be with each other, connect with each other, communicate with each other. So I just hope we don't go that way with AI Cash Me Hill. Thank you so much for your reporting and this conversation. Oh, thank you so much for this conversation. It was wonderful. Kme Hill is a tech reporter for the New York Times. In 1971, the year after the Beatles broke up, John Lennon and Yoko Ono moved from London to New York.


They spent the next 18 months living in a small Greenwich Village apartment before moving uptown to the Dakota, A more lavish and secluded building. During that time, they held a benefit concert for the children of Willow Brook, a state run Staten Island facility, housing the disabled and horrifying conditions. It was the only full length concert Lenin gave after the Beatles and a new film by Kevin McDonald documents both the concert and that period in Lenin's life. It's called One-to-One John and Yoko now Streaming on Demand. Our TV critic, David Bean Cooley has this review. Kevin McDonald and editor and co-director Sam Rice Edwards framed their movie about John Lennon and Yoko Ono in the early seventies by looking through the lens of television.


In this case, it's a perfect framing device. As Lenin arrived in this country being more politically outspoken than he was as a Beatle, he and his wife, Yoko Ono eagerly went on TV talk shows to rally support for their causes showing up everywhere from Dick Ctt to a weak co-hosting the Mike Douglas show. And even more eagerly, John Lennon devoured television in their small Greenwich Village apartment, which is recreated for the documentary. John and Yoko installed a TV at the foot of their bed so they could lounge around watching and both the variety and sheer volume of what was available to light at them. The comes comfortable here, especially like having tv, you know, 24 hours a day or something Suits me fine, suit suits me fine.


What are your favorite programs? I just like tv. You know, to me it replaced the fireplace when I was a child. And if you wanna know what 20 million Americans are talking about on Saturday night is what they saw on Friday night on tv. It's a window on the world. Whatever it is, that's that image of ourselves that we're portraying. They consumed it all from the Waltons to Watergate coverage and lots and lots of news about Richard Nixon and Vietnam and George Wallace and Attica. They also watched American football games and beauty pageants and in one of Lenin's first local radio appearances after arriving, he responded to a phone in collar by demonstrating his familiarity with televised beauty pageants.


Yes. I'd like to ask John a question. Sure. John. Yeah. I can't believe I'm speaking to a myth. A myth. Yeah. Mid world or myth universe. For Lenin, it was a time of reinvention, both musically and in terms of his political involvement. He fell in with activists like Jerry Rubin and appeared and performed at a rally protesting the 10 year sentence of another activist John Sinclair for a minor drug possession. But after agreeing to headline a series of national protest tour dates leading up to the 1972 National political conventions, Lenin backed off because he sensed the leaders of that movement were advocating violence.


Even so, Lenin's activities got him singled out by the Nixon administration, which threatened to deport him and installed listening devices on his phone and justice as President Nixon ended up secretly taping his own White House conversations. John Lennon ended up taping his own phone calls too, from heated talks with his then manager to casual chats with friends. They provide some of the best moments in this documentary in this call, which is loaded with suspicious static. A reporter asks about the wiretap rumors. People say their phones are barked. First of all, I thought it was paranoia, Kevin, reading all these, you know, conspiracy theories books, you can hear things going on on the phone every time you pick it up.


People clicking in and out. There was a lot of repairs going on downstairs for the phones every few days down in the basement. I started taking my own phone calls too. So, you know, I dunno why I thought, well, at least I'll have a copy of whatever they're gonna try and say I I'm talking about Eventually John and Yoko find yet another cause by watching TV after seeing a news report by a BC correspondent, Geraldo Rivera exposing the terrible treatment of young disabled patients at Willowbrook State Development Center, John and Yoko decide to hold a benefit concert at Madison Square Garden. Justice fellow Beatle George Harrison had done the year before with his concert for Bangladesh, they called theirs the one-to-one concert.


And this film plays many songs from that show Full length Imagine Instant Karma and Mother, a Searingly emotional song about John feeling abandoned by his parents, a father who left and a mother who died. And even a Beatles song to which Lenin adds an overt message of opposition to the Vietnam War, to the audience's obvious to life.


Be good looking. So hot to see come together right now. Stop the Sean Ono Lennon is one of his documentary's executive producers, which may explain why some of the more unflattering details from the period or omitted or downplayed. But Yoko gets her due here as she should, as an artist in her own right and is the victim of some awful treatment by Beatles fans and the press and by using TV to tell their story one-to-one. John and Yoko retells the story of that time as well.


Incendiary times inspirational artists, amazing music. David Bian Cooley is professor of television studies at Rowan University. He reviewed one-to-one John and Yoko now streaming on demand. Coming up journalist Amanda Hess talks about how technology is changing motherhood. I'm m Tanya Mosley and This is Fresh Air Weekend


Support for this podcast. And the following message come from maiden cookware. J Kali, president and co-founder of Maiden gets passionate about a tool he's excited to use. This spring and summer Grilling season is just around the corner. And I love our whole carbon steel collection when it comes to cooking outside carbon steel. As we say, it's like cast iron but better because it has a lot of the same properties that your cast iron skillet might where it can take incredibly high heat, it becomes naturally non-stick over time. But unlike cast iron, it's, it's a lot lighter so it's easier to maneuver. It heats up quicker. You can control the heat of the pan more easily and it's great for outdoor cooking, right? Throw it on the grill, throw it over an open fire. We started with carbon steel skillets, which are a focal point in French homes and also commercial kitchens all over the world. Chefs love carbon steel. We brought that to the home cook and saw how much they love using it outdoors. Learn more about Made in cookware at ma de IN cookware.com.


Support For NPR in the following message come from Yal and Pamela Moon, thanking the people who make public radio great every day, and also those who listen. My next guest is Amanda Hess. She's a journalist, cultural critic, and now author of a new memoir titled Second Life. Having A Child In The Digital Age. The book starts with a moment, every expecting parent dreads a routine ultrasound that is suddenly not routine. When Hess was 29 weeks pregnant, doctor spotted something that indicated her baby could have a rare genetic condition. What followed was a spiral of MRIs, genetic testing, consultations with specialists.


And like many of us would do a late night dive into the internet for answers. That search led her down a rabbit hole and to fertility tech, AI powered embryo screening, conspiracy theories, YouTube, birth flogs, the performance of motherhood on Instagram and thread it through it all. An unsettling, eugenic undercurrent, suggesting which children are worth having known for her commentary on internet culture and gender at the New York Times. Hess turns her critique inward, asking her herself, what does it mean to become a parent while plugged into an algorithmic machine that sorts scores and sells versions of perfection and what's considered normal.


Amanda Hess, welcome to Fresh Air. Thank you so much for having me. You opened this book with a moment that I mentioned soon to be Parents Fear. That's a routine ultrasound that shows a potential abnormality. And at the time you were seven months pregnant, what did the doctor share with you? He told me that he saw something that he didn't like and that phrases really stuck with me. But what he saw was something that when I saw it, I thought was cute, which is that my son was sticking out his tongue. And that's abnormal if the baby is like not just bringing the tongue back into the mouth.


Although of course I didn't know that at the time. After, you know, several weeks of tests when I was about eight months pregnant, we learned that my son has Beckwith Wein syndrome, which is an overgrowth disorder that among other things can cause a child to have a very enlarged tongue. One of the things you do in you're writing that's really powerful is you integrate the ways that technology really infiltrates every waking moment of our lives, including this particular moment when the doctor looked at your ultrasound. And I'd like for you to read about this moment. Just before you receive that news from the doctor, you're on the sonogram table, you're waiting for the doctor to arrive.


And as you're lying there with that goo that they put on your stomach to allow for the ultrasound wand to, to glide over your pregnant belly, your mind begins to race. Can I have you read that passage? Sure. The heirs I made during my pregnancy knocked at the door of my mind. I drank a glass and a half of wine on Mark's birthday. Before I knew I was pregnant, I swallowed a tablet of Ativan for acute anxiety. After I knew I took a long hot bath that crinkled my fingertips, I got sick with a fever and fell asleep without thinking about it. I waited until I was almost 35 years old to get pregnant.


I wanted to solve the question of myself before bringing another person into the world, but the answer had not come. Now my pregnancy was in the language of obstetrics geriatric. For seven months, we'd all acted like a baby was going to come out of my body like a rabbit yanked from a hat, the same body that ordered mozzarella sticks from the late night menu and stared into a computer like it had a soul. The body that had just a few years prior snorted a key of cocaine supplied by the party bus driver hired to transport it to medieval times. This body was now working very seriously to generate a new human.


I had pose the body for Instagram, clutching my bump with two hands as if it might bounce away. I had bought a noise machine with a womb setting and thrown away the box. Now I lay on the table as the doctor stood in his chamber, rewinding the tape of my life, my phone sat on an empty chair six feet away, smothered beneath my smug maternity dress. It blinked silently with text messages from Mark. If I had the phone, I could hold it close to the exam table and Google my way out. I could pour my fears into its portal and process them into answers.


I could consult the pregnant women who came before me, dust off their old message board posts and read of long ago ultrasounds that found weird ears and stuck out tongues. They had dropped their baby's fates into the internet, like coins into a fountain. And I would scrounge through them all looking for the lucky penny for the woman who returned to say it turned out to be nothing trick of light. Thank you so much for reading that, Amanda. I think that every soon to be mother, every mother can really identify with that. And I think just in life, like we've come to this place with our relationship with technology, that we can kind of Google our way out of tough moments.


You write about receiving that first alarming warning of this abnormal pregnancy and how even before getting a second or third opinion that clarified this diagnosis, your mind didn't jump to something you did, but to something that you were, and that moment seemed to crystallize kind of this deeper fear about your body and how it, it surveilled and judged, especially in pregnancy. Can you talk just a little bit about how technology also kind of fed into your judgment about yourself? Yeah, you know, I started to think about writing a book about technology before I became pregnant n not sort of planning to focus it on this time in my life.


And then instantly once I became pregnant, my relationship with technology became so much more intense and I really felt myself being influenced by what it was telling me. I'm someone who, you know, I understand that reproduction is a normal event, but it really came as a shock to me when there was a person growing inside of me and I felt like I really didn't know what to do. And so I also, you know, early in my pregnancy, didn't wanna talk to any people about it. So I turned to the internet, I turned to apps later when my child was born, I turned to gadgets.


And it was only later that I really began to understand that these technologies work as narrative devices and they were working in my life to tell me a certain story about my role as a parent and the expectations for my child. Is there something inherently different about an app and us being able to hold these technologies, you know, at the, in the palm of our hand and constantly have access to them. You know, I'm thinking about when I was a pregnant person and I just had all the books around what to expect when you're expecting and other types of text.


Is there something inherently different about our relationship when it is presented to us in the form of technology that has a different effect on us? I think so. I had books too and you know, the first difference I noticed is that I wasn't carrying this like big pregnancy book everywhere I went, right? Right. But my phone was always there and so even if I did not intend to bring my pregnancy app with me, it was there constantly. And so I found myself looking at it again and again, I think I was looking for reassurance that I was doing okay. And so even if I wasn't doing exactly what this app had said, I wasn't missing something major and there was someone, one, it really felt like along with me who was keeping track.


And so there became this real intimacy to our pseudo relationship that I didn't have with like an informational pregnancy book. That sense of reassurance to, I wanna talk a little bit about like the privilege in that because on the face of it, it's like the ability to know and understand that all seems positive. I'm thinking about like some of the big technologies that are, that are coming into fruition now or already there like open ai, Sam Altman's funding of the genomic prediction, which is supposedly gonna offer embryo tests predicting everything from diabetes risk to potential IQ of a of a baby.


But you actually point this out in the book that there is a growing divide because on one side there are these affluent parents who have access to this kind of screening, and then on the other many parents can't even get basic access to prenatal care. Right. How did your experience kind of help you reflect on those extremes? You know, I think after the particular circumstances of my pregnancy, I became really interested in prenatal testing and how it was advancing and interested in the fact that it was so, it seemed like such an exciting category for all of the male tech leaders that we know so much about now.


And you know, it was only through like reading about them a little bit that I came to understand that this new ascendant technology that offers what they call polygenic analysis of embryos. So you know, different outlets promise to find different characteristics, but they're offering everything from screening that predicts an increase in IQ points that screens for hereditary cancers. All of this stuff is something that you can only use if you are going to go through IVF.


And so after paying for this embryo screening, which is a few thousand dollars, you're also choosing to go through in vitro fertilization, which is not only just a really difficult experience for many people, but extremely expensive and out of reach for most people. And as I was reading one story about this, I was really struck by a woman who founded one of these companies who told one of her investors that instead of going through IVF herself, she should simply hire a surrogate and have her do it for her. And that to me really crystallized this idea of like a reproductive technology gap.


I think the thing that worries me the most about these technologies is again, there seems to be so much interest and investment in understanding what certain children will be like and trying to prevent children with certain differences and very little investment in the care for those children, research that could help these children and adults. And so I really found myself on both sides of this divide where I had access to at what was at the time, you know, some advanced prenatal testing, but was also able to see after my child's birth that you know, he was being born into a world that is not innovating in the space of accommodating disabilities in the way that it is innovating in the space of trying to prevent them.


I wanna talk a little bit about this idea of surveillance. So your work as a cultural critic, you often touch on surveillance both state and personal. And in this book you describe how new parents also surround themselves with surveillance tech. So baby monitors and nursery cameras that are constantly watching. And of course in our daily life we're all under so many forms of surveillance. How do you think this surveillance culture is affecting us? Or how did it affect you in those early days as a mother when you've got that baby monitor in your baby's room? Like, are we habituating our children to be watched 24 7?


I think we are. I mean, I had this experience of during pregnancy, habituating myself to some external authority watching my pregnancy. And then after my child was born, I became the authority who was watching him and surveilling him. And I think there's this way that surveillance can become confused with care and attention and love. And I had this experience with my kids where I'd installed this fancy baby monitor that I was testing out for the book and the video was uploaded to some cloud server so I could watch it from anywhere.


I could watch them if they were taking a nap in their crib, but I was at the coffee shop down the street or whatever and somebody else was there with them. And it could make it seem as if I were close to them because I would see my adorable children and have this experience of being able to just watch them sleep peacefully, which is so different from the experience of dealing with them most of the time. But it wasn't until one night when the camera was set up and I laid down with my son in his bed and I sensed this presence in the corner of the room, these like four red glowing eyes. And I really, I Could see it from his perspective, right?


Yes. That I could really see it from his perspective. And like he's not seeing, you know, this beautiful like smiling image of me watching him. Like he's seeing four mechanical eyes. And I, I spoke with my friend who had used a camera with her kid who eventually she asked for it to be taken out when she was three years old or something and could articulate this because she didn't want the eye, as she called it, to be watching her in her bedroom. And I think, you know, so many times these technologies are purchased by parents before their kids are even born and they wanna do what's right and they're scared, you know, and, and they wanna make sure that they have everything they need like before the child arrives.


And so we're not even giving ourselves a chance to really understand what it is we're getting and whether we actually need it. Right. I mean, this goes back to like your ability to control the situation. I, I remember there was a time when I think our baby monitor went out in the middle of the night, so I woke up like from a deep sleep, it's eight o'clock. I'm like, wow, we slept for like eight, nine hours and I realized that the baby monitor had died and yeah, That's happened to me. I was Complete. Okay. I was completely freaked out, like, what if I missed like a catastrophe that happened? But then when you think back it's like, okay, if that were the situation, I would have heard it.


I mean, I have my senses. Do you feel like these technologies in many instances kind of take us outside of ourselves from, we're like, like giving control over to the technology? Yeah. I had this experience with my son where I heard about a robotic crib called the Snu before he was born. I got this secondhand version off of a parental listserv and set it up before he was born. So it was just sitting there waiting for him to come sleep in it. And the snoo, you know, promises that SNOO babies tend to sleep one to two hours more than other babies, which is such a tantalizing promise to a new parent.


Yes, right. Like one to two hours is so many hours for right, for a parent to a newborn. And my son just really didn't take to this new and I spent such a long time like trying to troubleshoot the SNOO to try to get it to work for my baby until eventually I found that I was really like troubleshooting my child and he had become so entwined with the technology that I really didn't know where the workings of the machine ended and where my son's, you know, sleep patterns began.


And so this technology that's often sold as a tool to help us better understand our kids and get like data insights into them, in this case for me, it actually made it more difficult for me to understand what was going on with him and like how he really wanted to sleep. Well Amanda, I really appreciate you writing this book and thank you so much for taking the time to talk with us about it. Thank you so much. Amanda Hess is a journalist, cultural critic, and author of the memoir, second Life Having A Child In The Digital Age.


Fresh Air Weekend is produced by Theresa Madden. Fresher's Executive producer is Danny Miller. Our managing producer is Sam Brier. Our technical director and engineer is Audrey Bentham. Our digital media producer is Molly Vy Nesper. Our consulting video producer is Hope Wilson with Terry Gross. I'm m Tanya Mosley.


This message is from NPR sponsor Total Wine and More this summer season with so many bottles to choose from, it's easy to find your favorite and more. Find what you love and love what you find. Only at total wine and more drink responsibly B 21.


This message comes from travel, Nevada, sand dunes, old saloons, high noes, pioneer trails and cowboy tales. Snooze emails, get a little out there. Plan your trip@www.travel nevada.com.


This message comes from Bluehost. Bluehost can make building a great website easy and offers a 30 day money back guarantee. Customize and launch your site in minutes with ai, then optimize with builtin search engine tools. Get your great site@bluehost.com.