
NPR informs and connects communities around the country providing reliable information in times of crisis. Federal funding helps us fulfill our mission to create a more informed public and ensures that public radio remains available to everyone. Learn more about safeguarding the future of public media. Visit Protect by public media.org.


This is Fresh Air, I'm Dave Davies. For decades, scientists have dreamed of computers so sophisticated they could think like humans and worried what might happen if those machines began to act independently. Those fears and aspirations accelerated in 2022 when a company called OpenAI released its artificial intelligence chatbot called chat. GPT. Our guest, veteran investigative reporter, Gary Rivlin, has burrowed deep into the AI world to understand the plans and motivations of those pushing artificial intelligence and what impact they could have for good or ill. In this new book, Rivlin writes that in March of 2023, there were more than 3000 startup companies in the US working on artificial intelligence with new ones popping up at a rate of 30 per day.


While AI is already in use in some fields such as medical diagnosis, many believe the field is on the verge of a new breakthrough achieving artificial general intelligence systems that truly match or approximate human cognitive abilities. Some believe it could be as transformational to human society as the industrial revolution, but many fear where it may take us a poll of AI researchers in 2022 found that half of them believe there's at least a one in 10 chance that humanity will go extinct due to our inability to control ai. In 2023, president Joe Biden issued an executive order, imposing some regulatory safeguards on AI development, but President Trump quickly repealed that order upon taking office saying, Biden's dangerous approach imposed unnecessary government control on AI innovation.


We've invited Gary Rivlin here to help us understand all these issues and developments. Rivlin has worked for the New York Times among other publications and published 10 previous books. In 2017, he shared a Pulitzer Prize for reporting on the Panama Papers. His new book is AI Valley, Microsoft, Google, and the Trillion Dollar Race to Cash In On Artificial Intelligence. Well, Gary Rivlin, welcome back to Fresh Air. Thanks for having me. Let's just start with a couple of basics. You know, we're used to computers being very smart. I mean, in two thou, way back in 2011, Siri appeared on Apple products. What what distinguishes artificial intelligence from just smart computers?


You know, it, there's this sense out there that in 2022, we suddenly had artificial intelligence. It's been much, much more gradual than that. You know, Google has been using machine learning, artificial intelligence since the two thousands, you know, to decipher imprecise Google searches, to figure out how much to charge for the various ads they throw on the system. You know, Google translates been around since the mid 2010s. That's ai. So, you know, we, we've been auto complete, you know, spam filters. That's, that's ai. You know, you, but you're touching on a really interesting question. It's, it's, it's not this clear like, oh, this is a smart machine.


This is artificial intelligence. The way it's kind of played out now is that these machines can learn, right? I mean, the old approach had been, you encode rules. You just teach the computer. Here's exactly the set of rules. Just follow it. Now it's machine learning, deep learning that the computer is ingesting vast troves of data books, the public internet, Amazon reviews, Reddit posts, whatever it might be, articles, and it's finding patterns and in quote, learning, you know, and then they're fine tuned and then they get better at communicating with us and such. So, you know, there really isn't this, oh, artificial intelligence is this and all, in fact, the term artificial intelligence is controversial just in the sense that, you know, right now it's more amplified intelligence.


We could use this thing to get smarter, to find patterns that humans couldn't possibly understand. 'cause we can't read billions of of words. So, you know, there's another definition that AI really should be alien intelligence. 'cause the weird thing about AI is that it seems to know everything, but it doesn't understand a thing. You know? I mean, there's this term, I, I love it from a linguist at the University of Washington uses it, the stochastic parrot. You know, it's just like, it's like a parrot, it just, it's repeating words randomly, but it doesn't really understand what it's saying. Right? But it's learned a lot of words. Okay. Now, now this may be another artificial distinction, but I want new talk is now of, of artificial general intelligence, a great leap forward.


What is that exactly? Right. So, you know, a GI, just to use the phrase is that it, it's, it's a, a, a system that could match or exceed cognitive abilities across the board. And, you know, a again, I, I feel like in some ways we have artificial general intelligence. You know, again, you, you gotta be a PhD in physics and understand this. But what's amazing about, you know, the, these models is that they have deep understanding in a vast array of, of domains. So in one way, that is a GI, artificial general intelligence, you know, it's, there's no set definition that it keeps on changing.


There are predictions that we're gonna have a GI the next year or two years, maybe it's five years kind of thing. I, I, I, I, I'm, I'm dubious of, of, of those predictions. I mean, this is moving exponentially. This is improving so fast that making predictions could be perilous. But on the other hand, I I I, I really feel like there needs to be another breakthrough or two before we have this artificial general intelligence ala, you know, a computer from like Star Trek that you're talking to, and it's helping you explore. It's at yours of copilot, figuring out everything. You know, I, again, I an artificial distinction in that. I don't think like one day there's gonna be this eureka.


We have a GI, I do guarantee there will be startups and large companies that say, Eureka, we have artificial general intelligence. But, you know, they'll just play with the definition. But, you know, a few days ago, I'm sure you saw this, Kevin Ros, the respected tech columnist for the New York Times, wrote a piece saying that, you know, whether, whether that, that we're gonna quickly see companies claiming they have artificial general intelligence and what, whatever you call it, these dramatically more powerful AI systems are coming and soon, and as recline of the New York Times opinion section says essentially the same thing. Both of them agree, we are not ready for the implications of this. Do you agree with that? I, I, I do.


And you're taking away for me, what's the main message of those? These things are coming and they're coming fast and we're not prepared. You know, I personally think AI could be an amazing thing around health medicine, scientific discoveries, education, a wide array array of things, as long as we're deliberate about it. And that's my worry. And I do believe that's Kevin and Ezra's worry that we're not being deliberate. We started in 2023. There was, you know, meetings at the White House and, you know, the, there's hearing hearings in the Senate, and that's just kind of dropped by the wayside. And now we're more at a, a laissez-faire attitude towards it.


We, we need to prepare for this. You know, like any technology, there's good and there's bad, right? The car, the car meant freedom. The car changed our society, but the car meant pollution. The car means 30,000 to 40,000 deaths in the US a year kind of thing. And I, I look at AI the same way. It could be really great if we're deliberate about it and take steps to ensure that we get more of the positive than the negatives. 'cause I guarantee you, there'll be both positives and negatives. You know, I mentioned in the introduction that President Biden had issued this executive order trying to establish some processes and guardrails and safeguards. Trump swept all that away saying, Nope. That's, that's onerous government regulation.


Let, let, let innovation proceed. And you, you know, it's funny, the last time you and I talked on this program, it was about efforts to implement the Dodd-Frank reforms of, of the financial system. And one of the difficulties was that, was that that Bill had general principles, but regulators had to actually spell out what it meant to regulate some pretty complicated, you know, contracts and instruments in the world of finance. And what you, what you'd written about then was how the private interest had gotten in and kind of gum all that up with by disputing everything. But I'm wondering, what does, what do regulations that control something as sprawling as ai?


What, what does that look like? What do we need in terms of how do we get prepared? Right? So, so there were a few basic steps that the Biden administration thought of. One that you, in quotes, red team, these cutting edge models. And basically you get outsiders to try to break the system, try to get it to jump the fence, to use the term, to get it to misbehave, just to see what could go wrong. And you, the executive order said you need to test them, and then you need to share with the government what you find. That's one of the things that went by the wayside when Trump took over as, as, as as president. But to me, I, I, I'd break it down more to the concerns, the use of AI as a weapon of war, the use of AI for surveillance.


You know, I worry that AI is just going to solidify biases that we already have because the AI is learning from us and all these inherent biases in things. You know, it's like we need to prepare for the impact on the job market, which I think will be a slow role. I don't think, like we're gonna lose millions of jobs in a year kind of thing. But, you know, it is coming and we need to prepare for it. There's another concept, recursive learning that these systems change in ways we don't really understand. And that's what scares me, that we're gonna let, you know, let these systems loose and they could just learn. 'cause you know, really the way to understand any of these large language models, any of these chat bots, is, it's a mirror on us.


It's reading our collective works. It's learning from us about imperialism and domination, and, you know, humans mistreating each other, is learning about loneliness, is learning about freedom and independence and autonomy and all that. And so, me, it's recursive intelligence, this idea that these models are constantly improving in ways we don't understand. And then that could be dangerous And they could learn how to pursue an agenda and keep it hidden, right? To deceive in, in their own interests is yeah. What, what, so what would that look like in terms of what are the dark fears here? I, I mean, that's not really a theoretical, you know, these, the systems, God, I can't even remember which model it was, but, you know, they, they were testing it and it was dissembling, it was changing, it was changing the files that would monitor his behavior and then lying to the people who noticed it and said, wait, aren't you changing those files?


And you know, it, it, it's another example. O OpenAI, the creative chat, CPT, when they came out with GPT-4, their then cutting edge model in, in 2023, they put out a research report and they red teamed it. They tested, they tested it and saw all the ways it could misbehave. And one of the most interesting is that the model went to, it was a TaskRabbit. It went to one of those services where you can hire a human, or maybe Fiverr, you could hire a human. And they used it to beat the capture test, the test that is gonna test, are you a machine or a human? Wow. And you know, that's, that's very clever and very, very scary.


Wow. So, so what are some of the darkest fears? I mean, starting nuclear war, you said it to defend territory with drones and it gets signs. It needs to be more aggressive than the generals want to. I mean, what, what is it, what are the fears? I look at it is you look at the positives and then you imagine what the negative could be. So an AI that makes possible new drug discoveries and more effective therapeutics is also one that could create a new bio tarot weapon, or it can engineer a pandemic. You know, I can imagine cyber thieves employing AI to siphon off a trillion dollars from the world monetary system before any human being even notices it. I, I guess the point is that, you know, AI could be a powerful tool for good, but it could also be a powerful tool for people with bad intent.


You know, everyone knows, or many people know that, you know, you could use it to write a toast on someone's 50th birthday or for a wedding toast. Well, scammers from a different country could use it to create a better crafted a scam email. You know, these systems are so good now that you could take seconds of someone's voice and make it sound like it's that person speaking. So you can imagine a scenario where, you know, a kid is overseas in Europe and the bot, the one of these systems, you know, calls grandma pretends it's that kid and says, I'm in trouble. Wire me money.


And they, boom, it's done. They're good enough to fool. Yeah. You know, the, the parent, the grandparent, I mean, maybe not a parent, but I don't think we're very far away from that. And it could certainly fool many, many people. Right, right. You know, there's something that you wrote in the book. You wrote about a couple of tech guys, Tristan Harris and Aza Raskin, you know, who had real experience in, in the war, in the tech world, who said they worried about ai because it's a technology whose creators confess, they do not understand why their models do what they do. Is that literally true? That's kind of scary. Yeah, so, so, you know, they're a block, a black box. I mean, so nowadays it's neural networks models that emulate how humans learn.


They learn by reading vast stores of, of, of data, the open internet, books, whatever. And they improve through feedback and trial and error. You're not really encoding the rules. Well, you know, it's trying to emulate the human brain. And, you know, I mean, I I, I have two teenage sons, you know, we try to teach them. They read, you know, we give them feedback and all, and you know, there are things that come out of their mouths I don't quite understand. And I, that's the way I look at these chatbots, these neural networks, these large language models, you know, that we don't quite understand. They say what they say because they're trying to emulate the human brain as best they can.


And who could say why I'm saying the words I'm saying right now, and you're gonna have the exact reaction. And so that's part of the miracle, the gee whiz, these things are amazing, but it's part of what's scary. 'cause we don't fully understand the people who create it don't fully understand why it says what it says. One more thing about the national political scene. You know, there's a lot of talk about Tech Bros and Donald Trump. You know, Elon Musk is, you know, clearly a driving force in the administration's effort to cut federal workforce and contracts. There are a bunch of billionaires from the tech world at his inauguration. Do, do you think that there's a, an elite tech agenda to radically reshape society at work through Donald Trump?


In a word, yes. What scares me is there's a movement in Silicon Valley, there's a movement in tech, the accelerationist, you know, anything that stands in the way of our advancing artificial intelligence is bad. Often it's put in the context of competing with China. We can have new rules in the way, and that is their agenda. I would say their real agenda is that they could make a lot of money, billions, hundreds of billions, ultimately trillions of dollars off of this. And they don't want anyone standing in their way. And so I think if you want to understand Elon Musk, you wanna understand Mark Zuckerberg, you wanna understand Jeff Bezos and Cozy up to Trump, you know, for a few million dollars.


It's not very expensive for them. You know, they could have a friend in the White House who makes sure that they can do what they want to do unchecked. And in fact, maybe that's my biggest fear about ai. It's so much power in the hands of few people. It, it, creating these models is so expensive to hire the talent that you have to pay them a million or more a year to train them. It takes tens of millions, if not hundreds of millions of dollars in computer power. And then to operate them takes equivalent money. It's billions of dollars and billions of dollars. So, you know, it's becoming less and less about the startups and more about the same companies that dominated tech in the 2010s dominating in the 2020s.


You know, Google, Microsoft Meta, which is Facebook, Amazon, a few others. And that's really what concerns me. You know, that's kind of the Silicon Valley way. Let's get five smart guys. And they're almost always guys in a room and we'll figure it out and like, okay, we saw that didn't go so great with social network and now we're having a really powerful technology. And I like it to be more than just five people in a room figuring this out. You know, the account that you give us in the book is pretty detailed and really interesting about how all this unfolded.


One of the things that struck me is that some of the leading players in developing AI weren't just coders or computer nerds. A lot of them studied classics or philosophy or worked in completely unrelated fields. Is there a connection here? That's one of the things I was surprised by and found fascinating myself, that it's not just computer scientists, it's mathematicians, it's physicists, it's philosophers, it's neuroscientists. And you know, it's a broad range of things because again, it's no longer about just programming these models to act the way we want them to act. We're trying to emulate the way humans learn.


So what a psychologist has to say, what an educator has to say about that is a linguist is really important to it. Speaking a natural language. That's actually what attracted me to the topic in the first place. This idea that computers could speak to us in our language. You didn't have To learn a programming language earlier, earlier in my life, I tried a program in computers. I, you know, studied Fortran, I Did too a long time ago. And it's difficult. It was so frustrating. You know, you make a little mistake and you know what? Whatever. And the idea that you could speak to these things and you know, nowadays, I mean, speak to it, you don't even have to type you, you know, they have voice. You can talk to it. I just found that fascinating to me.


So you do need a wide range of people. In fact, if I had a criticism, I don't think there's a wide enough range of people. I'd like some historians and sociologists and others involved in the developing of these models, given the stakes. I'm gonna take another break here we are speaking with Gary Rivlin. He's a veteran investigative reporter. His new book is AI Valley, Microsoft, Google, and the Trillion Dollar Race to cash in on Artificial Intelligence. He'll be back to talk more after a short break. I'm Dave Davies and This is Fresh Air.


This message comes from NPR sponsor Shopify, no idea where to sell. Start selling with Shopify today. Whether you are a garage entrepreneur or IPO Ready, Shopify's the only tool you need to start, run, and grow your business without the struggle. Go to shopify.com/npr.


This message comes from NPR sponsor, Disney Plus season one of and or had critics calling it the best Star Wars series. Yet, season two of the Emmy nominated series is now streaming on Disney Plus. Follow Cassie Andor as he embarks on a path from a rebel to a hero starring Diego Luna. And from creator Tony Gilroy, writer of Michael Clayton. And the Born Identity. Season two of Andor is now streaming only on Disney plus.


99% of the US population lives within listening range of at least one public media station. And everyone can listen to NPR podcasts free of charge. That means you get completely un walled access to stories, prize winning reporting, and shows that represent the voices in every corner of the country. Hear the bigger picture every day on NPR At NPRs pop culture. Happy hour. We sort through a lot of television and we've found some recent TV comedies we really like that you don't want to miss. And we'll tell you where to watch them in one handy guide. Listen to the pop culture Happy hour podcast from NPR.


You know, you made the point earlier that it's enormously expensive to develop ai. I mean, the, the talent is high priced and it takes tons and tons of computing power to develop the systems to run them once you have 'em, which means, you know, not a a a couple, $3 million, but hundreds of millions in some cases or more. Which means that the big companies in tech, you know, Microsoft, Google, you know, meta, we all know the names have an edge. But it's interesting as, as I read your story, that doesn't, that's no guarantee of success, is it? Sometimes it's kind of an obstacle having a big organization. You know, it's interesting. Let, let's use the example of Google. Let's give Google credit first. They were so far ahead of almost everyone else on ai.


They hired some of the best talent. They were employing machine learning, deep learning, long before most everyone else. You know, they did some of the more cutting edge things. In fact, the breakthrough that led to Chatt PT was actually out of, out of Google. Google had inside the company in around 2020 a Chatt PT equivalent. But you know, Google takes in a lot of revenue. There's a lot of risk. If this chatbot misbehaves, there was famously this example of Microsoft, I think it was 20 16, 20 17 came out with te and you know, it was trained on social media and that kind of thing.


And within 24 hours it was a Holocaust denying white supremacists. And of course, Microsoft worrying about the reputational risk pulled the plug on that rather quickly. And I feel like that's haunted the giant. So even though Google was far ahead, even though Google could have had their version of chat PT and it was Google that changed the world. They were, they, they were scared of it. And, you know, never underestimate the ability of a giant to stumble over its own feet. They have layers and layers of bureaucracy. They have, you know, huge public relations department that's whispering the CEO's ear. You know, I don't think it's a coincidence that OpenAI startup founded in 2015 was the one that set off the starter's pistol on this.


'cause they didn't have as much as at stake. You know, they couldn't afford reputation wise to release chat GPT. They could just make the decision without 10 layers of, of decision making before they did it. And you know, so yes, they have an advantage. But you know, Google also, Google also has like a hundred billion dollars of reserves, you know, where at OpenAI has to go out and raise funds, raise, they've raised roughly, I don't know, 20 billion so far. And there's talk that they've raised another 30 billion. And those I, I might even be underestimating. And so, you know, that's 50 billion or so, you know, Google, they just pay for them, sell Microsoft meta.


They all have deep, deep, deep reserves of money. And so, you know, it's almost like a race of attrition. You know, you can use these chatbots for free if you want the leading edge, cutting edge, you know, you have to pay, a consumer would pay 20 bucks a month for it, but you know, most people are using these things for free and it's costing the companies a lot more than $20 a month to handle the heavy usage. And so these things are gonna become more of a commodity. You know, there's a leapfrogging going on, like yes, GPT-4, that's open ai. You know, when it came out it was cutting edge, but then, you know, anthropics clawed leapfrogged over that, and then others leapfrogged over that.


And so they're all more or less as powerful as useful as the other. And it's not clear how any of these companies are gonna make money. Google can afford to lose money on these things for five years plus a startup. That's, that's harder to do, Right? Right. And so a lot of times you see the big companies buying smaller startups that have shown promise. It's interesting that this company called Open AI kind of became the public face of artificial intelligence in a way. It was a startup that didn't have, you know, the power of a Microsoft or a Google behind it. It was this guy, Sam Altman and some other folks. Elon Musk. Yeah, yeah. Elon Musk among others, right, right.


And there's a moment that was sort of a critical transformational point when they released this version of chat GPT, but that was proceeded by a dinner at Bill Gates house, which you describe which the house being as absolutely as magnificent as you would expect a Bill Gates house to be. Tell us about that evening, what happened? So Microsoft starting, starting in 2019, started investing in open ai. And so, you know, they, they had a financial stake. So open AI would give Bill Gates, others at Microsoft an early peak at what they were learning. And you know, gates, who, to him, AI is the holy grail of computing.


He is, you know, been programming since before he was born practically. And, you know, to artificial intelligence, the holy grail. And you know, he was impressed with, I think it was GPT-3 or whatever, the more the, the most recent one he had seen. But he gave a challenge. He said, I'm gonna be impressed if it could ace the biology AP test. And he chose that one because it's not just regurgitating facts. You need to analyze, you need to synthesize. You really have to show some sense of understanding and intelligence. And he thought that would be a great challenge. And so, you know, he, he, he threw down the gauntlet and thought, okay, I'll hear from them in a few years, whatever.


And you know, not that many months later, you know, he heard from OpenAI, okay, we're ready. And so in September of 2022, gates hosted at his house, a demo, the OpenAI, and you know, it was whatever, 30 people from Microsoft, from OpenAI while someone was at a computer. The big screen was set up and watching this computer take the, this test, and, you know, within two or three answers, people were just blown away. And in fact, it did get five out of five on the test.


It did pass the test. And that's when Gates became a true, true, true believer. You know, I thought I was, you know, in his mind as he said, you know, I thought I was throwing down a gauntlet that would be a while. And suddenly, you know, it matched my, my, my expectations in fact. And then they kept on playing with it and they would just ask it, you know, what would you say to a father, you know, worried about the health of his son? And it just kind of spit out an answer in his gates foot is like, it's kind of better answer than most of us could have given sitting around that room. And, you know, they just started playing with it. Gates started playing with others, started playing with it, and it just blew them away.


We're gonna take another break here. Let me reintroduce you. We are speaking with Gary Rivlin. He's a veteran investigative reporter. His new book is AI Valley, Microsoft, Google, and the Trillion Dollar Race to Cash in on Artificial Intelligence. We'll be back to talk more in just a moment. This is Fresh Air.


Wanna know what's happening in the world? Listen to the State of the World podcast every weekday we bring you important stories from around the globe. In just a few minutes, you might hear how democracy is holding up in South Korea or meet Indian monkeys that have turned to crime. We don't go around the world, we already there. Listen to the State of the World podcast from NPR,


Imagine if you will, a show from NPR that's not like NPR, a show that focuses not on the important but the stupid, which features stories about people smuggling animals in their pants and competent criminals and ridiculous science studies. And call it, wait, wait, don't tell me because the good names were taken. Listen to nvs. Wait, wait, don't tell me. Yes. That is what it is called. Wherever you get your podcasts.


Donald Trump has an extraordinary approach to the presidency at the NPR Politics podcast. We're recapping the first 100 days of Donald Trump's second term, from his early promises to his policy decisions and what it all means for you. Politics may not always make sense, but will sort it out together. Over on the NPR Politics podcast.


You know, a few weeks ago there was this development, which kinda shook the stock market. This Chinese company called Deep Seek, announced that they had created this artificial intelligence system at far less cost without the sophisticated microchips that, that American companies were using. It made Americans wondered, heavens, are we about to be overtaken? Or I don't know, where does all this leave us? How important is this development? Right? So, so I mean, to me, some of that was overstated. You know, Silicon Valley companies were experimenting with smaller models that required less compute power. You know, deep seek itself was venture funded, you know, it was cheaper but hardly cheap.


You know, they still, you know, cost millions to train it, presumably, and it costs millions, tens of millions to operate. It just didn't require as much. And that really kind of was almost an existential threat to, to Silicon Valley, which they had put all their money, these tens of billions, hundreds of billions of dollars into building ever bigger models that presume that you need ever more computer power. But, you know, a a couple of things, one, I I think all it means is that instead of like, Hey, we can do this at one 10th, the power one 10th the cost, I think they're just gonna build 10 times more powerful models because they could do, you know, more with, more, with less.


When they say they you, do you mean the, the deep seek the Chinese or do you mean who No, the the American companies. You know, you know, the, they're learning from this. They'll integrate it. Like I said, I, I feel like the AI companies I was following, they were already for a year plus paying attention to smaller models. Like maybe you don't need this whole huge system to answer a simple question. You know, maybe we, we should have a bunch of smaller models and like, okay, this one's an expert in this, that one's an expert in that, and we just have a smaller model, give questions. But, you know, I, I think what an open AI would say, other than the fact, an ironic statement that, you know, you used our model to train. I say it's ironic because, you know, open AI is being sued for, you know, taking other, taking the copyright, the intellectual property of, you know, the New York Times of book writers, of artists, of musicians and all.


But, you know, I, I think what's interesting about Deep Sea is it really gives hope to startups. Like, wait, okay, maybe you don't need as much money as we thought you do to create a company. But, you know, I I, I do think it's important to understand that they still were using a lot of computer power. They still required a lot of money, just not as much as some of these larger companies that we've been talking about. You know, Reid Hoffman, the investor who's been very active in this area, is ultimately very optimistic about where AI is going to take us. Where are you on that scale? I do feel that AI is gonna bring about incredible things. I think it's being overstated.


You hear people say that it's gonna, you know, close the divide between the developing world and the developed world. I don't think that's so, but you know, there's this interesting study that came out recently, the idea of an AI tutor, a tutor in the pocket that everyone has access. 5 billion people around the globe have a smartphone, and you can use that smartphone as a tutor. And so there was a study in Africa that like, let's let these kids after school have access to these AI tutors. And in six weeks they showed two years worth of advancements. And I really do think around education, around science, you know, science is balkanized, right?


It's, it's, you know, it's specialties and subspecialties and there's own vocabulary lingo in every subspecialty. You know, these large language models could read across specialties and connect the dots. They can make connections that no human being can do. And I think we're gonna see some amazing scientific advancements, creation of vaccines, of better therapies. You know, there are some who predict, and I actually think there's a lot to it, that the mortality rate for most cancers are gonna go way down because of ai. So I really do think AI could do some amazing things. It's just, I just don't know how bad the bad's gonna be. I, you know, if I had one wish, I wish we were dealing with the concerns that are within the line of sight, the stuff that we can imagine, like, wait, it, it could be used for scams, it could be used in warfare instead of like, this idea of the robots are gonna take over and subjugate humanity.


I, I guess that's possible, but not in the short term, not in the median term, you know, just, just in, kinda in the long term. And if we're deliberate about it, I think there's no doubt that AI could be a positive. You know, again, i i, I just compare it to the internet, you know, is the internet a great thing? Like, nah, I could tell you a lot of negatives with the internet, but you know, I think the internet has, you know, changed society in a lot of ways that, you know, we like, you know, the smartphone the same kind of thing. So I I, I, it's gonna be a mixed bag and I guess I'm keeping my fingers crossed that, you know, despite the next four years, there's not gonna be much regulation, not much checks and balances, that AI's gonna be a net positive.


Speaking of guardrails, what, what rules, if any, do you have for your kids and their use of, of chatbots, You know, and right after chat, BT came out middle school where my younger son goes, they, they kind of, I had this idea of banning it and it's like, wait, wait, wait. Like they need To learn how to use this. I, I'll go back to what I was saying before, that, you know, we have To learn how to use this. What, what is this good for and what are ways we can't rely on it right now? So, you know, if my, one of my sons writes a, a composition, you know, like throw it into chap chat GPT and get some feedback, you know, on it. Like, I, I, I may or may or not cut my older son, you know, using it to write an English paper, you know, within three, You just told about a million people that you may or may not have done call what I'm doing, You know, within three sentences it was obvious, like, okay, this is too perfect.


This sounds like, you know, cliff notes for those of us who are old enough to know what a cliff notes are, are, but it's like, go rewrite. So, you know, don't use it to write, but use it as a research assistant, you know, use it for feedback. And in fact, I I see with one of my sons, you know, a teacher, like, yeah, if you're writing something for science, use it and get some feedback on, you know, saying more clearly what it is. But, you know, it's a very personal choice, but I'm convinced that my kids, their life is gonna be as dramatically different as mine was growing up before the internet and before mobile phones became pervasive. I, I really do think AI liked the internet, liked the phone within, you know, I'll say 10 or 15 years, I could be wrong on that, but at some point in the future is gonna be at the center of their lives.


And I think this next generation should get used to it because it's gonna be critical to, you know, what they do, how they relate to the world, how they get employment. The company inflection that you write about, they had this chatbot pie, you had an interesting exchange with that chatbot about a medical issue your son had. Do you want to share that with us? Yeah. So we were facing this health crisis just as pie was coming out. And usually what a reporter does when these chatbot comes out is they, they try to mess with it. They try to get it to misbehave, they try to get it to jump the fence, but I like, let me try dealing with this in a more authentic way.


And, you know, I was really impressed, you know, it had just the right tone, said all the right things, if not a little too perfectly, you know, it, ask the right questions to get a dialogue going, you know, kind of in the fashion of a friend, like, how is your son taking the news? How's the school handling it? How are you taking care of yourself through these stressful times? You know, it was a slew of questions, probably too many questions, but, you know, it really picked up on nuance. It got little jokes. I told a funny moment from the sit down with the, the neurosurgeon, you know, and it just responded like, you know, teenagers, am I right? You know, gave me a lot of things to think about, but what was so interesting to me is it, it also didn't mean anything to me. You know, there's this quote I love from an MIT sociologist, Sherry Turkel, you know, the performance of empathy is not empathy, you know, a bot expressing empathy.


It's, it's not really empathy, it's just algorithms parsing human language patterns, trying to like, oh, here's the right thing to ask and stuff. But, you know, it really was an interesting experience, and I can understand like, you know, if people were lonely, if people didn't have, you know, a network of people to speak with, this could be really something. I, I, I think something people have to get used to is dropping this idea like, oh my God, you're gonna have a friendship with a bot. You know, you're gonna treat it like a therapist. Yes, of course you should go to a licensed therapist to deal with your issues, but like, you know what, if you don't have a few hundred dollars or whatever it costs for a therapist every week, and you know, it's like they, they really do help you think through at least this bot pi really helps you think through what are the questions you should be asking yourself and all.


So, you know, it was really, it was really interesting experience for me to really just try to feel like just your average user, what they would feel like, you know, discussing something difficult. Brain surgery, in this case of myself, which by the way, I should say it was a very happy ending. Everything turned out fantastic. It's easy to talk about because of that. Good, I'm glad you mentioned that, but you Know, the bot gave me some interesting things to think about. Well, Gary Rivlin, thanks so much for speaking with us again. Oh, my pleasure. Thank you so much. Gary Rivlin is a veteran investigative reporter. His new book is AI Valley, Microsoft, Google, and the Trillion Dollar Race to Cash in on Artificial Intelligence.


This is Fresh Air


Aviv Regev is the co-founder of the Human Cell atlas. It's a huge leap in understanding how human cells work. She says it's like upgrading from a 15th century map of the world to Google Maps. If I want to develop a medicine that would only go to the place where something is broken, I need to know how to get there. The new wave of biotechnology that's on the TED Radio Hour podcast from NPR


At Planet Money, we'll take you from a race to make rum in the Caribbean. Our rum From a quality standpoint, is the best in the world. To the labs dreaming up the most advanced microchips, It's very rare for people to go inside Two the back rooms of New York's Diamond District. What You are looking for, the stupid guy here, they're all smart, don't worry about It. Planet money from NPR. We go to the story and take you along with us wherever you get your podcasts.


Karen Russell's first novel Swamplandia came out in 2011 and was a finalist for the Pulitzer Prize. Our book critic, Maureen Corrigan, says she expects Russell's new novel. The Antidote will be on a lot of prize lists this year. Here's her review. No one summons up the old Weird America in fiction. Like Karen Russell does. Her tall tales of alligator wrestlers in Florida, homesteaders on the gothic great plains and female prospectors digging for gold mashup history with the Mac carb in a cracker barrel, aged with dry humor. Russell's celebrated debut novel Swamplandia came out in 2011.


Since then, she's published a couple of excellent short story collections, but the wait for another novel was growing a little strained. I even heard speculation that maybe all the acclaim Russell received for her first novel had blocked her. Well, The Antidote has just come out, and now we know why it took so long. American epics take a while. The Antidote is set in a dust bowl era. Nebraska Town called us, but it also reaches back to the earlier pioneer era Russell evoked in her short story masterpiece Proving Up, which was made into an opera.


The novel is framed by two true weather catastrophes. The Black Sunday Dust Storm on April 14th, 1935, in which people were suffocated by a moving black wall of dust. And a month later, the Republican river flood when 24 inches of rain fell within one day. Much of what occurs between those two disasters is also true emotionally. But in Russell's worldview, the fantastic and the familiar coexist on the same plane. Our central character here is a prairie witch who goes by the name The Antidote part, huckster, mostly healer.


She like other prairie witches, promises to treat what ails her customers by taking away whatever they can't stand to know the memories that make them chase impossible dreams that make them sick with regret and grief. Whatever cargo unbalances the cart, I can hold on to anything for anyone. Milk, honey, rainwater, venom blood, pour it all into me. I am the empty bottle lying in a trance. The Antidote absorbs the heaviness, but not the details of her customer stories, which they sometimes want back after the Black Sunday.


Dust settles. However, The Antidote is horrified to realize she feels lighter, vacant. Some awful force has robbed her of the stories she's safeguarded. Who knows how her more violent customers will react when they discover they can't make withdrawals. Other narrators step in to amplify Russell's peculiar vision of life in us. There's Dell Ky, a teenage girl whose single mother was allegedly murdered by the lucky rabbit's foot killer, so-called because he leaves a bloody rabbit's foot near his victim's bodies.


Dell lives with her uncle Harp, whose farm is mysteriously untouched by the all enveloping dust. A federal agency photographer, a black woman named Cleo EY eventually turns up in us. Cleo explains her work by saying she's making advertisements for Roosevelt's new deal programs. She's also painfully aware of whose faces carried the most weight with Congress. Actual depression error photographs are scattered throughout this novel, but the camera CLE depends on goes Twilight Zone haywire, photographing the past and possible futures of the town and surrounding terrain like Cleo's Camera, Russell's instrument.


Her language is uncanny. Swaths of the spell binding. Final third of this novel move deeply into the past, specifically into the buried memory of how harp Oles parents in Poland grabbed at the offer of free land in Nebraska land. They come to realize that was occupied before their arrival. Here's harp's Father Guiltily, recalling how he made peace not only with that land grab, but with racial hierarchy in America. I was born a surf in all, but name my skin is the color of an unwashed onion in America.


This placed me ahead of many on a low rung of the ladder, but higher than the black porter. I heard the ticking pulse of a sick relief. Not me, not me, not me. The same feeling I once had whenever one of my brothers was chosen over me for a beating in The Antidote. Karen Russell, America's own prairie witch of a writer, exhumed memories out of the collective national unconscious, and invites us to see our history in full. There are last no antidotes for history.


Our constellations are found in writers like Russell, who refract horror and wonder through their own strange looking glass, leaving us energized for that next astounding thing. Maureen Corrigan is a professor of literature at Georgetown University. She reviewed The Antidote by Karen Russell on tomorrow's show, new Yorker, staff writer Andrew Morantz joins us to discuss how podcasts live streams and YouTube channels have become the platforms where men who feel disillusioned and alienated, go to feel seen and heard. Many of them gravitating toward the MAGA movement. I hope you can join us to keep up with what's on the show and get highlights of our interviews.


Follow us on Instagram at NPR Fresh Air. Fresh Air's Executive Producer is Danny Miller. Our technical director and engineer is Audrey Bentham with additional engineering support from Al Banks. Our managing producer is Sam Rigger. Our interviews and reviews are produced and edited by Phyllis Myers, Ann Marie Baldonado, Lauren Kreel, Theresa Madden, Monique Nazareth, Thea Cha, Susan Yadi, and Anna Balman. Our digital media producer is Molly Sevy Neper.


Roberta Shorrock directs the show for Terry Gross, Antonia Mosley. I'm Dave Davies. On this week's Wild Card podcast, Brett Goldstein says, even though his show Ted Lasso and shrinking get emotional, he doesn't, I Haven't tried yet. I Guess I thought you might be like a closet crier. No, I mean, I write all this stuff 'cause then I don't have to live it. Whoa. She's like, I got him. I'm Rachel Martin. Brett Goldstein is on Wild Card, the show where Cards Control the Conversation.


This message comes from stamps.com. How much is an hour of your time worth? Whether you are a realtor, lawyer, accountant, or even a content creator, stamps.com gives you the ability to focus your time on what you do best. Not on tedious mailing and shipping tasks, print stamps, shipping labels, or certified mail forms in seconds. More than 4 million customers have relied on stamps.com. Go to stamps.com/ NPR for a special offer. No contract, cancel any time. That's stamps.com/ NPR.