{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac095831-a70e-4b2e-a0c2-0501dce6eb44",
   "metadata": {},
   "source": [
    "# Topic Visualization\n",
    "This notebook contains the code to visually explore our labeled topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68ec33-88dd-465e-a2ae-d8c329178590",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcef11a-02d9-4454-939e-0fb2f7627a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f2b8e-8c51-4802-9218-6e3ab6883612",
   "metadata": {},
   "source": [
    "## Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74757262-089f-4839-b703-321c13f7beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv containing our chunks, assigned topic numbers, and relevant metadata\n",
    "chunk_df = pd.read_csv(\"data/bertopic_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf988fe-b608-42f4-a96b-0703878cda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv containing our topic number to iptc topic label mappings\n",
    "label_names_df = pd.read_csv(\"data/cleaned_topic_labels.csv\")\n",
    "label_names_df = label_names_df.rename(columns={\"Topic\":\"topic\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779932ce-b37d-485d-8be5-d3f629834ec3",
   "metadata": {},
   "source": [
    "## Merging Data\n",
    "We merge our two csv files `chunk_df` and `label_names_df` into `df_merged` so that we get a new DataFrame containing all of our chunks with correct topic labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60def2ce-c4d9-42e5-997a-fe6ace838c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = chunk_df.merge(\n",
    "    label_names_df[[\"topic\", \"iptc_news_topic\", \"all_topics\"]],\n",
    "    on=\"topic\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a5fd98-8db0-4608-90d6-d1c55bcb6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e37ae-4d8a-4f6f-bb20-ed2c84a0095a",
   "metadata": {},
   "source": [
    "## Extracting Broad Topics\n",
    "Here, for each topic, we get the broader category it falls into: E.g. national election --> politics and government."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45018b61-649f-469d-a0a6-91cee6efd9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_broadest_topic(topics):\n",
    "    if isinstance(topics, list) and len(topics) > 0:\n",
    "        return topics[-1]\n",
    "    return None\n",
    "\n",
    "if isinstance(df_merged[\"all_topics\"].iloc[0], str):\n",
    "    df_merged[\"all_topics\"] = df_merged[\"all_topics\"].apply(ast.literal_eval)\n",
    "\n",
    "df_merged[\"broadest_topic\"] = df_merged[\"all_topics\"].apply(extract_broadest_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d0aa46-e54e-4462-8f4f-91d1b8b63df1",
   "metadata": {},
   "source": [
    "## Filtering Out Non-News\n",
    "We then filter to only get those topics relevant to news. Specifically, this means cutting human interest, sport, lifestyle and leisure, and arts, culture, entertainment and media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81152836-20d8-4359-ad0c-bac6bb41f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_news = [\"human interest\", \"lifestyle and leisure\", \"arts, culture, entertainment and media\", \"sport\"]\n",
    "news_only = df_merged[~df_merged[\"broadest_topic\"].isin(non_news)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d41835c-c9cb-4d76-9874-e9d2f3a6de3e",
   "metadata": {},
   "source": [
    "## UMAP Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e34619-7768-43f9-9190-c894a5c8a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the embeddings\n",
    "embeddings = np.load(\"models/embeddings/docs_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f3bd8-a167-4df2-8ba1-2b5a6ee139ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "umap_results = umap_reducer.fit_transform(\n",
    "    embeddings[news_only.index]  # only get embeddings for our news chunks\n",
    ")\n",
    "\n",
    "# add UMAP results back to the filtered DataFrame\n",
    "news_only[\"umap_1\"] = umap_results[:, 0]\n",
    "news_only[\"umap_2\"] = umap_results[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14bff2-07e0-4617-9bae-94f897c6cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting news chunks with UMAP\n",
    "news_only.to_csv(\"data/news_chunks_w_umap.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66796e29-d1e1-4433-a340-a75cd4ca2197",
   "metadata": {},
   "source": [
    "## UMAP Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ec4f6-08fa-4e6d-9f5b-f0acafe6bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.scatterplot(\n",
    "    data=news_only, \n",
    "    x=\"umap_1\", y=\"umap_2\",\n",
    "    hue=\"source_type\", \n",
    "    s=5, alpha=0.5,\n",
    "    legend=True  \n",
    ")\n",
    "plt.title(\"UMAP by Broader Topic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1d4cb-21e3-4835-b462-a877c7aa960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify unique source_types\n",
    "source_types = news_only[\"source_type\"].unique()\n",
    "num_types = len(source_types)\n",
    "\n",
    "# Set up side-by-side plots\n",
    "fig, axes = plt.subplots(1, num_types, figsize=(8*num_types, 8), sharex=True, sharey=True)\n",
    "if num_types == 1:\n",
    "    axes = [axes]  # Make iterable if only one source_type\n",
    "\n",
    "for ax, src in zip(axes, source_types):\n",
    "    subset = news_only[news_only[\"source_type\"] == src]\n",
    "\n",
    "    sns.scatterplot(\n",
    "        ax=ax,\n",
    "        data=subset,\n",
    "        x=\"umap_1\", y=\"umap_2\",\n",
    "        hue=\"broadest_topic\",\n",
    "        palette=\"tab20\",\n",
    "        s=3, alpha=0.5,\n",
    "        legend=True\n",
    "    )\n",
    "    ax.set_title(f\"UMAP by Broadest Topic: {src}\")\n",
    "    ax.set_xlabel(\"UMAP 1\")\n",
    "    ax.set_ylabel(\"UMAP 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffc217-f47b-4e81-948c-0bcec67f4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts = (\n",
    "    news_only.groupby([\"source_type\", \"broadest_topic\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# converting counts to proportions\n",
    "topic_totals = topic_counts.groupby(\"source_type\")[\"count\"].transform(\"sum\")\n",
    "topic_counts[\"proportion\"] = topic_counts[\"count\"] / topic_totals\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(\n",
    "    data=topic_counts,\n",
    "    x=\"broadest_topic\",\n",
    "    y=\"proportion\",\n",
    "    hue=\"source_type\"\n",
    ")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.title(\"Proportion of Each Topic in Each Source Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296408a-5be5-454b-a446-01adaa487196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subtopic_distribution(\n",
    "    df, \n",
    "    drill_path=None, \n",
    "    all_topics_col=\"all_topics\", \n",
    "    source_col=\"source_type\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots the distribution of the next-more-granular subtopic beneath the specified drill_path, split by source_type.\n",
    "    If drill_path is None or empty, shows distribution of broadest topics.\n",
    "    \"\"\"\n",
    "    # if drill_path is not specified, plot distribution of broadest topics\n",
    "    if not drill_path:\n",
    "        # extract broadest topic (last element of all_topics)\n",
    "        df = df[df[all_topics_col].apply(lambda x: isinstance(x, list) and len(x) > 0)].copy()\n",
    "        df[\"broadest_topic\"] = df[all_topics_col].apply(lambda x: x[-1])\n",
    "        counts = (\n",
    "            df.groupby([source_col, \"broadest_topic\"])\n",
    "            .size()\n",
    "            .reset_index(name=\"count\")\n",
    "        )\n",
    "        counts[\"source_total\"] = counts.groupby(source_col)[\"count\"].transform(\"sum\")\n",
    "        counts[\"proportion\"] = counts[\"count\"] / counts[\"source_total\"]\n",
    "\n",
    "        # sort topics by total count\n",
    "        order = counts.groupby(\"broadest_topic\")[\"count\"].sum().sort_values(ascending=False).index\n",
    "\n",
    "        plt.figure(figsize=(12,6))\n",
    "        sns.barplot(\n",
    "            data=counts,\n",
    "            x=\"broadest_topic\",\n",
    "            y=\"proportion\",\n",
    "            hue=source_col,\n",
    "            order=order\n",
    "        )\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.title(f\"Distribution of broadest topics by {source_col}\")\n",
    "        plt.ylabel(\"Proportion within Source\")\n",
    "        plt.xlabel(\"Broadest Topic\")\n",
    "        plt.legend(title=source_col)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    # drilldown as before\n",
    "    if not isinstance(drill_path, (list, tuple)):\n",
    "        print(\"drill_path must be a list or None.\")\n",
    "        return\n",
    "    if len(drill_path) < 1:\n",
    "        print(\"drill_path must be non-empty or None to get broadest topic distribution.\")\n",
    "        return\n",
    "    drill_path = list(reversed(drill_path))\n",
    "    # find rows whose all_topics ends with the drill_path (ordered broadest last)\n",
    "    def matches_drill_path(all_topics):\n",
    "        if not isinstance(all_topics, list):\n",
    "            return False\n",
    "        if len(all_topics) < len(drill_path):\n",
    "            return False\n",
    "        return all_topics[-len(drill_path):] == drill_path\n",
    "\n",
    "    subset = df[df[all_topics_col].apply(matches_drill_path)].copy()\n",
    "    if subset.empty:\n",
    "        print(f\"No entries found for drill_path {drill_path}.\")\n",
    "        return\n",
    "    \n",
    "    # get next-more-granular subtopic (one level deeper)\n",
    "    def get_next_subtopic(all_topics):\n",
    "        if not isinstance(all_topics, list):\n",
    "            return None\n",
    "        idx = len(all_topics) - len(drill_path)\n",
    "        if idx > 0:\n",
    "            return all_topics[idx - 1]\n",
    "        return None\n",
    "\n",
    "    subset[\"next_subtopic\"] = subset[all_topics_col].apply(get_next_subtopic)\n",
    "    # remove missing/empty\n",
    "    subset = subset[subset[\"next_subtopic\"].notnull() & (subset[\"next_subtopic\"] != \"\")]\n",
    "    if subset.empty:\n",
    "        print(f\"No subtopics found one level deeper than {drill_path}.\")\n",
    "        return\n",
    "    \n",
    "    # calculate counts and proportions\n",
    "    counts = (\n",
    "        subset.groupby([source_col, \"next_subtopic\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    counts[\"source_total\"] = counts.groupby(source_col)[\"count\"].transform(\"sum\")\n",
    "    counts[\"proportion\"] = counts[\"count\"] / counts[\"source_total\"]\n",
    "\n",
    "    # sort by total count\n",
    "    plot_order = (\n",
    "        counts.groupby(\"next_subtopic\")[\"count\"].sum().sort_values(ascending=False).index\n",
    "    )\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.barplot(\n",
    "        data=counts,\n",
    "        x=\"next_subtopic\",\n",
    "        y=\"proportion\",\n",
    "        hue=source_col,\n",
    "        order=plot_order\n",
    "    )\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    path_txt = \" > \".join(drill_path)\n",
    "    plt.title(f\"Distribution of subtopics within \\\"{path_txt}\\\" by {source_col}\")\n",
    "    plt.ylabel(\"Proportion within Source\")\n",
    "    plt.xlabel(\"Subtopic\")\n",
    "    plt.legend(title=source_col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daea1b7-632f-4f10-bc2f-ba1c865dfde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suptopic plotting!\n",
    "plot_subtopic_distribution(news_only, [\"society\", \"mankind\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
